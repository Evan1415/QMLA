{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 22/11 further development -- adding columns to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/parallel.py:13: ShimWarning: The `IPython.parallel` package has been deprecated since IPython 4.0. You should import from ipyparallel instead.\n",
      "  \"You should import from ipyparallel instead.\", ShimWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/qinfer/parallel.py:52: UserWarning: Could not import IPython parallel. Parallelization support will be disabled.\n",
      "  \"Could not import IPython parallel. \"\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This library provides a database framework for QMD/QML.\n",
    "\n",
    "A Pandas dataframe is used as a database for running QMD, recording: \n",
    "  - model name (and name reordered alphabetically) \n",
    "  - Log Likelihood\n",
    "  - Origin epoch\n",
    "  - QML Class\n",
    "  - Qubits acted on: which qubits have some operator acting on \n",
    "  - Root Node\n",
    "  - Selected\n",
    "  - Status\n",
    "\n",
    "A separate database holds all information on individual models:\n",
    "  - constituent operators (names and matrices) [i.e. those which are summed to give model]\n",
    "  - total matrix\n",
    "  - number of qubits (dimension)\n",
    "\n",
    "The database is generated by the function launch_db. E.g. usage: \n",
    "\n",
    "  $ db, model_db, model_lists = DataBase.launch_db(gen_list=gen_list)\n",
    "\n",
    "This returns: \n",
    "\n",
    "  - db: \"running database\", info on dlog likelihood, etc.\n",
    "  - model_db: info on construction of model, i.e. constituent operators etc.\n",
    "  - model_lists = list of lists containing alphabetised model names. When a new model is considered, it should be compared against models of identical dimension (number of qubits) by alhpabetical name. If the alphabetical name is found in, e.g. model_lists[3], it has already been considered and the QML should be terminated.\n",
    "\n",
    "\n",
    "To fill the data base, a list of generators are passed to launch_db. \n",
    "These are strings corresponding to unique models, e.g. 'xTy' means pauli_x TENSOR_PROD pauli_y \n",
    "(see Naming_Convention.pdf). \n",
    "These names are used to generate instances of the operator class (defined here). \n",
    "This class computes, based on the name, what the constituent operator names, matrices, total matrix, etc.\n",
    "of the given model are, and fills these values into the model_db. \n",
    "\n",
    "e.g. usage of operator: \n",
    "  $ name='xPyTz'\n",
    "  $ test_op = operator(name)\n",
    "  $ print(test_op.name)\n",
    "  $ print(test_op.matrix)\n",
    "  $ print(test_op.constituent_operators\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import itertools as itr\n",
    "\n",
    "import os as os\n",
    "import sys as sys \n",
    "import pandas as pd\n",
    "import warnings\n",
    "import hashlib\n",
    "sys.path.append(os.path.join(\"..\",\"Libraries\",\"QML_lib\"))\n",
    "\n",
    "import Evo as evo\n",
    "\n",
    "global paulis_list\n",
    "paulis_list = {'i' : np.eye(2), 'x' : evo.sigmax(), 'y' : evo.sigmay(), 'z' : evo.sigmaz()}\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "------ ------ Operator Class ------ ------\n",
    "\"\"\"\n",
    "\n",
    "class operator():\n",
    "    \"\"\"\n",
    "    Operator class:\n",
    "    Takes one argument: name (string) according to naming convention.\n",
    "    Name specifies all details of operator. \n",
    "    e.g.\n",
    "    - xPy is X+Y, 1 qubit\n",
    "    - xTz is x TENSOR_PROD Z, 2 qubits\n",
    "    - xMyTz is (X PROD Y) TENSOR_PROD Z, 2 qubits\n",
    "    - xPzTiTTz is (X+Z) TENSOR_PROD I TENSOR_PROD Z\n",
    "      -- 3 qubit operator. X+Z on qubit 1; I on qubit 2; Z on qubit 3\n",
    "    See Naming_Convention.pdf for details.\n",
    "\n",
    "    Constituents of an operator are operators of the same dimension which sum to give the operator.\n",
    "    e.g. \n",
    "    - xPy = X + Y has constituents X, Y\n",
    "\n",
    "    Assigns properties for : \n",
    "    - constituents_names: strings specifying constituents\n",
    "    - constituents_operators: whole matrices of constituents\n",
    "    - num_qubits: total dimension of operator [number of qubits it acts on]\n",
    "    - matrix: total matrix operator\n",
    "    - qubits_acted_on: list of qubits which are acted on non-trivially\n",
    "      -- e.g. xTiTTz has list [1,3], since qubit 2 is acted on by identity\n",
    "    - alph_name: rearranged version of name which follows alphabetical convention\n",
    "      -- uniquely identifies equivalent operators for comparison against previously considered models\n",
    "    -\n",
    "    \"\"\"\n",
    "    def __init__(self, name): \n",
    "        self.name = name\n",
    "    \n",
    "    @property\n",
    "    def constituents_names(self):\n",
    "        \"\"\"\n",
    "        List of constituent operators names.\n",
    "        \"\"\"\n",
    "        t_str, p_str, max_t, max_p = get_t_p_strings(self.name)\n",
    "        paulis_list = {'i' : np.eye(2), 'x' : evo.sigmax(), 'y' : evo.sigmay(), 'z' : evo.sigmaz()}\n",
    "        if(max_t >= max_p):\n",
    "            # if more T's than P's in name, it has only one constituent. \n",
    "            return [self.name]\n",
    "        else: \n",
    "            # More P's indicates a sum at the highest dimension. \n",
    "            return self.name.split(p_str)\n",
    "\n",
    "    @property\n",
    "    def num_qubits(self):\n",
    "        \"\"\"\n",
    "        Number of qubits this operator acts on. \n",
    "        \"\"\"\n",
    "        return get_num_qubits(self.name)\n",
    "        \n",
    "    @property\n",
    "    def constituents_operators(self):\n",
    "        \"\"\"\n",
    "        List of matrices of constituents. \n",
    "        \"\"\"\n",
    "        ops = []\n",
    "        for i in self.constituents_names:\n",
    "            ops.append(compute(i))\n",
    "        return ops\n",
    "\n",
    "    @property\n",
    "    def num_constituents(self):\n",
    "        \"\"\"\n",
    "        Integer, how many constituents, and therefore parameters, are in this model.\n",
    "        \"\"\"    \n",
    "        return len(self.constituents_names)\n",
    "    \n",
    "    @property \n",
    "    def matrix(self):\n",
    "        \"\"\"\n",
    "        Full matrix of operator. \n",
    "        \"\"\"\n",
    "        mtx = empty_array_of_same_dim(self.name)\n",
    "        for i in self.constituents_operators:\n",
    "            mtx += i\n",
    "        return mtx\n",
    "\n",
    "    @property\n",
    "    def qubits_acted_on(self):\n",
    "        \"\"\"\n",
    "        List of qubits which are acted on non-trivially by this operator. \n",
    "        TODO: qubit count starts from 1 -- should it start from 0?\n",
    "        \"\"\"\n",
    "        return list_used_qubits(self.name)\n",
    "   \n",
    "    @property \n",
    "    def two_to_power_used_qubits_sum(self):\n",
    "        \"\"\"\n",
    "        Binary sum of operators acted on. \n",
    "        For use in comparing new operators. [Not currently used]\n",
    "        \"\"\"\n",
    "        running_sum = 0\n",
    "        for element in list_used_qubits(self.name):\n",
    "            running_sum += 2**element\n",
    "        return running_sum\n",
    "\n",
    "    @property\n",
    "    def alph_name(self):\n",
    "        \"\"\"\n",
    "        Name of operator rearranged to conform with alphabetical naming convention. \n",
    "        Uniquely identifies equivalent operators. \n",
    "        For use when comparing potential new operators. \n",
    "        \"\"\"\n",
    "        return alph(self.name)\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "Functions for use by operator class to parse string (name) and prodcue relevent operators, lists etc.\n",
    "\"\"\"\n",
    "\n",
    "def get_num_qubits(name):\n",
    "    \"\"\"\n",
    "    Parse string and determine number of qubits this operator acts on. \n",
    "    \"\"\"\n",
    "    max_t_found = 0 \n",
    "    t_str=''\n",
    "    while name.count(t_str+'T')>0:\n",
    "        t_str=t_str+'T'\n",
    "\n",
    "    num_qubits = len(t_str) + 1\n",
    "    return num_qubits\n",
    "    \n",
    "\n",
    "def list_used_qubits(name):\n",
    "    \"\"\"\n",
    "    Parse string and determine which qubits are acted on non-trivially. \n",
    "    \"\"\"\n",
    "    max_t, t_str = find_max_letter(name, \"T\")\n",
    "    max_p, p_str = find_max_letter(name, \"P\")\n",
    "    running_list = []\n",
    "\n",
    "    if max_p >= max_t:\n",
    "        list_by_p_sep = []\n",
    "        if p_str == '':  \n",
    "          ## In case of empty separator, split by anything into one string    \n",
    "          p_str = 'RRR'\n",
    "        \n",
    "        sep_by_p = name.split(p_str)\n",
    "        for element in sep_by_p:\n",
    "            list_by_p_sep.append(get_acted_on_qubits(element))\n",
    "\n",
    "        for i in range(len(list_by_p_sep)):\n",
    "            to_add= list(set(list_by_p_sep[i]) - set(running_list))\n",
    "            running_list = running_list + to_add\n",
    "\n",
    "    else:\n",
    "        running_list = get_acted_on_qubits(name)\n",
    "    return running_list\n",
    "\n",
    "\n",
    "def get_acted_on_qubits(name):\n",
    "    \"\"\"\n",
    "    Parse string and determine which qubits are acted on non-trivially. \n",
    "    \"\"\"\n",
    "    max_t, t_str = find_max_letter(name, \"T\")\n",
    "    max_p, p_str = find_max_letter(name, \"P\")\n",
    "    if max_p > max_t:\n",
    "        list_by_p_sep = []\n",
    "        if p_str == '':\n",
    "          ## In case of empty separator, split by anything into one string    \n",
    "          p_str = 'RRR'\n",
    "\n",
    "        sep_by_p = name.split(p_str)\n",
    "        for element in sep_by_p:\n",
    "            list_by_sep.append(fill_qubits_acted_on_list, element)\n",
    "    \n",
    "    \n",
    "    qubits_acted_on = []\n",
    "    fill_qubits_acted_on_list(qubits_acted_on,name)\n",
    "    return sorted(qubits_acted_on)\n",
    "    \n",
    "def fill_qubits_acted_on_list(qubits_acted_on, name):\n",
    "    \"\"\"\n",
    "    Parse string and determine which qubits are acted on non-trivially. \n",
    "    Return list of those qubits. \n",
    "    \"\"\"\n",
    "    max_t, t_str = find_max_letter(name, \"T\")\n",
    "    max_p, p_str = find_max_letter(name, \"P\")\n",
    "    if(max_p > max_t):\n",
    "        string_to_analyse = name.split(p_str)[0]\n",
    "    else:\n",
    "        string_to_analyse = name\n",
    "\n",
    "    if max_t == 0:\n",
    "        if string_to_analyse != 'i':\n",
    "            qubits_acted_on.append(1)\n",
    "\n",
    "\n",
    "    else:\n",
    "        i=max_t\n",
    "        this_t_str = t_str\n",
    "        broken_down = string_to_analyse.split(this_t_str)\n",
    "        lhs = broken_down[0]\n",
    "        rhs = broken_down[1]\n",
    "        if rhs !='i':\n",
    "            qubits_acted_on.append(i+1)\n",
    "\n",
    "        if max_t == 1:\n",
    "            if lhs!='i':\n",
    "                qubits_acted_on.append(1)\n",
    "        else: \n",
    "            fill_qubits_acted_on_list(qubits_acted_on, lhs)                \n",
    "    \n",
    "def get_t_p_strings(name):\n",
    "    \"\"\"\n",
    "    Find largest instance of consecutive P's and T's.\n",
    "    Return those instances and lengths of those instances. \n",
    "    \"\"\"\n",
    "    t_str = ''\n",
    "    p_str = ''\n",
    "    while name.count(t_str+'T')>0:\n",
    "        t_str=t_str+'T'\n",
    "\n",
    "    while name.count(p_str+'P')>0:\n",
    "        p_str=p_str+'P'\n",
    "\n",
    "    max_t = len(t_str)\n",
    "    max_p = len(p_str)\n",
    "\n",
    "    return t_str, p_str, max_t, max_p        \n",
    "    \n",
    "def find_max_letter(string, letter):\n",
    "    \"\"\"\n",
    "    Find largest instance of consecutive given 'letter'.\n",
    "    Return largest instance and length of that instance. \n",
    "    \"\"\"\n",
    "    letter_str=''\n",
    "    while string.count(letter_str+letter)>0:\n",
    "        letter_str=letter_str+letter\n",
    "\n",
    "    return len(letter_str), letter_str\n",
    "\n",
    "\n",
    "def empty_array_of_same_dim(name):\n",
    "    \"\"\"\n",
    "    Parse name to find size of system it acts on. \n",
    "    Produce an empty matrix of that dimension and return it. \n",
    "    \"\"\"\n",
    "    t_str=''\n",
    "    while name.count(t_str+'T')>0:\n",
    "        t_str=t_str+'T'\n",
    "\n",
    "    num_qubits = len(t_str) +1\n",
    "    dim = 2**num_qubits\n",
    "    #print(\"String: \", name, \" has NQubits: \", num_qubits)\n",
    "    empty_mtx = np.zeros([dim, dim], dtype=np.complex128)\n",
    "    return empty_mtx\n",
    "\n",
    "\n",
    "\n",
    "def alph(name):\n",
    "    \"\"\"\n",
    "    Return alphabetised version of name. \n",
    "    Parse string and recursively call alph function to alphabetise substrings. \n",
    "    \"\"\"\n",
    "    t_max, t_str = find_max_letter(name, \"T\")\n",
    "    p_max, p_str = find_max_letter(name, \"P\")\n",
    "    m_max, m_str = find_max_letter(name, \"M\")\n",
    "    \n",
    "    if p_max == 0 and t_max ==0 and p_max ==0 :\n",
    "        return name\n",
    "    \n",
    "    if p_max > t_max and p_max > m_max: \n",
    "        ltr = 'P'\n",
    "        string = p_str\n",
    "    elif t_max >= p_max:\n",
    "        string = t_str\n",
    "        ltr = 'T'\n",
    "    elif m_max >= p_max: \n",
    "        string = m_str\n",
    "        ltr = 'M'\n",
    "    elif t_max > m_max: \n",
    "        string = t_str\n",
    "        ltr = 'T'\n",
    "    else:\n",
    "        ltr = 'M'\n",
    "        string = m_str\n",
    "\n",
    "    spread = name.split(string)\n",
    "    if  p_max==m_max and p_max > t_max:\n",
    "        string = p_str\n",
    "        list_elements = name.split(p_str)\n",
    "        \n",
    "        for i in range(len(list_elements)):\n",
    "            list_elements[i] = alph(list_elements[i])\n",
    "        sorted_list = sorted(list_elements)\n",
    "        linked_sorted_list = p_str.join(sorted_list)\n",
    "        return linked_sorted_list\n",
    "        \n",
    "    if ltr=='P' and p_max==1:\n",
    "        sorted_spread = sorted(spread)\n",
    "        out = string.join(sorted_spread)\n",
    "        return out\n",
    "    elif ltr=='P' and p_max>1:\n",
    "        list_elements = name.split(string)\n",
    "        sorted_list = sorted(list_elements)\n",
    "        for i in range(len(sorted_list)):\n",
    "            sorted_list[i] = alph(sorted_list[i])\n",
    "        linked_sorted_list = string.join(sorted_list)\n",
    "        return linked_sorted_list\n",
    "    else: \n",
    "        for i in range(len(spread)):\n",
    "            spread[i] = alph(spread[i])\n",
    "        out = string.join(spread)\n",
    "        return out\n",
    "\n",
    "\n",
    "def compute_t(inp):\n",
    "    \"\"\"\n",
    "    Assuming largest instance of action on inp is tensor product, T.\n",
    "    Parse string.\n",
    "    Recursively call compute() function.\n",
    "    Tensor product resulting lists.\n",
    "    Return operator which is specified by inp.\n",
    "    \"\"\"\n",
    "    max_t, t_str = find_max_letter(inp, \"T\")\n",
    "    max_p, p_str = find_max_letter(inp, \"P\")\n",
    "\n",
    "    if(max_p == 0 and max_t==0):\n",
    "        pauli_symbol = inp\n",
    "        return paulis_list[pauli_symbol] \n",
    "\n",
    "    elif(max_t==0):\n",
    "        return compute(inp)\n",
    "    else:\n",
    "        to_tens = inp.split(t_str)\n",
    "        #print(\"To tens: \", to_tens)\n",
    "        running_tens_prod=compute(to_tens[0])\n",
    "        #print(\"Split by \", t_str, \" : \\n\", to_tens)\n",
    "        for i in range(1,len(to_tens)):\n",
    "            max_p, p_str = find_max_letter(to_tens[i], \"P\")\n",
    "            max_t, t_str = find_max_letter(to_tens[i], \"T\")\n",
    "            #print(\"To tens [i=\", i, \"]:\\n\", to_tens[i] )\n",
    "            rhs = compute(to_tens[i])\n",
    "            running_tens_prod = np.kron(running_tens_prod, rhs)\n",
    "        #print(\"RESULT \", t_str, \" : \", inp, \": \\n\", running_tens_prod)\n",
    "        return running_tens_prod\n",
    "\n",
    "def compute_p(inp):\n",
    "    \"\"\"\n",
    "    Assuming largest instance of action on inp is addition, P.\n",
    "    Parse string.\n",
    "    Recursively call compute() function.\n",
    "    Sum resulting lists.\n",
    "    Return operator which is specified by inp.\n",
    "    \"\"\"\n",
    "    max_p, p_str = find_max_letter(inp, \"P\")\n",
    "    max_t, t_str = find_max_letter(inp, \"T\")\n",
    "\n",
    "    if(max_p == 0 and max_t==0):\n",
    "        pauli_symbol = inp\n",
    "        return paulis_list[pauli_symbol] \n",
    "\n",
    "    elif max_p==0:\n",
    "        return compute(inp)\n",
    "    else: \n",
    "        to_add = inp.split(p_str)\n",
    "        #print(\"To add : \", to_add)\n",
    "        running_sum = empty_array_of_same_dim(to_add[0])\n",
    "        for i in range(len(to_add)):\n",
    "            max_p, p_str = find_max_letter(to_add[i], \"P\")\n",
    "            max_t, t_str = find_max_letter(to_add[i], \"T\")\n",
    "\n",
    "           # print(\"To add [i=\", i, \"]:\", to_add[i] )\n",
    "            rhs = compute(to_add[i])\n",
    "            #print(\"SUM shape:\", np.shape(running_sum))\n",
    "            #print(\"RHS shape:\", np.shape(rhs))\n",
    "            running_sum += rhs\n",
    "\n",
    "        #print(\"RESULT \", p_str, \" : \", inp, \": \\n\", running_sum)\n",
    "        return running_sum\n",
    "\n",
    "\n",
    "def compute_m(inp):\n",
    "    \"\"\"\n",
    "    Assuming largest instance of action on inp is multiplication, M.\n",
    "    Parse string.\n",
    "    Recursively call compute() function.\n",
    "    Multiple resulting lists.\n",
    "    Return operator which is specified by inp.\n",
    "    \"\"\"\n",
    "\n",
    "    max_m, m_str = find_max_letter(inp, \"M\")\n",
    "    max_p, p_str = find_max_letter(inp, \"P\")\n",
    "    max_t, t_str = find_max_letter(inp, \"T\")\n",
    "\n",
    "    if(max_m == 0 and max_t==0 and max_p == 0 ):\n",
    "        pauli_symbol = inp\n",
    "        return paulis_list[pauli_symbol] \n",
    "\n",
    "    elif max_m ==0:\n",
    "        return compute(inp)\n",
    "    \n",
    "    else:   \n",
    "        to_mult = inp.split(m_str)\n",
    "        #print(\"To mult : \", to_mult)\n",
    "        t_str=''\n",
    "        while inp.count(t_str+'T')>0:\n",
    "            t_str=t_str+'T'\n",
    "\n",
    "        num_qubits = len(t_str) +1\n",
    "        dim = 2**num_qubits\n",
    "\n",
    "        running_product = np.eye(dim)\n",
    "\n",
    "        for i in range(len(to_mult)):\n",
    "            running_product = np.dot(running_product, compute(to_mult[i]))\n",
    "\n",
    "        return running_product    \n",
    "    \n",
    "def compute(inp):\n",
    "    \"\"\"\n",
    "    Parse string.\n",
    "    Recursively call compute() functions (compute_t, compute_p, compute_m).\n",
    "    Tensor product, multiply or sum resulting lists.\n",
    "    Return operator which is specified by inp.\n",
    "    \"\"\"\n",
    "\n",
    "    max_p, p_str = find_max_letter(inp, \"P\")\n",
    "    max_t, t_str = find_max_letter(inp, \"T\")\n",
    "    max_m, m_str = find_max_letter(inp, \"M\")\n",
    "\n",
    "    if(max_m == 0 and max_t==0 and max_p == 0):\n",
    "        pauli_symbol = inp\n",
    "        return paulis_list[pauli_symbol] \n",
    "    elif max_m > max_t:\n",
    "        return compute_m(inp)\n",
    "    elif max_t >= max_p:\n",
    "        return compute_t(inp)\n",
    "    else:\n",
    "        return compute_p(inp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qinfer import NormalDistribution\n",
    "a=NormalDistribution(mean=0.5, var=0.15)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "------ ------ Database declaration and functions ------ ------\n",
    "\"\"\"\n",
    "\n",
    "def launch_db(RootN_Qbit=[0], N_Qubits=1, gen_list=[]):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    TODO\n",
    "    RootN_Qbit: TODO\n",
    "    N_Qubits: TODO\n",
    "    gen_list: list of strings corresponding to model names. \n",
    "    \n",
    "    Outputs: \n",
    "      - db: \"running database\", info on log likelihood, etc.\n",
    "      - model_db: info on construction of model, i.e. constituent operators etc.\n",
    "      - model_lists = list of lists containing alphabetised model names. When a new model is considered, it     \n",
    "\n",
    "    Usage: \n",
    "        $ gen_list = ['xTy, yPz, iTxTTy] # Sample list of model names\n",
    "        $ running_db, model_db, model_lists = DataBase.launch_db(gen_list=gen_list)\n",
    "    \n",
    "    \"\"\"\n",
    "    generators = []\n",
    "    total_model_list = []\n",
    "#     TODO: Is this the absolute total ever???? Could define this as a global variable at top of file. \n",
    "    Max_N_Qubits = 13\n",
    "    model_lists = {}\n",
    "    for j in range(1, Max_N_Qubits):\n",
    "        model_lists[j] = []\n",
    "    \n",
    "    for i in gen_list:\n",
    "        generators.append(operator(i))\n",
    "        alph_model_name = alph(i)\n",
    "        num_qubits = get_num_qubits(i)\n",
    "        model_lists[num_qubits].append(alph_model_name)\n",
    "\n",
    "    model_db = pd.DataFrame({\n",
    "        '<Name>' : [ gen.name for gen in generators], \n",
    "        'Alph_Name' :[ gen.alph_name for gen in generators],\n",
    "        'All_Operators_Names': [gen.constituents_names for gen in generators],\n",
    "        'All_Operators_Matrices': [gen.constituents_operators for gen in generators],\n",
    "        'N_params' : [ gen.num_constituents for gen in generators ],\n",
    "        'Num_Qubits' : [ gen.num_qubits for gen in generators ],\n",
    "        'Binary_Sum_Used_Qubits' : [ gen.two_to_power_used_qubits_sum for gen in generators ],\n",
    "        'Matrix' : [gen.matrix for gen in generators]\n",
    "    })\n",
    "        \n",
    "    # if N_qubits defined: work out generator list.\n",
    "    # Or should number qubits be implied by gen list?\n",
    "    db = pd.DataFrame({\n",
    "        'Model_Class_Instance' : [gen for gen in generators],\n",
    "        '<Name>' : [ gen.name for gen in generators], \n",
    "        'Alph_Name' :[ gen.alph_name for gen in generators],\n",
    "        'Qubits_Acted_On' : [ gen.qubits_acted_on for gen in generators ],\n",
    "        'DB_location' : [ get_location(model_db, gen.name) for gen in generators],\n",
    "        'Status' : 'Ready', #TODO can get rid?\n",
    "        'Selected' : False, #TODO what's this for?\n",
    "        'TreeID' : [0 for gen in generators ], # TODO proper tree id's,\n",
    "        'Param_Estimates' : [ [[None, None]]*gen.num_constituents for gen in generators ]\n",
    "        \n",
    "#        'LogL_Ext' : None, \n",
    "#        'QML_Class' : None, \n",
    "#        'Origin_epoch' : 0, \n",
    "#        'RootNode' : 'NaN',\n",
    "        })  \n",
    "        \n",
    "    return db, model_db, model_lists\n",
    "\n",
    "\n",
    "def add_model(model_name, running_database, model_db, model_lists ):\n",
    "    \"\"\"\n",
    "    Function to add a model to the existing databases. \n",
    "    First checks whether the model already exists. \n",
    "    If so, does not add model to databases.\n",
    "      TODO: do we want to return False in this case and use as a check in QMD?\n",
    "    \n",
    "    Inputs: \n",
    "      - model_name: new model name to be considered and added if new. \n",
    "      - running_database: Database (output of launch_db) containing info on log likelihood etc. \n",
    "      - model_db: Database (output of launch_db) containing info on models, e.g constituent info, etc. \n",
    "      - model_lists: output of launch_db. A list of lists containing every previously considered model, categorised by dimension. \n",
    "      \n",
    "    Outputs: \n",
    "      TODO: return True if added; False if previously considered? \n",
    "      \n",
    "    Effect: \n",
    "      - If model hasn't been considered before, \n",
    "          Adds a row to running_database and model_db containing all columns of those.     \n",
    "    \"\"\"    \n",
    "    \n",
    "    alph_model_name = alph(model_name)\n",
    "    model_num_qubits = get_num_qubits(model_name)\n",
    "    \n",
    "    if consider_new_model(model_lists, model_name, running_database)== 'New':\n",
    "        print(\"Model Not previously considered -- adding\")\n",
    "        op = operator(model_name)\n",
    "        num_rows = len(running_database)\n",
    "\n",
    "        # add model_db_new_row to model_db and running_database\n",
    "        # Note: do NOT use pd.df.append() as this copies total DB,\n",
    "        # appends and returns copy.\n",
    "        \n",
    "        model_db_new_row = pd.Series({\n",
    "            '<Name>': op.name, \n",
    "            'Model_Class_Instance' : gen,\n",
    "            'Alph_Name': op.alph_name,\n",
    "            'All_Operators_Names' : op.constituents_names,\n",
    "            'All_Operators_Matrices': op.constituents_operators,\n",
    "            'N_params' : op.num_constituents,\n",
    "            'Num_Qubits' : op.num_qubits,\n",
    "            'Binary_Sum_Used_Qubits' : op.two_to_power_used_qubits_sum,\n",
    "            'Matrix' : op.matrix\n",
    "            })\n",
    "\n",
    "        model_db.loc[num_rows] = model_db_new_row\n",
    "       # total_model_list.append(alph_model_name)\n",
    "        model_lists[model_num_qubits].append(alph_model_name)\n",
    "        \n",
    "        # Add to running_database too, after adding to model_db\n",
    "        \n",
    "        running_db_new_row = pd.Series({\n",
    "            '<Name>': op.name,\n",
    "            'Alph_Name' : op.alph_name,\n",
    "            'Qubits_Acted_On' : op.qubits_acted_on,\n",
    "            'DB_location' : get_location(model_db, model_name),\n",
    "            'Status' : 'Ready', \n",
    "            'Selected' : False, \n",
    "            'TreeID' : 0, #TODO make argument of add_model fnc,\n",
    "            'Param_Estimates' : [[None, None]]*op.num_constituents\n",
    "#            'LogL_Ext' : None, \n",
    "#            'QML_Class' : None, \n",
    "#            'Origin_epoch' : 0, \n",
    "#            'RootNode' : 'NaN',\n",
    "        })\n",
    "\n",
    "        running_database.loc[num_rows] = running_db_new_row      \n",
    "        \n",
    "    else:\n",
    "        location = consider_new_model(model_lists, model_name, running_database)\n",
    "        #db_loc = get_location_by_alph_name(model_db, model_name)\n",
    "        print(\"Model\", alph_model_name, \" previously considered at location\", location)  \n",
    "\n",
    "\n",
    "\n",
    "def get_location(db, name):\n",
    "    \"\"\"\n",
    "    Return which row in db corresponds to the string name.\n",
    "    \"\"\"\n",
    "    for i in range(len(db['<Name>'])):\n",
    "        if db['<Name>'][i] == name:\n",
    "            return i\n",
    "\n",
    "def get_location_by_alph_name(db, name):\n",
    "    \"\"\"\n",
    "    Return which row in db corresponds to the string name.\n",
    "    Pass in alphabetised version of name. \n",
    "    \n",
    "    \"\"\"\n",
    "    for i in range(len(db['Alph_Name'])):\n",
    "        if db['Alph_Name'][i] == name:\n",
    "            return i\n",
    "\n",
    "        \n",
    "def consider_new_model(model_lists, name, db):\n",
    "    \"\"\"\n",
    "    Check whether the new model, name, exists in all previously considered models, \n",
    "    held in model_lists. \n",
    "    If name has not been previously considered, 'New' is returned. \n",
    "    If name has been previously considered, the corresponding location in db is returned. \n",
    "    TODO: return something else? Called in add_model function. \n",
    "    \"\"\"\n",
    "    # Return true indicates it has not been considered and so can be added\n",
    "    al_name = alph(name)\n",
    "    n_qub = get_num_qubits(name)\n",
    "    if al_name not in model_lists[n_qub]:\n",
    "        return 'New'\n",
    "    else: \n",
    "        location = get_location_by_alph_name(db, al_name)\n",
    "        return location\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_list = ['x', 'xTyPPyTz', 'xPyPzPi']\n",
    "db, model_db, model_lists = launch_db(gen_list=gen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;Name&gt;</th>\n",
       "      <th>Alph_Name</th>\n",
       "      <th>DB_location</th>\n",
       "      <th>Model_Class_Instance</th>\n",
       "      <th>Param_Estimates</th>\n",
       "      <th>Qubits_Acted_On</th>\n",
       "      <th>Selected</th>\n",
       "      <th>Status</th>\n",
       "      <th>TreeID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.operator instance at 0x7f2304a3f248&gt;</td>\n",
       "      <td>[[None, None]]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>False</td>\n",
       "      <td>Ready</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xTyPPyTz</td>\n",
       "      <td>xTyPPyTz</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;__main__.operator instance at 0x7f2304129b00&gt;</td>\n",
       "      <td>[[None, None], [None, None]]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>False</td>\n",
       "      <td>Ready</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xPyPzPi</td>\n",
       "      <td>iPxPyPz</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;__main__.operator instance at 0x7f2304129c20&gt;</td>\n",
       "      <td>[[None, None], [None, None], [None, None], [No...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>False</td>\n",
       "      <td>Ready</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     <Name> Alph_Name  DB_location  \\\n",
       "0         x         x            0   \n",
       "1  xTyPPyTz  xTyPPyTz            1   \n",
       "2   xPyPzPi   iPxPyPz            2   \n",
       "\n",
       "                             Model_Class_Instance  \\\n",
       "0  <__main__.operator instance at 0x7f2304a3f248>   \n",
       "1  <__main__.operator instance at 0x7f2304129b00>   \n",
       "2  <__main__.operator instance at 0x7f2304129c20>   \n",
       "\n",
       "                                     Param_Estimates Qubits_Acted_On  \\\n",
       "0                                     [[None, None]]             [1]   \n",
       "1                       [[None, None], [None, None]]          [1, 2]   \n",
       "2  [[None, None], [None, None], [None, None], [No...             [1]   \n",
       "\n",
       "   Selected Status  TreeID  \n",
       "0     False  Ready       0  \n",
       "1     False  Ready       0  \n",
       "2     False  Ready       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_model('yTzPPzTy', running_database=db, model_db=model_db, model_lists=model_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.loc[1][\"Param_Estimates\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before 22/11/17 development below [legacy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools as itr\n",
    "\n",
    "import os as os\n",
    "import sys as sys \n",
    "import pandas as pd\n",
    "import warnings\n",
    "sys.path.append(os.path.join(\"..\",\"Libraries\",\"QML_lib\"))\n",
    "import Evo as evo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global mycolumns\n",
    "mycolumns = ['<Name>' , 'N_Qbit' , 'N_params' , 'Status' , 'Selected' , 'LogL_Ext' , 'QML_Class' , 'Origin_epoch' ,'All_Operators']\n",
    "\n",
    "global spinnames\n",
    "spinnames  = ['x', 'y', 'z']\n",
    "\n",
    "global MaxParamRate\n",
    "MaxParamRate = 3\n",
    "\n",
    "global paulis_list\n",
    "paulis_list = {'i' : np.eye(2), 'x' : evo.sigmax(), 'y' : evo.sigmay(), 'z' : evo.sigmaz()}\n",
    "\n",
    "paulilist = evo.paulilist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtb = pd.DataFrame\n",
    "({\n",
    "    '<Name>':'test',\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_operators(generators):\n",
    "    print(\"Number of generators: \", len(generators))\n",
    "\n",
    "    for i in range(len(generators)):\n",
    "        print(i, \"\\n\", generators[i])\n",
    "    for i in range(0,len(generators)):\n",
    "        op_i = generators[i]\n",
    "        for j in range(i+1,len(generators)):\n",
    "            op_i = generators[i]        \n",
    "            print(\"i,j = \", i,j)\n",
    "            print(\"op_0: \\n\", op_0)\n",
    "            print(\"op_1: \\n\", op_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_operators(generators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generators = list()\n",
    "generators_names = list()\n",
    "\n",
    "generators.append(evo.sigmay())\n",
    "generators.append(evo.sigmax())\n",
    "generators.append(evo.sigmaz())\n",
    "generators_names.append('y')\n",
    "generators_names.append('x')\n",
    "generators_names.append('z')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operators = pd.DataFrame({\n",
    "    'Name':['i', 'x', 'y', 'z'],\n",
    "    'Op_list':[np.identity(2), evo.sigmax(), evo.sigmay(), evo.sigmaz()]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operators.loc[1,'Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = 'xty01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global spinnames\n",
    "spinnames  = ['x', 'y', 'z']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spinname in spinnames:\n",
    "    print(spinname+str(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RootN_Qbit = [0]\n",
    "x = evo.sigmax()\n",
    "y = evo.sigmay()\n",
    "z = evo.sigmaz()\n",
    "\n",
    "xTx = np.kron(x,x)\n",
    "xTy = np.kron(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class operator():\n",
    "    # Better to have this info in a DB than recalculating when called?\n",
    "    def __init__(self, name): \n",
    "        self.name = name\n",
    "    \n",
    "    @property\n",
    "    def constituents_names(self):\n",
    "        t_str, p_str, max_t, max_p = get_t_p_strings(self.name)\n",
    "        paulis_list = {'i' : np.eye(2), 'x' : evo.sigmax(), 'y' : evo.sigmay(), 'z' : evo.sigmaz()}\n",
    "        if(max_t >= max_p):\n",
    "            #constituent_names.append(self.name)\n",
    "            return [self.name]\n",
    "        else: \n",
    "            return self.name.split(p_str)\n",
    "            #constituent_names = self.name.split(p_str)\n",
    "        #return constituent_names        \n",
    "\n",
    "    @property\n",
    "    def num_qubits(self):\n",
    "        max_t_found = 0 \n",
    "        t_str=''\n",
    "        while self.name.count(t_str+'T')>0:\n",
    "            t_str=t_str+'T'\n",
    "\n",
    "        num_qubits = len(t_str) + 1\n",
    "        return num_qubits\n",
    "\n",
    "    @property\n",
    "    def constituents_operators(self):\n",
    "        ops = []\n",
    "        for i in self.constituents_names:\n",
    "            ops.append(compute(i))\n",
    "        return ops\n",
    "\n",
    "    @property\n",
    "    def num_constituents(self):\n",
    "        # 1 param per constituent?\n",
    "        return len(self.constituents_names)\n",
    "    \n",
    "    #THis is giving problems\n",
    "    @property \n",
    "    def matrix(self):\n",
    "        mtx = empty_array_of_same_dim(self.name)\n",
    "        for i in self.constituents_operators:\n",
    "            mtx += i\n",
    "        return mtx\n",
    "    \n",
    "    def test_const(self):\n",
    "        for i in self.constituents_operators:\n",
    "            print(i)\n",
    "            \n",
    "    def get_t_p_strings(self):\n",
    "        t_str = ''\n",
    "        p_str = ''\n",
    "        while self.name.count(t_str+'T')>0:\n",
    "            t_str=t_str+'T'\n",
    "\n",
    "        while self.name.count(p_str+'P')>0:\n",
    "            p_str=p_str+'P'\n",
    "\n",
    "        max_t = len(t_str)\n",
    "        max_p = len(p_str)\n",
    "\n",
    "        return t_str, p_str, max_t, max_p        \n",
    "    \n",
    "    def interactions_on(self):\n",
    "        # work out which qubits have actions; list ?\n",
    "        return 0\n",
    "\n",
    "    def find_max_letter(string, letter):\n",
    "        letter_str=''\n",
    "        while string.count(letter_str+letter)>0:\n",
    "            letter_str=letter_str+letter\n",
    "\n",
    "        return len(letter_str), letter_str\n",
    "\n",
    "\n",
    "    def empty_array_of_same_dim(name):\n",
    "        t_str=''\n",
    "        while name.count(t_str+'T')>0:\n",
    "            t_str=t_str+'T'\n",
    "\n",
    "        num_qubits = len(t_str) +1\n",
    "        dim = 2**num_qubits\n",
    "        #print(\"String: \", name, \" has NQubits: \", num_qubits)\n",
    "        empty_mtx = np.zeros([dim, dim], dtype=np.complex128)\n",
    "        return empty_mtx\n",
    "\n",
    "    def compute_t(inp):\n",
    "       # print(\"Compute t : \", inp)\n",
    "        max_t, t_str = find_max_letter(inp, \"T\")\n",
    "        max_p, p_str = find_max_letter(inp, \"P\")\n",
    "\n",
    "        if(max_p == 0 and max_t==0):\n",
    "            pauli_symbol = inp\n",
    "            return paulis_list[pauli_symbol] \n",
    "\n",
    "        elif(max_t==0):\n",
    "            return compute(inp)\n",
    "        else:\n",
    "            to_tens = inp.split(t_str)\n",
    "            running_tens_prod=compute(to_tens[0])\n",
    "            #print(\"Split by \", t_str, \" : \\n\", to_tens)\n",
    "            for i in range(1,len(to_tens)):\n",
    "                max_p, p_str = find_max_letter(to_tens[i], \"P\")\n",
    "                max_t, t_str = find_max_letter(to_tens[i], \"T\")\n",
    "                #print(\"To tens [i=\", i, \"]:\\n\", to_tens[i] )\n",
    "                rhs = compute(to_tens[i])\n",
    "                running_tens_prod = np.kron(running_tens_prod, rhs)\n",
    "            #print(\"RESULT \", t_str, \" : \", inp, \": \\n\", running_tens_prod)\n",
    "            return running_tens_prod\n",
    "\n",
    "    def compute_p(inp):\n",
    "        #print(\"Compute p : \", inp)\n",
    "        max_p, p_str = find_max_letter(inp, \"P\")\n",
    "        max_t, t_str = find_max_letter(inp, \"T\")\n",
    "\n",
    "        if(max_p == 0 and max_t==0):\n",
    "            pauli_symbol = inp\n",
    "            return paulis_list[pauli_symbol] \n",
    "\n",
    "        elif max_p==0:\n",
    "            return compute_t(inp)\n",
    "        else: \n",
    "            to_add = inp.split(p_str)\n",
    "            #print(\"Split by \", p_str, \"; len to_add \",len(to_add), \":\\n\", to_add)\n",
    "            running_sum = empty_array_of_same_dim(to_add[0])\n",
    "            for i in range(len(to_add)):\n",
    "                max_p, p_str = find_max_letter(to_add[i], \"P\")\n",
    "                max_t, t_str = find_max_letter(to_add[i], \"T\")\n",
    "\n",
    "               # print(\"To add [i=\", i, \"]:\", to_add[i] )\n",
    "                rhs = compute(to_add[i])\n",
    "                #print(\"SUM shape:\", np.shape(running_sum))\n",
    "                #print(\"RHS shape:\", np.shape(rhs))\n",
    "                running_sum += rhs\n",
    "\n",
    "            #print(\"RESULT \", p_str, \" : \", inp, \": \\n\", running_sum)\n",
    "            return running_sum\n",
    "\n",
    "    def compute(inp):\n",
    "        #print(\"Computing \", inp)\n",
    "        max_p, p_str = find_max_letter(inp, \"P\")\n",
    "        max_t, t_str = find_max_letter(inp, \"T\")\n",
    "\n",
    "        if(max_p == 0 and max_t==0):\n",
    "            pauli_symbol = inp\n",
    "            return paulis_list[pauli_symbol] \n",
    "\n",
    "        elif max_t >= max_p:\n",
    "           # print(\"Max t=\", max_t, \">= max p=\", max_p)\n",
    "            return compute_t(inp)\n",
    "        else:\n",
    "            return compute_p(inp)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_t_p_strings(name):\n",
    "    t_str = ''\n",
    "    p_str = ''\n",
    "    while name.count(t_str+'T')>0:\n",
    "        t_str=t_str+'T'\n",
    "\n",
    "    while name.count(p_str+'P')>0:\n",
    "        p_str=p_str+'P'\n",
    "\n",
    "    max_t = len(t_str)\n",
    "    max_p = len(p_str)\n",
    "\n",
    "    return t_str, p_str, max_t, max_p        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_t_p_strings('xPxPxTTy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen1 = operator('yTxPPzTi')\n",
    "gen2 = operator('xTyPPyTiTTiTyPPxTiPPPxTyPPyTiTTiTyPPxTi')\n",
    "gen3 = operator('xTy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen1.constituents_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gen1.operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = 'xPyTzTTyPPPiTiPyTTz'\n",
    "res_fnc=compute(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=x+y\n",
    "b=np.kron(a,z)\n",
    "c=np.kron(b,y)\n",
    "d=i+y\n",
    "e= np.kron(i,d)\n",
    "f=np.kron(e,z)\n",
    "res = c+f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.abs(res-res_fnc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen3.constituents_operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(ls[2]):\n",
    "    print(\"this\")\n",
    "else:\n",
    "    print(\"that\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generators_list = [gen1, gen2, gen3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_test = Init_N_Qubit_DB(generators=generators_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Idea for N qubit DB initialisation\n",
    "def Init_N_Qubit_DB(RootN_Qbit=[0], N_Qubits=1, generators = paulilist):\n",
    "    # if N_qubits defined: work out generator list.\n",
    "    # Or should number qubits be implied by gen list?\n",
    "    db = pd.DataFrame({\n",
    "        '<Name>' : [   [gen.name] for gen in generators], \n",
    "        'N_Qbit' : [RootN_Qbit for i in range(len(generators))],\n",
    "        'N_params' : [ gen.num_constituents for gen in generators ],\n",
    "        'Num_Qubits' : [ gen.num_qubits for gen in generators ],\n",
    "        'Status' : 'Ready', \n",
    "        'Selected' : False, \n",
    "        'LogL_Ext' : None, \n",
    "        'QML_Class' : None, \n",
    "        'Origin_epoch' : 0, \n",
    "        'RootNode' : 'NaN',\n",
    "        'All_Operators_Names': [gen.constituents_names for gen in generators],\n",
    "        'All_Operators_Matrices': [gen.constituents_operators for gen in generators]\n",
    "        })  \n",
    "        \n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitialiseDB(RootN_Qbit = [0]):\n",
    "    db = pd.DataFrame({\n",
    "        '<Name>' : [   [spinname+str(RootN_Qbit[0])] for spinname in spinnames], \n",
    "        'N_Qbit' : [RootN_Qbit for i in range(len(spinnames))],\n",
    "        'N_params' : 1, \n",
    "        'Status' : 'Ready', \n",
    "        'Selected' : False, \n",
    "        'LogL_Ext' : None, \n",
    "        'QML_Class' : None, \n",
    "        'Origin_epoch' : 0, \n",
    "        'RootNode' : 'NaN',\n",
    "        'All_Operators': list(map(lambda j: np.array([evo.paulilist()[j]]) , \n",
    "                        range(  len(evo.paulilist())  ))) \n",
    "        })  \n",
    "        \n",
    "    return db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='xPyPzPiTxPyPzPiPPxPyPzPiTxPyPzPi'\n",
    "num_levels_p = len(p_str)\n",
    "num_terms=1+name.count(p_str)\n",
    "p_array = np.empty([num_levels_p, num_terms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_1p(inp):\n",
    "    to_add = inp.split(\"P\")\n",
    "    running_sum = empty_array_of_same_dim(inp)\n",
    "    for i in range(len(to_add)):\n",
    "        pauli_symbol = to_add[i]\n",
    "        rhs = paulis_list[pauli_symbol]\n",
    "        running_sum += rhs\n",
    "    return running_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_1t(inp):\n",
    "    to_tens = inp.split(\"T\")\n",
    "    for i in range(len(to_tens)):\n",
    "        to_tens[i] = compute_1p(to_tens[i])\n",
    "    \n",
    "    running_tens_prod = to_tens[0]\n",
    "    for i in range(1,len(to_tens)):\n",
    "        running_tens_prod = np.kron(running_tens_prod, to_tens[i])\n",
    "    return running_tens_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_1p('xPy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_p('xTy',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_t('xTx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = evo.sigmax()\n",
    "y = evo.sigmay()\n",
    "z = evo.sigmaz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_letter(string, letter):\n",
    "    letter_str=''\n",
    "    while string.count(letter_str+letter)>0:\n",
    "        letter_str=letter_str+letter\n",
    "\n",
    "    return len(letter_str), letter_str\n",
    "\n",
    "\n",
    "def empty_array_of_same_dim(name):\n",
    "    t_str=''\n",
    "    while name.count(t_str+'T')>0:\n",
    "        t_str=t_str+'T'\n",
    "\n",
    "    num_qubits = len(t_str) +1\n",
    "    dim = 2**num_qubits\n",
    "    #print(\"String: \", name, \" has NQubits: \", num_qubits)\n",
    "    empty_mtx = np.zeros([dim, dim], dtype=np.complex128)\n",
    "    return empty_mtx\n",
    "\n",
    "def compute_t(inp):\n",
    "   # print(\"Compute t : \", inp)\n",
    "    max_t, t_str = find_max_letter(inp, \"T\")\n",
    "    max_p, p_str = find_max_letter(inp, \"P\")\n",
    "\n",
    "    if(max_p == 0 and max_t==0):\n",
    "        pauli_symbol = inp\n",
    "        return paulis_list[pauli_symbol] \n",
    "    \n",
    "    elif(max_t==0):\n",
    "        return compute(inp)\n",
    "    else:\n",
    "        to_tens = inp.split(t_str)\n",
    "        running_tens_prod=compute(to_tens[0])\n",
    "        #print(\"Split by \", t_str, \" : \\n\", to_tens)\n",
    "        for i in range(1,len(to_tens)):\n",
    "            max_p, p_str = find_max_letter(to_tens[i], \"P\")\n",
    "            max_t, t_str = find_max_letter(to_tens[i], \"T\")\n",
    "            #print(\"To tens [i=\", i, \"]:\\n\", to_tens[i] )\n",
    "            rhs = compute(to_tens[i])\n",
    "            running_tens_prod = np.kron(running_tens_prod, rhs)\n",
    "        #print(\"RESULT \", t_str, \" : \", inp, \": \\n\", running_tens_prod)\n",
    "        return running_tens_prod\n",
    "\n",
    "def compute_p(inp):\n",
    "    #print(\"Compute p : \", inp)\n",
    "    max_p, p_str = find_max_letter(inp, \"P\")\n",
    "    max_t, t_str = find_max_letter(inp, \"T\")\n",
    "    \n",
    "    if(max_p == 0 and max_t==0):\n",
    "        pauli_symbol = inp\n",
    "        return paulis_list[pauli_symbol] \n",
    "\n",
    "    elif max_p==0:\n",
    "        return compute_t(inp)\n",
    "    else: \n",
    "        to_add = inp.split(p_str)\n",
    "        #print(\"Split by \", p_str, \"; len to_add \",len(to_add), \":\\n\", to_add)\n",
    "        running_sum = empty_array_of_same_dim(to_add[0])\n",
    "        for i in range(len(to_add)):\n",
    "            max_p, p_str = find_max_letter(to_add[i], \"P\")\n",
    "            max_t, t_str = find_max_letter(to_add[i], \"T\")\n",
    "\n",
    "           # print(\"To add [i=\", i, \"]:\", to_add[i] )\n",
    "            rhs = compute(to_add[i])\n",
    "            #print(\"SUM shape:\", np.shape(running_sum))\n",
    "            #print(\"RHS shape:\", np.shape(rhs))\n",
    "            running_sum += rhs\n",
    "\n",
    "        #print(\"RESULT \", p_str, \" : \", inp, \": \\n\", running_sum)\n",
    "        return running_sum\n",
    "\n",
    "def compute(inp):\n",
    "    #print(\"Computing \", inp)\n",
    "    max_p, p_str = find_max_letter(inp, \"P\")\n",
    "    max_t, t_str = find_max_letter(inp, \"T\")\n",
    "    \n",
    "    if(max_p == 0 and max_t==0):\n",
    "        pauli_symbol = inp\n",
    "        return paulis_list[pauli_symbol] \n",
    "    \n",
    "    elif max_t >= max_p:\n",
    "       # print(\"Max t=\", max_t, \">= max p=\", max_p)\n",
    "        return compute_t(inp)\n",
    "    else:\n",
    "        return compute_p(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h='xPyTzPPzPxTy'\n",
    "ham=compute(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=x+y\n",
    "b=np.kron(a,z)\n",
    "c=x+z\n",
    "d=np.kron(c,y)\n",
    "ham1=b+d\n",
    "print(np.max(np.abs(ham1-ham)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.shape(operator_from_string('xTyPPyTzTTz'))\n",
    "#np.shape(operator_from_string('xPyTiTTzPx'))\n",
    "compute('xPyPiPzTiTTzPxPi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(compute('xTyTTTzTi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =np.kron(np.kron(x,y), np.kron(z,i))\n",
    "d = compute('xTyTTTzTi')\n",
    "print(np.max(np.abs(a-d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.kron(x+y, y+y) + np.kron(x+y, y+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.kron(np.kron(y,i), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=operator_from_string('yTiTz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.abs(a-b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=operator_from_string('iPiTiTTz')\n",
    "\n",
    "np.shape(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = 'xPyTzPiTTyPzPPyTiTTz'\n",
    "operator_from_string(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhs=operator_from_string('iTyTTzTx')\n",
    "i=np.identity(2, dtype=np.complex128)\n",
    "c=np.kron(i,y)\n",
    "d=np.kron(z,x)\n",
    "rhs_real=np.kron(c,d)\n",
    "diff = np.max(np.abs(rhs-rhs_real))\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=operator_from_string('xTzPPzTyTTxTz')\n",
    "np.shape(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.kron(x,z) + np.kron(z,y)\n",
    "b=np.kron(x,z)\n",
    "out_actual=np.kron(a,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.abs(out-out_actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_p('xPy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_t('xPyTx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_2p(inp):\n",
    "    #print(\"Computing (2p)\", inp)\n",
    "    to_add = inp.split(\"PP\")\n",
    "    running_sum = empty_array_of_same_dim(inp)\n",
    "    for i in range(len(to_add)):\n",
    "        rhs = compute_1t(to_add[i])\n",
    "        print(\"Adding \\n\", running_sum, \"\\n TO string \", to_add[i], \" \\n\", rhs)\n",
    "        running_sum += rhs\n",
    "    \n",
    "    #print(\"RESULT: \", inp, \": \\n\", running_sum)\n",
    "    return running_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_2t(inp):\n",
    "#    print(\"Computing (2t)\", inp)\n",
    "    to_tens = inp.split(\"TT\")\n",
    "    running_tens_prod=compute_2p(to_tens[0])\n",
    "    for i in range(1,len(to_tens)):\n",
    "\n",
    " #       print(\"tensor product bw \\n\", running_tens_prod, \"\\n AND \", to_tens[i], \" \\n\", compute_2p(to_tens[i]))\n",
    "        running_tens_prod = np.kron(running_tens_prod, compute_2p(to_tens[i]))\n",
    "  #  print(\"RESULT (2t) [shape : \", np.shape(running_tens_prod), \"] \\n\",running_tens_prod )\n",
    "    return running_tens_prod        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_t('xTy', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to=compute_2p('xPzTxPPxTx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1=compute_2t('xTyTTyTz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xty = np.kron(evo.sigmax(), evo.sigmay())\n",
    "ytz = np.kron(evo.sigmay(), evo.sigmaz())\n",
    "out = np.kron(xty, ytz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.abs(out - out1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_str, p_str, max_t, max_p = get_t_p_strings(name)\n",
    "constit_names = name.split(p_str)\n",
    "ind_ops = list()\n",
    "\n",
    "for i in range(len(constit_names)):\n",
    "    ind_ops.append(constit_names[i].split(t_str))\n",
    "op_list = list()\n",
    "for j in range(len(ind_ops)):\n",
    "    running_sum = evo.sigmax() - evo.sigmax()\n",
    "    print(\"op \", j)\n",
    "    for k in range(len(ind_ops[j])):\n",
    "        print(\"k=\", k)\n",
    "        op_name = ind_ops[j][k][0]\n",
    "        op = paulis_list[op_name]\n",
    "        running_sum += op\n",
    "    op_list.append(running_sum)\n",
    "\n",
    "\n",
    "running_kron_prod = op_list[0]\n",
    "for j in range(1,len(op_list)):\n",
    "    running_kron_prod = np.kron(running_kron_prod, op_list[j])\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
