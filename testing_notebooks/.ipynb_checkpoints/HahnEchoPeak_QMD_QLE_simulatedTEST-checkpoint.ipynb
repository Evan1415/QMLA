{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QMD class testing\n",
    "## for the QLE algorithm, reproducing Hahn-echo dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import qinfer as qi\n",
    "import qutip as qt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import math as mth\n",
    "from IPython.display import display, Math, Latex\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os as os\n",
    "import time as time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import importlib as imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging as logging\n",
    "import warnings as warnings\n",
    "import sys\n",
    "\n",
    "%run LoggingCode.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Local Function for Hamiltonian learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add personalized library to PYTHONPATH\n",
    "sys.path.append(os.path.join(\"..\",\"Libraries\",\"QML_lib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Norms import *\n",
    "from IOfuncts import *\n",
    "from EvalLoss import *\n",
    "\n",
    "import Distrib as dist\n",
    "import ProbeStates as pros\n",
    "import multiPGH as mpgh\n",
    "import HahnSimQMD as gsi\n",
    "import Evo as evo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" filter only the Weight Clipping warning \"\"\"\n",
    "#SET LEVEL WARNINGS TO 0 In FINAL VERSION\n",
    "warnings.filterwarnings(\"ignore\", message='Negative weights occured', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Model learning functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Utils as uti\n",
    "import Models as mods\n",
    "import BayesF as bayf\n",
    "import ModLearn as mdl\n",
    "import QMD_Hahn as qmd\n",
    "import QML_Hahn as qml\n",
    "import QMD_Utils as quti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'QML_Hahn' from '..\\\\Libraries\\\\QML_lib\\\\QML_Hahn.py'>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(pros)\n",
    "imp.reload(dist)\n",
    "imp.reload(mpgh)\n",
    "imp.reload(gsi)\n",
    "imp.reload(evo)\n",
    "imp.reload(mdl)\n",
    "imp.reload(uti)\n",
    "imp.reload(mods)\n",
    "imp.reload(bayf)\n",
    "imp.reload(qmd)\n",
    "imp.reload(quti)\n",
    "imp.reload(qml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL LEARNING TEST\n",
    "\n",
    "## Simulated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spinlst = [evo.sigmax(), evo.sigmay(), evo.sigmaz()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eoplist = list(map(lambda j: np.kron(spinlst[j],np.eye(2)) , range(len(spinlst))))\n",
    "\n",
    "HFoplist = list(map(lambda j: np.kron(spinlst[j],spinlst[j]), range(len(spinlst))))\n",
    "bathoplist = list(map(lambda j: np.kron(np.eye(2),spinlst[j]) , range(len(spinlst))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TwoQlist = []\n",
    "TwoQlist.extend(HFoplist)\n",
    "TwoQlist.extend(bathoplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TwoQsample = []\n",
    "TwoQsample.append(HFoplist[0])\n",
    "TwoQsample.append(HFoplist[2])\n",
    "TwoQsample.append(bathoplist[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HahnTestingList = [np.array([eoplist[2]]), np.array([HFoplist[1]]), \n",
    "                   np.array(eoplist), np.array(HFoplist), np.array(TwoQsample), \n",
    "                   np.array(TwoQlist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allnameslist = ['1q_1p', '1q_full', '2qHF_1p', '2qHF_full', '2q_advanced', '2q_full']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch the learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2q_full\n"
     ]
    }
   ],
   "source": [
    "modeltest = qmd.ModelsDevelopmentClass(HahnTestingList, allnameslist, checkloss=True, gaussian = False, trotter=False, IQLE=False)\n",
    "\n",
    "\n",
    "print(modeltest.TrueNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization Ready\n",
      "Initialization Ready\n",
      "Initialization Ready\n",
      "Initialization Ready\n",
      "Initialization Ready\n",
      "Initialization Ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\Libraries\\QML_lib\\QMD_Hahn.py:128: UserWarning: Did you adopt the corrct 'pr0fromHahn' definition???!!!\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "modeltest.InitialiseAllActiveModels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelNames: ['1q_1p', '1q_full', '2qHF_1p', '2qHF_full', '2q_advanced', '2q_full']\n"
     ]
    }
   ],
   "source": [
    "print('ModelNames: ' + repr(modeltest.ModelNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.49895015, -2.42472382, -1.86953559,  4.72654829, -2.45428031,\n",
       "        -0.57291543]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeltest.TrueParamsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial time selected > 6.99865570586\n",
      "Final time selected > 2.55007448177\n",
      "Final Parameters mean and stdev:[-0.12194346  0.22463484]\n",
      "Batch single time 0 elapsed time: 62.36506475130591\n",
      "\n",
      "\n",
      "Initial time selected > 3.72843011274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0017582417582417628. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0010730436115582128. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.004830593760483069. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0008580008580008578. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0016785212228027078. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.01651287032540068. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\utils.py:268: ApproximationWarning: Numerical error in covariance estimation causing positive semidefinite violation.\n",
      "  warnings.warn('Numerical error in covariance estimation causing positive semidefinite violation.', ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0017913121361397232. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0018305007182172958. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final time selected > 2.20141674454\n",
      "Final Parameters mean and stdev:[ 0.76294117  0.17241754]\n",
      "Batch single time 1 elapsed time: 57.56392532163591\n",
      "\n",
      "\n",
      "Initial time selected > 0.630932207048\n",
      "Final time selected > 1.131345152\n",
      "Final Parameters mean and stdev:[ 0.94749196  0.25087069]\n",
      "Final Parameters mean and stdev:[ 0.13423003  0.23549052]\n",
      "Final Parameters mean and stdev:[ 0.49877075  0.1013926 ]\n",
      "Batch single time 2 elapsed time: 54.181303991150344\n",
      "\n",
      "\n",
      "Initial time selected > 2.30271332236\n",
      "Final time selected > 1.5716137534\n",
      "Final Parameters mean and stdev:[-2.80922142  0.21136595]\n",
      "Final Parameters mean and stdev:[-4.30927345  0.18291659]\n",
      "Final Parameters mean and stdev:[-1.03262022  0.04156296]\n",
      "Batch single time 3 elapsed time: 56.575986696829204\n",
      "\n",
      "\n",
      "Initial time selected > 1.09599672543\n",
      "Final time selected > 1.33582670268\n",
      "Final Parameters mean and stdev:[-4.804321    0.21760752]\n",
      "Final Parameters mean and stdev:[-2.0924452   0.18944295]\n",
      "Final Parameters mean and stdev:[ 7.42583636  0.20981463]\n",
      "Batch single time 4 elapsed time: 57.85178641305538\n",
      "\n",
      "\n",
      "Initial time selected > 0.0989021388633\n",
      "Final time selected > 0.113124098679\n",
      "Final Parameters mean and stdev:[-2.72710218  0.19836583]\n",
      "Final Parameters mean and stdev:[-2.65382515  0.20946531]\n",
      "Final Parameters mean and stdev:[-1.94175186  0.17314285]\n",
      "Final Parameters mean and stdev:[ 3.05829919  2.07535206]\n",
      "Final Parameters mean and stdev:[ 0.05750671  1.94998478]\n",
      "Final Parameters mean and stdev:[-1.06988884  1.97419395]\n",
      "Batch single time 5 elapsed time: 55.0109566402316\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0008965275566599555. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -3.0006078879084014e-05. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:285: ApproximationWarning: Extremely small n_ess encountered (9.16903796258049). Resampling is likely to fail. Consider adding particles, or resampling more often.\n",
      "  ApproximationWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New LogTotLikelihoods update! Elapsed time : 682.1310363983212\n",
      "Total elapsed time: 1025.6804899236377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:285: ApproximationWarning: Extremely small n_ess encountered (6.827285312895417). Resampling is likely to fail. Consider adding particles, or resampling more often.\n",
      "  ApproximationWarning\n"
     ]
    }
   ],
   "source": [
    "start=time.clock()\n",
    "modeltest.UpdateAllActiveModels(expnum=50)\n",
    "modeltest.UpdateAllLogLikelihoods(datalikesize=20)\n",
    "end=time.clock()\n",
    "print('Total elapsed time: ' + str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1q_1p VS 1q_full': 3.747896827531684e+272,\n",
       " '1q_1p VS 2qHF_1p': 9.6367358537463588e-14,\n",
       " '1q_1p VS 2qHF_full': 5.0908521970906523e+30,\n",
       " '1q_1p VS 2q_advanced': 3.9523939676655573e-14,\n",
       " '1q_1p VS 2q_full': 0.0,\n",
       " '1q_full VS 1q_1p': 0.0,\n",
       " '1q_full VS 2qHF_1p': 0.0,\n",
       " '1q_full VS 2qHF_full': 0.0,\n",
       " '1q_full VS 2q_advanced': 0.0,\n",
       " '1q_full VS 2q_full': 0.0,\n",
       " '2qHF_1p VS 1q_1p': 10379528527357.596,\n",
       " '2qHF_1p VS 1q_full': 3.8901402038959256e+285,\n",
       " '2qHF_1p VS 2qHF_full': 5.2840645608263524e+43,\n",
       " '2qHF_1p VS 2q_advanced': 0.41021562197565142,\n",
       " '2qHF_1p VS 2q_full': 4.5393739878107908e-09,\n",
       " '2qHF_full VS 1q_1p': 0.0,\n",
       " '2qHF_full VS 1q_full': 7.3620224717458093e+241,\n",
       " '2qHF_full VS 2qHF_1p': 0.0,\n",
       " '2qHF_full VS 2q_advanced': 0.0,\n",
       " '2qHF_full VS 2q_full': 0.0,\n",
       " '2q_advanced VS 1q_1p': 25302616407850.207,\n",
       " '2q_advanced VS 1q_full': 9.4831595763238314e+285,\n",
       " '2q_advanced VS 2qHF_1p': 2.4377423638423878,\n",
       " '2q_advanced VS 2qHF_full': 1.2881188033204622e+44,\n",
       " '2q_advanced VS 2q_full': 1.1065824256917267e-08,\n",
       " '2q_full VS 1q_1p': 2.2865550495709497e+21,\n",
       " '2q_full VS 1q_full': 8.5697724162633928e+293,\n",
       " '2q_full VS 2qHF_1p': 220294692.91829744,\n",
       " '2q_full VS 2qHF_full': 1.1640513797876995e+52,\n",
       " '2q_full VS 2q_advanced': 90368324.473414525}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeltest.ComputeAllBayesFactors(fromLogL = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAFkCAYAAACq4KjhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc200c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(modeltest.ModelsList[5].TrackTime)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULTIPLE testing running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remember to adopt the corrct 'pr0fromHahn' definition!!!\n",
      "Initialization Ready\n",
      "Remember to adopt the corrct 'pr0fromHahn' definition!!!\n",
      "Initialization Ready\n",
      "Remember to adopt the corrct 'pr0fromHahn' definition!!!\n",
      "Initialization Ready\n",
      "Remember to adopt the corrct 'pr0fromHahn' definition!!!\n",
      "Initialization Ready\n",
      "Remember to adopt the corrct 'pr0fromHahn' definition!!!\n",
      "Initialization Ready\n",
      "Remember to adopt the corrct 'pr0fromHahn' definition!!!\n",
      "Initialization Ready\n",
      "Initial time selected > 2.41341870378\n",
      "Final time selected > 0.935086134316\n",
      "Final Parameters mean and stdev:[ 0.05048016  0.20570339]\n",
      "Batch single time 0 elapsed time: 34.66650478012525\n",
      "\n",
      "\n",
      "Initial time selected > 10.0650582324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0017566974088713226. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0012517602879048657. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0008029118938015197. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0008449514152936209. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0033406726900007556. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final time selected > 3.72591134139\n",
      "Final Parameters mean and stdev:[ 0.19090293  0.20603459]\n",
      "Batch single time 1 elapsed time: 30.796699964310392\n",
      "\n",
      "\n",
      "Initial time selected > 1.3852050493\n",
      "Final time selected > 0.921537928137\n",
      "Final Parameters mean and stdev:[ 0.38249923  0.16703861]\n",
      "Final Parameters mean and stdev:[ 0.36289034  0.21180432]\n",
      "Final Parameters mean and stdev:[ 0.36024619  0.10362666]\n",
      "Batch single time 2 elapsed time: 31.008563765088184\n",
      "\n",
      "\n",
      "Initial time selected > 1.11443949146\n",
      "Final time selected > 0.740096142291\n",
      "Final Parameters mean and stdev:[-0.51781324  0.10791671]\n",
      "Final Parameters mean and stdev:[-1.28857901  0.19299798]\n",
      "Final Parameters mean and stdev:[-0.30196688  0.11348328]\n",
      "Batch single time 3 elapsed time: 31.89598673655928\n",
      "\n",
      "\n",
      "Initial time selected > 1.09486946133\n",
      "Final time selected > 1.18884967519\n",
      "Final Parameters mean and stdev:[-2.21962925  0.1912256 ]\n",
      "Final Parameters mean and stdev:[-3.70678054  0.22011428]\n",
      "Final Parameters mean and stdev:[ 17.47385854   0.12940038]\n",
      "Batch single time 4 elapsed time: 33.896300577958755\n",
      "\n",
      "\n",
      "Initial time selected > 0.0702770492689\n",
      "Final time selected > 0.187435202828\n",
      "Final Parameters mean and stdev:[-2.55467004  0.1922327 ]\n",
      "Final Parameters mean and stdev:[-2.66583356  0.20061269]\n",
      "Final Parameters mean and stdev:[-2.02929171  0.19969878]\n",
      "Final Parameters mean and stdev:[ 0.04161358  1.8782348 ]\n",
      "Final Parameters mean and stdev:[ 0.6777683   2.09830903]\n",
      "Final Parameters mean and stdev:[-1.66474017  2.00522895]\n",
      "Batch single time 5 elapsed time: 31.027083387132734\n",
      "\n",
      "\n",
      "LogTotLikelihoods updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0020110608345902466. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0012010409021151634. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.003595602158295212. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0047842763293860285. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.001127470089617142. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0002583371436068669. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0039170393384580235. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.00019097650582048615. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.007186397092951677. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.020353833220590624. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -4.443990667301909e-05. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0001687486167772501. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogTotLikelihoods updated\n",
      "LogTotLikelihoods updated\n",
      "LogTotLikelihoods updated\n",
      "LogTotLikelihoods updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:285: ApproximationWarning: Extremely small n_ess encountered (1.8982919560755904). Resampling is likely to fail. Consider adding particles, or resampling more often.\n",
      "  ApproximationWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogTotLikelihoods updated\n",
      "New Bayes Factor update! Total elapsed time : 642.902543638189\n",
      "Total elapsed time for the learning process: 836.1937692550637\n",
      "Remember to adopt the corrct 'pr0fromHahn' definition!!!\n",
      "Initialization Ready\n",
      "Remember to adopt the corrct 'pr0fromHahn' definition!!!\n",
      "Initialization Ready\n",
      "Remember to adopt the corrct 'pr0fromHahn' definition!!!\n",
      "Initialization Ready\n",
      "Remember to adopt the corrct 'pr0fromHahn' definition!!!\n",
      "Initialization Ready\n",
      "Remember to adopt the corrct 'pr0fromHahn' definition!!!\n",
      "Initialization Ready\n",
      "Remember to adopt the corrct 'pr0fromHahn' definition!!!\n",
      "Initialization Ready\n",
      "Initial time selected > 0.512288206986\n",
      "Final time selected > 5.64653352863\n",
      "Final Parameters mean and stdev:[ 1.30677073  0.09778671]\n",
      "Batch single time 0 elapsed time: 37.7923541878954\n",
      "\n",
      "\n",
      "Initial time selected > 1.62185837362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0009250693802035154. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.00190885230255309. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0015065913370998125. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0008920606601248884. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.001498913287866297. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0012109744560075656. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0032857910659340925. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0008722197993894463. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.001817906377821542. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final time selected > 3.76129519366\n",
      "Final Parameters mean and stdev:[ 0.09764909  0.22248065]\n",
      "Batch single time 1 elapsed time: 30.334869103640813\n",
      "\n",
      "\n",
      "Initial time selected > 2.1934895542\n",
      "Final time selected > 4.37411501689\n",
      "Final Parameters mean and stdev:[ 0.76632739  0.19042724]\n",
      "Final Parameters mean and stdev:[ 0.28275456  0.20414136]\n",
      "Final Parameters mean and stdev:[ 0.49310226  0.12009348]\n",
      "Batch single time 2 elapsed time: 31.08851320616668\n",
      "\n",
      "\n",
      "Initial time selected > 1.86557893742\n",
      "Final time selected > 0.962891042974\n",
      "Final Parameters mean and stdev:[-2.58782184  0.16285544]\n",
      "Final Parameters mean and stdev:[-2.59187995  0.40614142]\n",
      "Final Parameters mean and stdev:[-0.4587507   0.06823079]\n",
      "Batch single time 3 elapsed time: 32.83835413360066\n",
      "\n",
      "\n",
      "Initial time selected > 2.22397214344\n",
      "Final time selected > 2.04495313531\n",
      "Final Parameters mean and stdev:[-2.67055782  0.17542796]\n",
      "Final Parameters mean and stdev:[-3.99715955  0.17421419]\n",
      "Final Parameters mean and stdev:[ 4.02011338  0.16469554]\n",
      "Batch single time 4 elapsed time: 33.38096770413176\n",
      "\n",
      "\n",
      "Initial time selected > 0.126345198339\n",
      "Final time selected > 0.0636668273206\n",
      "Final Parameters mean and stdev:[-2.55258948  0.2252561 ]\n",
      "Final Parameters mean and stdev:[-2.64601959  0.1793011 ]\n",
      "Final Parameters mean and stdev:[-2.20709479  0.19209332]\n",
      "Final Parameters mean and stdev:[ 2.67229785  2.01708771]\n",
      "Final Parameters mean and stdev:[-0.1166846   1.36351615]\n",
      "Final Parameters mean and stdev:[-2.68296415  2.41506858]\n",
      "Batch single time 5 elapsed time: 31.092704048223823\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:285: ApproximationWarning: Extremely small n_ess encountered (1.00000084421266). Resampling is likely to fail. Consider adding particles, or resampling more often.\n",
      "  ApproximationWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogTotLikelihoods updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0034328318180599135. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.003044762770163226. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.001967181354498748. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.000961273086043328. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0032369120004021147. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.009675142003165382. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0012150385756666837. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0028331179459623428. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0011105603060992376. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -2.2881784408977537e-05. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.005369724160883233. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.002326203614735731. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -3.317601972229599e-06. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.015260063722972088. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:285: ApproximationWarning: Extremely small n_ess encountered (7.164434277720616). Resampling is likely to fail. Consider adding particles, or resampling more often.\n",
      "  ApproximationWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogTotLikelihoods updated\n",
      "LogTotLikelihoods updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:285: ApproximationWarning: Extremely small n_ess encountered (3.7604647957221693). Resampling is likely to fail. Consider adding particles, or resampling more often.\n",
      "  ApproximationWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogTotLikelihoods updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:285: ApproximationWarning: Extremely small n_ess encountered (2.9135135552162583). Resampling is likely to fail. Consider adding particles, or resampling more often.\n",
      "  ApproximationWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogTotLikelihoods updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:285: ApproximationWarning: Extremely small n_ess encountered (3.604655762903452). Resampling is likely to fail. Consider adding particles, or resampling more often.\n",
      "  ApproximationWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogTotLikelihoods updated\n",
      "New Bayes Factor update! Total elapsed time : 653.067177950059\n",
      "Total elapsed time for the learning process: 849.5950221046332\n",
      "Remember to adopt the corrct 'pr0fromHahn' definition!!!\n",
      "Initialization Ready\n",
      "Remember to adopt the corrct 'pr0fromHahn' definition!!!\n",
      "Initialization Ready\n",
      "Remember to adopt the corrct 'pr0fromHahn' definition!!!\n",
      "Initialization Ready\n",
      "Remember to adopt the corrct 'pr0fromHahn' definition!!!\n",
      "Initialization Ready\n",
      "Remember to adopt the corrct 'pr0fromHahn' definition!!!\n",
      "Initialization Ready\n",
      "Remember to adopt the corrct 'pr0fromHahn' definition!!!\n",
      "Initialization Ready\n",
      "Initial time selected > 0.279742522898\n",
      "Final time selected > 1.03795968794\n",
      "Final Parameters mean and stdev:[ 0.00924443  0.32442466]\n",
      "Batch single time 0 elapsed time: 34.45650383330212\n",
      "\n",
      "\n",
      "Initial time selected > 2.09269504773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0016799664006719838. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0018005851901868103. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0009207749856128911. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0017331022530329319. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0015384615384615393. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final time selected > 3.56437309346\n",
      "Final Parameters mean and stdev:[ 0.40959475  0.19658513]\n",
      "Batch single time 1 elapsed time: 30.79647617023511\n",
      "\n",
      "\n",
      "Initial time selected > 1.23897432236\n",
      "Final time selected > 1.04616810122\n",
      "Final Parameters mean and stdev:[ 0.66526552  0.18851002]\n",
      "Final Parameters mean and stdev:[ 0.79060697  0.15162356]\n",
      "Final Parameters mean and stdev:[ 0.70963358  0.12664771]\n",
      "Batch single time 2 elapsed time: 31.02008187685351\n",
      "\n",
      "\n",
      "Initial time selected > 0.86864181026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:285: ApproximationWarning: Extremely small n_ess encountered (8.192072187180722). Resampling is likely to fail. Consider adding particles, or resampling more often.\n",
      "  ApproximationWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final time selected > 8.58711927908\n",
      "Final Parameters mean and stdev:[-1.81777268  0.0327559 ]\n",
      "Final Parameters mean and stdev:[-3.13111602  0.05577567]\n",
      "Final Parameters mean and stdev:[-3.35520099  0.11299985]\n",
      "Batch single time 3 elapsed time: 33.33376536184005\n",
      "\n",
      "\n",
      "Initial time selected > 0.963306155358\n",
      "Final time selected > 0.830285084068\n",
      "Final Parameters mean and stdev:[-1.75371822  0.21193589]\n",
      "Final Parameters mean and stdev:[-1.96744588  0.25020225]\n",
      "Final Parameters mean and stdev:[ 11.14658638   0.24062527]\n",
      "Batch single time 4 elapsed time: 33.35156758482117\n",
      "\n",
      "\n",
      "Initial time selected > 0.131419499139\n",
      "Final time selected > 0.0937407564957\n",
      "Final Parameters mean and stdev:[-2.83001195  0.20617545]\n",
      "Final Parameters mean and stdev:[-2.68617475  0.20645901]\n",
      "Final Parameters mean and stdev:[-1.99707809  0.1926878 ]\n",
      "Final Parameters mean and stdev:[ 3.97135324  1.90666702]\n",
      "Final Parameters mean and stdev:[-0.38649963  1.86836976]\n",
      "Final Parameters mean and stdev:[-0.39501084  1.87489527]\n",
      "Batch single time 5 elapsed time: 31.08454384079596\n",
      "\n",
      "\n",
      "LogTotLikelihoods updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0014938910526596512. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.00010847972446149888. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0002543676755210555. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.00022741082851754216. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -5.120433244643124e-05. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0026453844314430677. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0001316457606188322. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0006238486399030939. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.000656705901510451. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogTotLikelihoods updated\n",
      "LogTotLikelihoods updated\n",
      "LogTotLikelihoods updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:285: ApproximationWarning: Extremely small n_ess encountered (8.197086982955351). Resampling is likely to fail. Consider adding particles, or resampling more often.\n",
      "  ApproximationWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogTotLikelihoods updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:285: ApproximationWarning: Extremely small n_ess encountered (4.9742390447074465). Resampling is likely to fail. Consider adding particles, or resampling more often.\n",
      "  ApproximationWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogTotLikelihoods updated\n",
      "New Bayes Factor update! Total elapsed time : 654.0373001164662\n",
      "Total elapsed time for the learning process: 848.0803195620538\n",
      "Remember to adopt the corrct 'pr0fromHahn' definition!!!\n",
      "Initialization Ready\n",
      "Remember to adopt the corrct 'pr0fromHahn' definition!!!\n",
      "Initialization Ready\n",
      "Remember to adopt the corrct 'pr0fromHahn' definition!!!\n",
      "Initialization Ready\n",
      "Remember to adopt the corrct 'pr0fromHahn' definition!!!\n",
      "Initialization Ready\n",
      "Remember to adopt the corrct 'pr0fromHahn' definition!!!\n",
      "Initialization Ready\n",
      "Remember to adopt the corrct 'pr0fromHahn' definition!!!\n",
      "Initialization Ready\n",
      "Initial time selected > 1.95823965042\n",
      "Final time selected > 0.994554330146\n",
      "Final Parameters mean and stdev:[ 1.12341189  0.28763173]\n",
      "Batch single time 0 elapsed time: 37.76560847822111\n",
      "\n",
      "\n",
      "Initial time selected > 3.01772166218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0008547008547008544. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.01008064516129032. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.001866716445771887. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0025717959708529805. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.0004684937924572498. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.003291278113000546. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.03918872464764523. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\utils.py:268: ApproximationWarning: Numerical error in covariance estimation causing positive semidefinite violation.\n",
      "  warnings.warn('Numerical error in covariance estimation causing positive semidefinite violation.', ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -0.06361520558572537. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:285: ApproximationWarning: Extremely small n_ess encountered (4.85863211423124). Resampling is likely to fail. Consider adding particles, or resampling more often.\n",
      "  ApproximationWarning\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py:429: ApproximationWarning: Negative weights occured in particle approximation. Smallest weight observed == -3.2684613058664934e-18. Clipping weights.\n",
      "  warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "All particle weights are zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-e87ea42e3d45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mmodeltest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUpdateAllActiveModels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpnum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_expnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Total elapsed time for the learning process: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ag15141\\Local Documents\\Cloud\\Dropbox (Qsim)\\QML_share_stateofart\\QMD\\Libraries\\QML_lib\\QMD_Hahn.py\u001b[0m in \u001b[0;36mUpdateAllActiveModels\u001b[0;34m(self, expnum, sigma_threshold, datalikesize)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModelsList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModelsList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUpdateModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_experiments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexpnum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msigma_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msigma_threshold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcheckloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ag15141\\Local Documents\\Cloud\\Dropbox (Qsim)\\QML_share_stateofart\\QMD\\Libraries\\QML_lib\\QML_Hahn.py\u001b[0m in \u001b[0;36mUpdateModel\u001b[0;34m(self, n_experiments, sigma_threshold, checkloss)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[1;31m#print(str(self.GenSimModel.ProbeState))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUpdater\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExperiment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExperiment\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\qinfer\\smc.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, outcome, expparams, check_for_resample)\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All particle weights are zero. This will very likely fail quite badly.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mApproximationWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_zero_weight_policy\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'error'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All particle weights are zero.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_zero_weight_policy\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'reset'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All particle weights are zero. Resetting from initial prior.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mApproximationWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: All particle weights are zero."
     ]
    }
   ],
   "source": [
    "nruns = 10\n",
    "pool_len = 20\n",
    "max_expnum = 30\n",
    "\n",
    "collectTrueOpList = []\n",
    "collectTrueNames = []\n",
    "collectTrueParams = []\n",
    "\n",
    "collectEstimParams = []\n",
    "\n",
    "collectKfactorsDict = []\n",
    "collectLogL = []\n",
    "\n",
    "\n",
    "for run in range(nruns):\n",
    "    modeltest = qmd.ModelsDevelopmentClass(HahnTestingList, allnameslist, checkloss=True, gaussian = False, trotter=False, IQLE=False)\n",
    "    collectTrueNames.append(modeltest.TrueNames)\n",
    "    \n",
    "    modeltest.InitialiseAllActiveModels()\n",
    "    \n",
    "    collectTrueParams.append(modeltest.TrueParamsList)\n",
    "    \n",
    "    start=time.clock()\n",
    "    modeltest.UpdateAllActiveModels(expnum=max_expnum)\n",
    "    end=time.clock()\n",
    "    print('Total elapsed time for the learning process: ' + str(end-start))\n",
    "    \n",
    "    collectEstimParams.append([modeltest.ModelsList[i].NewEval for i in range(len(modeltest.ModelsList)) ])\n",
    "    \n",
    "    collectKfactorsDict.append(modeltest.ComputeAllBayesFactors(fromLogL = True))\n",
    "    \n",
    "    collectLogL.append([modeltest.ModelsList[i].KLogTotLikelihood for i in range(len(modeltest.ModelsList)) ])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-70.276623257074107,\n",
       "  -629.99902254401024,\n",
       "  -54.257107987785588,\n",
       "  -75.391614846988929,\n",
       "  -82.429335491594884,\n",
       "  -44.136259552682247],\n",
       " [-144.99761516022195,\n",
       "  -874.48948543902429,\n",
       "  -76.25821743334599,\n",
       "  -105.79005129461859,\n",
       "  -79.70901238685434,\n",
       "  -62.385424071412437],\n",
       " [-120.95883470604647,\n",
       "  -524.74200851584305,\n",
       "  -62.889659490003879,\n",
       "  -118.38672451838589,\n",
       "  -92.45151456616864,\n",
       "  -48.513353610330952]]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collectLogL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "PIK = \"testQMD_QLE_epochs\"+str(max_expnum)+\"pool\"+str(pool_len)+\".dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [collectTrueOpList, collectTrueNames, collectTrueParams, collectEstimParams, collectKfactorsDict, collectLogL]\n",
    "with open(PIK, \"wb\") as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(PIK, \"rb\") as f:\n",
    "    dataold = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall results \n",
    "#### applying directly the champion rule as the highest BayesFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myModelNames = modeltest.ModelNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2q_full'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myModelNames[np.argmax(np.array(collectLogL[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(collectKfactorsDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly estimated model in 100.0% of cases\n"
     ]
    }
   ],
   "source": [
    "performance = []\n",
    "for ids in range(3):\n",
    "    performance.append(collectTrueNames[ids]==myModelNames[np.argmax(np.array(collectLogL[ids]))])\n",
    "print(\"Correctly estimated model in \" + str(100*sum(performance)/len(performance)) + \"% of cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collectTrueNames[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-42.884404946492481, -123.75660364127944, -48.750543625361544]"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collectLogL[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check against tournament rule among Bayes Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  0.,  2.,  0.,  3.,  0.,  4.,  0.,  5.,  0.,  6.,  1.,\n",
       "        0.,  1.,  2.,  1.,  3.,  1.,  4.,  1.,  5.,  1.,  6.,  2.,  0.,\n",
       "        2.,  1.,  2.,  3.,  2.,  4.,  2.,  5.,  2.,  6.,  3.,  0.,  3.,\n",
       "        1.,  3.,  2.,  3.,  4.,  3.,  5.,  3.,  6.,  4.,  0.,  4.,  1.,\n",
       "        4.,  2.,  4.,  3.,  4.,  5.,  4.,  6.,  5.,  0.,  5.,  1.,  5.,\n",
       "        2.,  5.,  3.,  5.,  4.,  5.,  6.,  6.,  0.,  6.,  1.,  6.,  2.,\n",
       "        6.,  3.,  6.,  4.,  6.,  5.])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prooutlst = bayf.getProLst(len(modeltest.AvailableModsOpList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly estimated model in 63.0% of cases\n"
     ]
    }
   ],
   "source": [
    "performance = []\n",
    "for ids in range(100):\n",
    "    performance.append(collectTrueNames[ids][0]== ChampbyTourn(myModelNames, collectLogL[ids]) )\n",
    "print(\"Correctly estimated model in \" + str(100*sum(performance)/len(performance)) + \"% of cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1op</th>\n",
       "      <th>2op</th>\n",
       "      <th>3op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Failure Rate</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Failed with 1 extra operator</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Failed with 1 less operator</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              1op  2op  3op\n",
       "Failure Rate                  0.0  0.0  0.0\n",
       "Failed with 1 extra operator  0.0  0.0  0.0\n",
       "Failed with 1 less operator   0.0  0.0  0.0"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "perf_metrics=[\"Failure Rate\", \"Failed with 1 extra operator\", \"Failed with 1 less operator\"]\n",
    "n_ops = [\"1op\", \"2op\", \"3op\"]\n",
    "output_df = pd.DataFrame(np.zeros([len(perf_metrics),len(n_ops)],dtype='float32'), index=perf_metrics, columns=n_ops)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sx_</th>\n",
       "      <th>sy_</th>\n",
       "      <th>sz_</th>\n",
       "      <th>sy_sx_</th>\n",
       "      <th>sz_sx_</th>\n",
       "      <th>sy_sz_</th>\n",
       "      <th>sy_sz_sx_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sx_</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sy_</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sz_</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sy_sx_</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sz_sx_</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sy_sz_</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sy_sz_sx_</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sx_  sy_  sz_  sy_sx_  sz_sx_  sy_sz_  sy_sz_sx_\n",
       "sx_        0.0  0.0  0.0     0.0     0.0     0.0        0.0\n",
       "sy_        0.0  0.0  0.0     0.0     0.0     0.0        0.0\n",
       "sz_        0.0  0.0  0.0     0.0     0.0     0.0        0.0\n",
       "sy_sx_     0.0  0.0  0.0     0.0     0.0     0.0        0.0\n",
       "sz_sx_     0.0  0.0  0.0     0.0     0.0     0.0        0.0\n",
       "sy_sz_     0.0  0.0  0.0     0.0     0.0     0.0        0.0\n",
       "sy_sz_sx_  0.0  0.0  0.0     0.0     0.0     0.0        0.0"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_mods = myModelNames\n",
    "est_mods = myModelNames\n",
    "detail_df = pd.DataFrame(np.zeros([len(est_mods),len(true_mods)],dtype='float32'), index=true_mods, columns=est_mods)\n",
    "detail_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True model: sy_sz_sx_\tbut estimated model: sy_sx_\n",
      "True model: sy_sz_sx_\tbut estimated model: sx_\n",
      "True model: sy_sz_sx_\tbut estimated model: sy_sx_\n",
      "True model: sx_\tbut estimated model: sz_sx_\n",
      "True model: sy_sz_\tbut estimated model: sy_sz_sx_\n",
      "True model: sz_\tbut estimated model: sy_sz_\n",
      "True model: sy_sz_sx_\tbut estimated model: sz_sx_\n",
      "True model: sy_sz_sx_\tbut estimated model: sy_sz_\n",
      "True model: sx_\tbut estimated model: sz_sx_\n",
      "True model: sy_sx_\tbut estimated model: sy_sz_sx_\n",
      "True model: sy_sx_\tbut estimated model: sy_sz_sx_\n",
      "True model: sy_sz_sx_\tbut estimated model: sy_sz_\n",
      "True model: sy_sx_\tbut estimated model: sy_sz_sx_\n",
      "True model: sy_sz_sx_\tbut estimated model: sx_\n",
      "True model: sy_sx_\tbut estimated model: sy_sz_sx_\n",
      "True model: sz_sx_\tbut estimated model: sy_sz_sx_\n",
      "True model: sx_\tbut estimated model: sy_sx_\n",
      "True model: sz_\tbut estimated model: sy_sz_\n",
      "True model: sy_sz_sx_\tbut estimated model: sx_\n",
      "True model: sx_\tbut estimated model: sz_sx_\n",
      "True model: sy_sz_sx_\tbut estimated model: sy_sz_\n",
      "True model: sy_sz_sx_\tbut estimated model: sz_sx_\n",
      "True model: sy_sz_sx_\tbut estimated model: sx_\n",
      "True model: sz_sx_\tbut estimated model: sy_sz_\n",
      "True model: sy_sx_\tbut estimated model: sx_\n",
      "True model: sy_sz_sx_\tbut estimated model: sy_sx_\n",
      "True model: sx_\tbut estimated model: sz_sx_\n",
      "True model: sy_sz_sx_\tbut estimated model: sy_sx_\n",
      "True model: sz_sx_\tbut estimated model: sy_sz_sx_\n",
      "True model: sy_sz_sx_\tbut estimated model: sx_\n",
      "True model: sy_sz_sx_\tbut estimated model: sy_\n",
      "True model: sx_\tbut estimated model: sz_sx_\n",
      "True model: sy_sz_sx_\tbut estimated model: sy_sx_\n",
      "True model: sy_sz_sx_\tbut estimated model: sz_\n",
      "True model: sy_sx_\tbut estimated model: sy_sz_\n",
      "True model: sy_sz_sx_\tbut estimated model: sz_sx_\n",
      "True model: sy_sz_sx_\tbut estimated model: sy_sx_\n"
     ]
    }
   ],
   "source": [
    "length_test_mods = []\n",
    "length_fail_mods = []\n",
    "more_complex_fails = []\n",
    "model_lengths = 3\n",
    "\n",
    "for ids in range(100):\n",
    "    est_name = str(myModelNames[np.argmax(np.array(collectLogL[ids]))])\n",
    "    true_name = str(collectTrueNames[ids][0])\n",
    "    est_ops = est_name.split(\"_\")[0:-1]\n",
    "    true_ops = true_name.split(\"_\")[0:-1]\n",
    "    length_test_mods.append(int(len(true_name)/model_lengths))\n",
    "    \n",
    "    detail_df.loc[true_name, est_name] += 1\n",
    "    \n",
    "    if true_name != est_name:\n",
    "        length_fail_mods.append(int(len(true_name)/model_lengths))\n",
    "        \n",
    "        if (set(est_ops)>set(true_ops)) and (len(est_ops)==len(true_ops)+1):\n",
    "            output_df.loc[\"Failed with 1 extra operator\",str(length_fail_mods[-1])+\"op\"] += 1\n",
    "            \n",
    "        if (set(true_ops)>set(est_ops)) and (len(true_ops)==len(est_ops)+1):\n",
    "            output_df.loc[\"Failed with 1 less operator\",str(length_fail_mods[-1])+\"op\"] += 1\n",
    "        \n",
    "        print(\"True model: \" + true_name + \n",
    "              #\"\\twith True params: \" + str(collectTrueParams[ids]) +\n",
    "              \"\\tbut estimated model: \" + est_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for mod_len in range(3):\n",
    "    opstep = str(mod_len+1)+\"op\"\n",
    "    rate = length_fail_mods.count(mod_len+1)\n",
    "    output_df[opstep][0] = rate\n",
    "    output_df[opstep][:] /= length_test_mods.count(mod_len+1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1op</th>\n",
       "      <th>2op</th>\n",
       "      <th>3op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Failure Rate</th>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.59375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Failed with 1 extra operator</th>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Failed with 1 less operator</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.37500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   1op       2op      3op\n",
       "Failure Rate                  0.242424  0.285714  0.59375\n",
       "Failed with 1 extra operator  0.242424  0.200000  0.00000\n",
       "Failed with 1 less operator   0.000000  0.028571  0.37500"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sx_</th>\n",
       "      <th>sy_</th>\n",
       "      <th>sz_</th>\n",
       "      <th>sy_sx_</th>\n",
       "      <th>sz_sx_</th>\n",
       "      <th>sy_sz_</th>\n",
       "      <th>sy_sz_sx_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sx_</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sy_</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sz_</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sy_sx_</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sz_sx_</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sy_sz_</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sy_sz_sx_</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sx_   sy_  sz_  sy_sx_  sz_sx_  sy_sz_  sy_sz_sx_\n",
       "sx_        4.0   0.0  0.0     1.0     5.0     0.0        0.0\n",
       "sy_        0.0  14.0  0.0     0.0     0.0     0.0        0.0\n",
       "sz_        0.0   0.0  7.0     0.0     0.0     2.0        0.0\n",
       "sy_sx_     1.0   0.0  0.0     7.0     0.0     1.0        4.0\n",
       "sz_sx_     0.0   0.0  0.0     0.0     6.0     1.0        2.0\n",
       "sy_sz_     0.0   0.0  0.0     0.0     0.0    12.0        1.0\n",
       "sy_sz_sx_  5.0   1.0  1.0     6.0     3.0     3.0       13.0"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-step checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True model: 'sz_sx_'\n"
     ]
    }
   ],
   "source": [
    "ids = 0\n",
    "print(\"True model: \" + repr(collectTrueNames[ids][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found by Likelihood Max: 'sz_sx_'\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model found by Likelihood Max: \" + repr(myModelNames[np.argmax(np.array(collectLogL[ids]))]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found by Tournament: 'sz_sx_'\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model found by Tournament: \" + repr(ChampbyTourn(myModelNames, collectLogL[ids])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.51707507,  0.29320623]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collectTrueParams[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.03783763]),\n",
       " array([-0.2476092]),\n",
       " array([ 0.09036134]),\n",
       " array([ 0.31792165,  0.04013711]),\n",
       " array([ 0.82316908,  0.51020887]),\n",
       " array([-0.34350552,  0.28836693]),\n",
       " array([ 0.53932834, -0.17918401,  0.95925429])]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collectEstimParams[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.29320623+0.j,  0.51707507+0.j],\n",
       "       [ 0.51707507+0.j, -0.29320623+0.j]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evo.getH(collectTrueParams[ids], collectTrueOpList[ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-400.41067247020612,\n",
       " -425.74206272176707,\n",
       " -1031.3307759135796,\n",
       " -231.21195917491445,\n",
       " -135.32523752936802,\n",
       " -362.08848718087978,\n",
       " -336.58109053962932]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collectLogL[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"['sx_']VS['sy_']\": 100295859666.0164,\n",
       " \"['sx_']VS['sy_sx_']\": 0.0,\n",
       " \"['sx_']VS['sy_sz_']\": 0.0,\n",
       " \"['sx_']VS['sy_sz_sx_']\": 0.0,\n",
       " \"['sx_']VS['sz_']\": 1.0118577148488023e+274,\n",
       " \"['sx_']VS['sz_sx_']\": 0.0,\n",
       " \"['sy_']VS['sx_']\": 9.9704688949486808e-12,\n",
       " \"['sy_']VS['sy_sx_']\": 0.0,\n",
       " \"['sy_']VS['sy_sz_']\": 0.0,\n",
       " \"['sy_']VS['sy_sz_sx_']\": 0.0,\n",
       " \"['sy_']VS['sz_']\": 1.0088728669541018e+263,\n",
       " \"['sy_']VS['sz_sx_']\": 0.0,\n",
       " \"['sy_sx_']VS['sx_']\": 3.0343629663868174e+73,\n",
       " \"['sy_sx_']VS['sy_']\": 3.0433404225248947e+84,\n",
       " \"['sy_sx_']VS['sy_sz_']\": 6.901665769238503e+56,\n",
       " \"['sy_sx_']VS['sy_sz_sx_']\": 5.7707507227335888e+45,\n",
       " \"['sy_sx_']VS['sz_']\": inf,\n",
       " \"['sy_sx_']VS['sz_sx_']\": 0.0,\n",
       " \"['sy_sz_']VS['sx_']\": 43965660868587880.0,\n",
       " \"['sy_sz_']VS['sy_']\": 4.409573752599559e+27,\n",
       " \"['sy_sz_']VS['sy_sx_']\": 0.0,\n",
       " \"['sy_sz_']VS['sy_sz_sx_']\": 8.3614226653594415e-12,\n",
       " \"['sy_sz_']VS['sz_']\": 4.4486993138304217e+290,\n",
       " \"['sy_sz_']VS['sz_sx_']\": 0.0,\n",
       " \"['sy_sz_sx_']VS['sx_']\": 5.2581771630389327e+27,\n",
       " \"['sy_sz_sx_']VS['sy_']\": 5.2737339884320509e+38,\n",
       " \"['sy_sz_sx_']VS['sy_sx_']\": 0.0,\n",
       " \"['sy_sz_sx_']VS['sy_sz_']\": 119597364378.42879,\n",
       " \"['sy_sz_sx_']VS['sz_']\": 5.3205271284630354e+301,\n",
       " \"['sy_sz_sx_']VS['sz_sx_']\": 0.0,\n",
       " \"['sz_']VS['sx_']\": 0.0,\n",
       " \"['sz_']VS['sy_']\": 0.0,\n",
       " \"['sz_']VS['sy_sx_']\": 0.0,\n",
       " \"['sz_']VS['sy_sz_']\": 0.0,\n",
       " \"['sz_']VS['sy_sz_sx_']\": 0.0,\n",
       " \"['sz_']VS['sz_sx_']\": 0.0,\n",
       " \"['sz_sx_']VS['sx_']\": 1.3339563776185255e+115,\n",
       " \"['sz_sx_']VS['sy_']\": 1.3379030165021522e+126,\n",
       " \"['sz_sx_']VS['sy_sx_']\": 4.3961661554514114e+41,\n",
       " \"['sz_sx_']VS['sy_sz_']\": 3.0340869470963843e+98,\n",
       " \"['sz_sx_']VS['sy_sz_sx_']\": 2.5369179018828174e+87,\n",
       " \"['sz_sx_']VS['sz_']\": inf}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collectKfactorsDict[ids]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
