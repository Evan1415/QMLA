In RUN script:  -agr hopping_probabilistic -agr ising_probabilistic16:1:12 [GLOBAL VARIABLES] use_experimental_data : True
16:1:12 [GLOBAL VARIABLES] growth_generation_rule : two_qubit_ising_rotation_hyperfine_transverse
16:1:12 [GLOBAL VARIABLES] growth_class : <NVCentreExperimentGrowthRules.nv_centre_spin_experimental_method object at 0x2aaabfb15cc0>
16:1:12 [GLOBAL VARIABLES] measurement_type : hahn_evolution
16:1:12 [GLOBAL VARIABLES] dataset : NVB_rescale_dataset.p
16:1:12 [GLOBAL VARIABLES] alternative_growth_rules : []
16:1:12 [GLOBAL VARIABLES] multiQHL : False
16:1:12 [GLOBAL VARIABLES] models_for_qhl : []
16:1:12 [GLOBAL VARIABLES] prior_pickle_file : /panfs/panasas01/phys/bf16951/QMD/ParallelDevelopment/Results/Aug_21/15_59/prior.p
16:1:12 [GLOBAL VARIABLES] true_params_pickle_file : /panfs/panasas01/phys/bf16951/QMD/ParallelDevelopment/Results/Aug_21/15_59/true_params.p
16:1:12 [GLOBAL VARIABLES] true_operator : xTiPPxTxPPyTiPPyTyPPzTiPPzTz
16:1:12 [GLOBAL VARIABLES] true_op_name : xTiPPxTxPPyTiPPyTyPPzTiPPzTz
16:1:12 [GLOBAL VARIABLES] true_operator_class : <DataBase.operator object at 0x2aaae055c0f0>
16:1:12 [GLOBAL VARIABLES] true_op_list : [array([[ 0.+0.j,  0.+0.j,  1.+0.j,  0.+0.j],
       [ 0.+0.j,  0.+0.j,  0.+0.j,  1.+0.j],
       [ 1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],
       [ 0.+0.j,  1.+0.j,  0.+0.j,  0.+0.j]]), array([[ 0.+0.j,  0.+0.j,  0.+0.j,  1.+0.j],
       [ 0.+0.j,  0.+0.j,  1.+0.j,  0.+0.j],
       [ 0.+0.j,  1.+0.j,  0.+0.j,  0.+0.j],
       [ 1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j]]), array([[ 0.+0.j,  0.+0.j,  0.-1.j,  0.+0.j],
       [ 0.+0.j,  0.+0.j,  0.+0.j,  0.-1.j],
       [ 0.+1.j,  0.+0.j,  0.+0.j,  0.+0.j],
       [ 0.+0.j,  0.+1.j,  0.+0.j,  0.+0.j]]), array([[ 0.+0.j,  0.+0.j,  0.+0.j, -1.-0.j],
       [ 0.+0.j,  0.+0.j,  1.+0.j,  0.+0.j],
       [ 0.+0.j,  1.+0.j,  0.+0.j,  0.+0.j],
       [-1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j]]), array([[ 1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],
       [ 0.+0.j,  1.+0.j,  0.+0.j,  0.+0.j],
       [ 0.+0.j,  0.+0.j, -1.+0.j, -0.+0.j],
       [ 0.+0.j,  0.+0.j, -0.+0.j, -1.+0.j]]), array([[ 1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],
       [ 0.+0.j, -1.+0.j,  0.+0.j, -0.+0.j],
       [ 0.+0.j,  0.+0.j, -1.+0.j, -0.+0.j],
       [ 0.+0.j, -0.+0.j, -0.+0.j,  1.-0.j]])]
16:1:12 [GLOBAL VARIABLES] true_params : []
16:1:12 [GLOBAL VARIABLES] true_params_dict : None
16:1:12 [GLOBAL VARIABLES] true_params_list : []
16:1:12 [GLOBAL VARIABLES] true_hamiltonian : None
16:1:12 [GLOBAL VARIABLES] qhl_test : False
16:1:12 [GLOBAL VARIABLES] further_qhl : False
16:1:12 [GLOBAL VARIABLES] do_iqle : False
16:1:12 [GLOBAL VARIABLES] do_qle : True
16:1:12 [GLOBAL VARIABLES] use_rq : True
16:1:12 [GLOBAL VARIABLES] num_runs : 1
16:1:12 [GLOBAL VARIABLES] num_tests : 1
16:1:12 [GLOBAL VARIABLES] num_qubits : 2
16:1:12 [GLOBAL VARIABLES] num_parameters : 2
16:1:12 [GLOBAL VARIABLES] num_experiments : 750
16:1:12 [GLOBAL VARIABLES] num_particles : 2500
16:1:12 [GLOBAL VARIABLES] num_times_bayes : 750
16:1:12 [GLOBAL VARIABLES] bayes_lower : 1
16:1:12 [GLOBAL VARIABLES] bayes_upper : 100
16:1:12 [GLOBAL VARIABLES] save_plots : False
16:1:12 [GLOBAL VARIABLES] store_particles_weights : False
16:1:12 [GLOBAL VARIABLES] gaussian : True
16:1:12 [GLOBAL VARIABLES] custom_prior : True
16:1:12 [GLOBAL VARIABLES] resample_threshold : 0.5
16:1:12 [GLOBAL VARIABLES] resample_a : 0.98
16:1:12 [GLOBAL VARIABLES] pgh_factor : 1.0
16:1:12 [GLOBAL VARIABLES] pgh_exponent : 1.0
16:1:12 [GLOBAL VARIABLES] increase_pgh_time : False
16:1:12 [GLOBAL VARIABLES] pickle_qmd_class : True
16:1:12 [GLOBAL VARIABLES] qmd_id : 8
16:1:12 [GLOBAL VARIABLES] host_name : node36-004
16:1:12 [GLOBAL VARIABLES] port_number : 6308
16:1:12 [GLOBAL VARIABLES] results_directory : /panfs/panasas01/phys/bf16951/QMD/ParallelDevelopment/Results/Aug_21/15_59/
16:1:12 [GLOBAL VARIABLES] rq_timeout : 200000
16:1:12 [GLOBAL VARIABLES] log_file : /panfs/panasas01/phys/bf16951/QMD/ParallelDevelopment/Results/Aug_21/15_59/logs/experimental_run_for_single_instance_tree_8.qmd.8644314.log
16:1:12 [GLOBAL VARIABLES] cumulative_csv : /panfs/panasas01/phys/bf16951/QMD/ParallelDevelopment/Results/Aug_21/15_59/cumulative.csv
16:1:12 [GLOBAL VARIABLES] data_time_offset : 180
16:1:12 [GLOBAL VARIABLES] data_max_time : 15
16:1:12 [GLOBAL VARIABLES] true_expec_path : /panfs/panasas01/phys/bf16951/QMD/ParallelDevelopment/Results/Aug_21/15_59/true_expec_vals.p
16:1:12 [GLOBAL VARIABLES] plot_probe_file : /panfs/panasas01/phys/bf16951/QMD/ParallelDevelopment/Results/Aug_21/15_59/plot_probes.p
16:1:12 [GLOBAL VARIABLES] special_probe : dec_13_exp
16:1:12 [GLOBAL VARIABLES] latex_mapping_file : /panfs/panasas01/phys/bf16951/QMD/ParallelDevelopment/Results/Aug_21/15_59/LatexMapping.txt
16:1:12 [GLOBAL VARIABLES] reallocate_resources : False
16:1:12 [GLOBAL VARIABLES] param_min : 0.0
16:1:12 [GLOBAL VARIABLES] param_max : 10.0
16:1:12 [GLOBAL VARIABLES] param_mean : 0.5
16:1:12 [GLOBAL VARIABLES] param_sigma : 2.0
16:1:12 [GLOBAL VARIABLES] bayes_time_binning : True
16:1:12 [GLOBAL VARIABLES] bayes_factors_use_all_exp_times : False
16:1:12 [GLOBAL VARIABLES] num_probes : 40
16:1:12 [GLOBAL VARIABLES] probe_noise_level : 0.001
16:1:12 [GLOBAL VARIABLES] updater_from_prior : False
16:1:12 [GLOBAL VARIABLES] plots_directory : /panfs/panasas01/phys/bf16951/QMD/ParallelDevelopment/Results/Aug_21/15_59/plots/
16:1:12 [GLOBAL VARIABLES] long_id : 008
16:1:12 [GLOBAL VARIABLES] results_file : /panfs/panasas01/phys/bf16951/QMD/ParallelDevelopment/Results/Aug_21/15_59/results_008.p
16:1:12 [GLOBAL VARIABLES] class_pickle_file : /panfs/panasas01/phys/bf16951/QMD/ParallelDevelopment/Results/Aug_21/15_59/qmd_class_008.p
16:1:13 [EXP] Prior specific terms: {'xTi': [4.0, 1.5], 'yTi': [4.0, 1.5], 'zTi': [4.0, 1.5], 'xTx': [4.0, 1.5], 'yTy': [4.0, 1.5], 'zTz': [4.0, 1.5], 'xTy': [4.0, 1.5], 'xTz': [4.0, 1.5], 'yTz': [4.0, 1.5]}
16:1:13 [EXP] 
 QMD id 8  on host  node36-004 and port 6308 has seed 1 
 2500  particles for 750 experiments and  750 bayes updates
 Gaussian= True 
 RQ= True RQ log: /panfs/panasas01/phys/bf16951/QMD/ParallelDevelopment/Results/Aug_21/15_59/logs/experimental_run_for_single_instance_tree_8.qmd.8644314.log 
 Bayes CSV: /panfs/panasas01/phys/bf16951/QMD/ParallelDevelopment/Results/Aug_21/15_59/cumulative.csv
16:1:13 [EXP] Generators: ['two_qubit_ising_rotation_hyperfine_transverse']
16:1:13 [QMD 8] Probe dict provided to QMD.
16:1:13 [QMD 8] generator list after ensuring true generator is first: ['two_qubit_ising_rotation_hyperfine_transverse']
16:1:13 [QMD 8] initialising generator two_qubit_ising_rotation_hyperfine_transverse with models: ['xTi', 'yTi', 'zTi']
16:1:13 [QMD 8] xTi not added yet. List: []
16:1:13 [QMD 8] yTi not added yet. List: ['xTi']
16:1:13 [QMD 8] zTi not added yet. List: ['xTi', 'yTi']
16:1:13 [QMD 8] After setting up initial branches, highest branch id: 0 highest model id: 3 initial models: {}
16:1:13 [QMD 8] Retrieving databases from redis
16:1:13 [QMD 8] any job failed db: [b'Status'] Status: b'0'
16:1:13 [QMD 8] Initial op list: ['xTi', 'yTi', 'zTi']
16:1:13 [QMD 8] Specific terms for prior {'xTi': [4.0, 1.5], 'yTi': [4.0, 1.5], 'zTi': [4.0, 1.5], 'xTx': [4.0, 1.5], 'yTy': [4.0, 1.5], 'zTz': [4.0, 1.5], 'xTy': [4.0, 1.5], 'xTz': [4.0, 1.5], 'yTz': [4.0, 1.5]}
16:1:13 [QMD 8] RunParallel= True
16:1:13 [QMD 8] Saving qmd info db to  StrictRedis<ConnectionPool<Connection<host=node36-004,port=6308,db=1>>>
16:1:13 [QMD 8] Running  QLE  for true operator  xTiPPxTxPPyTiPPyTyPPzTiPPzTz  with parameters :  []
16:1:13 [DB] Model  xTi  not previously considered -- adding.
16:1:13 [DB] Model  yTi  not previously considered -- adding.
16:1:13 [DB] Model  zTi  not previously considered -- adding.
16:1:13 [QMD 8] After initiating DB, models: {0: 'xTi', 1: 'yTi', 2: 'zTi'}
16:1:13 [QMD 8] learnModelFromBranchID branch 0 : ['xTi', 'yTi', 'zTi']
16:1:13 [QMD 8] learnModelFromBranchID. Setting active branches on redis for branch 0 to 0
16:1:13 [QMD 8] branch 0 precomputed: []
16:1:13 [QMD 8] Branch  0 has unlearned models: ['xTi', 'zTi', 'yTi']
16:1:13 [QMD 8] Model  xTi being passed to learnModel function
16:1:13 [QMD 8] Model xTi added to queue.
16:1:13 [QMD 8] Model  zTi being passed to learnModel function
16:1:13 [QMD 8] Model zTi added to queue.
16:1:13 [QMD 8] Model  yTi being passed to learnModel function
16:1:13 [QMD 8] Model yTi added to queue.
16:1:13 [QMD 8] learnModelFromBranchID finished, branch 0
16:1:13 [QMD 8] Entering while loop of spawning/comparing.
16:1:18 [QML 0] QML for  xTi
16:1:18 [QML 0] Getting prior for model: xTi Specific terms: {'xTi': [4.0, 1.5], 'yTi': [4.0, 1.5], 'zTi': [4.0, 1.5], 'xTx': [4.0, 1.5], 'yTy': [4.0, 1.5], 'zTz': [4.0, 1.5], 'xTy': [4.0, 1.5], 'xTz': [4.0, 1.5], 'yTz': [4.0, 1.5]}
16:1:18 [QML 0] Normal Prior 
Means: [ 4.] 
Cov mtx: [[ 2.25]] 
Samples: [[ 5.92891298]
 [ 3.72860724]
 [ 6.12450206]
 [ 4.19705936]
 [ 5.21207431]
 [ 3.59276399]
 [ 2.71375304]
 [ 2.53716627]
 [ 5.791152  ]
 [ 2.70211076]]
16:1:18 [GenSim (QML 0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
16:1:18 [QML 0] Initialization Ready
16:1:18 [RQ Learn 0.0] Time to unpickle and initialise QML class: 0.21030139923095703
16:1:18 [RQ Learn 0.0] Updating model.
16:1:18 [QML 0] Experiment 0
16:1:18 [QML 0] Initial time selected >  1.45
16:1:18 [QML 1] QML for  yTi
16:1:18 [QML 2] QML for  zTi
16:1:19 [QML 1] Getting prior for model: yTi Specific terms: {'xTi': [4.0, 1.5], 'yTi': [4.0, 1.5], 'zTi': [4.0, 1.5], 'xTx': [4.0, 1.5], 'yTy': [4.0, 1.5], 'zTz': [4.0, 1.5], 'xTy': [4.0, 1.5], 'xTz': [4.0, 1.5], 'yTz': [4.0, 1.5]}
16:1:19 [QML 2] Getting prior for model: zTi Specific terms: {'xTi': [4.0, 1.5], 'yTi': [4.0, 1.5], 'zTi': [4.0, 1.5], 'xTx': [4.0, 1.5], 'yTy': [4.0, 1.5], 'zTz': [4.0, 1.5], 'xTy': [4.0, 1.5], 'xTz': [4.0, 1.5], 'yTz': [4.0, 1.5]}
16:1:19 [QML 1] Normal Prior 
Means: [ 4.] 
Cov mtx: [[ 2.25]] 
Samples: [[ 3.90080935]
 [ 3.72321257]
 [-0.12559892]
 [ 4.16265644]
 [ 4.4633624 ]
 [ 4.4134622 ]
 [ 4.32648553]
 [ 1.72295904]
 [ 5.79238993]
 [ 1.92910821]]
16:1:19 [QML 2] Normal Prior 
Means: [ 4.] 
Cov mtx: [[ 2.25]] 
Samples: [[ 1.2361463 ]
 [ 3.22981484]
 [ 0.99124112]
 [ 3.45601659]
 [ 3.43212193]
 [ 5.03838388]
 [ 6.12320034]
 [ 3.54192824]
 [ 4.33774793]
 [ 5.92302664]]
16:1:19 [GenSim (QML 1)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
16:1:19 [QML 1] Initialization Ready
16:1:19 [RQ Learn 1.0] Time to unpickle and initialise QML class: 0.3005545139312744
16:1:19 [RQ Learn 1.0] Updating model.
16:1:19 [QML 1] Experiment 0
16:1:19 [GenSim (QML 2)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
16:1:19 [QML 1] Initial time selected >  1.91
16:1:19 [QML 2] Initialization Ready
16:1:19 [RQ Learn 2.0] Time to unpickle and initialise QML class: 0.3193349838256836
16:1:19 [RQ Learn 2.0] Updating model.
16:1:19 [QML 2] Experiment 0
16:1:19 [QML 2] Initial time selected >  2.02
16:3:40 [QML 1] Experiment 75
16:3:44 [QML 0] Experiment 75
16:4:18 [QML 2] Experiment 75
16:6:4 [QML 1] Experiment 150
16:6:8 [QML 0] Experiment 150
16:7:25 [QML 2] Experiment 150
16:8:29 [QML 1] Experiment 225
16:8:33 [QML 0] Experiment 225
16:10:40 [QML 2] Experiment 225
16:10:55 [QML 1] Experiment 300
16:10:56 [QML 0] Experiment 300
16:13:16 [QML 0] Experiment 375
16:13:21 [QML 1] Experiment 375
16:13:46 [QML 2] Experiment 300
16:15:40 [QML 0] Experiment 450
16:15:41 [QML 1] Experiment 450
16:16:59 [QML 2] Experiment 375
16:18:1 [QML 0] Experiment 525
16:18:6 [QML 1] Experiment 525
16:20:6 [QML 2] Experiment 450
16:20:33 [QML 0] Experiment 600
16:20:33 [QML 1] Experiment 600
16:22:41 [QML 2] Experiment 525
16:23:1 [QML 1] Experiment 675
16:23:1 [QML 0] Experiment 675
16:25:29 [QML 1] Results for QHL on  yTi
16:25:29 [QML 1] Final time selected > 3.24
16:25:29 [QML 1] Cumulative time.	 Datum: 0.11855554580688477 	 Update: 1449.8876695632935
16:25:29 [QML 1] Final Parameters mean and stdev (term  yTi ): [  6.41895886e+00   2.12685626e-03]
16:25:29 [RQ Learn 1.0] Time for update alone: 1450.797120809555
16:25:30 [RQ Learn 1.0] Redis learned_models_info added to db for model: 1.0
16:25:30 [RQ Learn 1.0] Redis SET learned_models_ids: 1.0 ; set True
16:25:30 [RQ Learn 1.0] Learned. rq time: 1451.2175045013428
16:25:31 [QML 0] Results for QHL on  xTi
16:25:31 [QML 0] Final time selected > 3.24
16:25:31 [QML 0] Cumulative time.	 Datum: 0.12739920616149902 	 Update: 1451.6947095394135
16:25:31 [QML 0] Final Parameters mean and stdev (term  xTi ): [ 4.06642139  1.49002841]
16:25:31 [RQ Learn 0.0] Time for update alone: 1452.6358015537262
16:25:31 [RQ Learn 0.0] Redis learned_models_info added to db for model: 0.0
16:25:31 [RQ Learn 0.0] Redis SET learned_models_ids: 0.0 ; set True
16:25:31 [RQ Learn 0.0] Learned. rq time: 1452.9616122245789
16:25:56 [QML 2] Experiment 600
16:29:13 [QML 2] Experiment 675
16:32:33 [QML 2] Results for QHL on  zTi
16:32:33 [QML 2] Final time selected > 3.24
16:32:33 [QML 2] Cumulative time.	 Datum: 0.11956095695495605 	 Update: 1873.3788893222809
16:32:33 [QML 2] Final Parameters mean and stdev (term  zTi ): [  2.15314366e+00   1.08052246e-03]
16:32:33 [RQ Learn 2.0] Time for update alone: 1874.287470817566
16:32:33 [RQ Learn 2.0] Redis learned_models_info added to db for model: 2.0
16:32:33 [RQ Learn 2.0] Redis SET learned_models_ids: 2.0 ; set True
16:32:33 [QMD 8] All models on branch 0 have finished learning.
16:32:33 [RQ Learn 2.0] Learned. rq time: 1874.7261896133423
16:32:33 [QMD 8] remoteBayesFromBranchID 0 model id list: [0, 1, 2]
16:32:33 [QMD 8] Computing BF for pair 0,1
16:32:33 [QMD 8] Bayes factor calculation queued. Model IDs 0 1
16:32:33 [QMD 8] Computing BF for pair 0,2
16:32:33 [QMD 8] Bayes factor calculation queued. Model IDs 0 2
16:32:33 [QMD 8] Computing BF for pair 1,2
16:32:33 [QMD 8] Bayes factor calculation queued. Model IDs 1 2
16:32:38 [GenSim (Bayes 0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
16:32:38 [GenSim (Bayes 0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
16:32:38 [GenSim (Bayes 1)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
16:32:39 [GenSim (Bayes 1)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
16:32:39 [GenSim (Bayes 2)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
16:32:39 [GenSim (Bayes 2)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
16:32:39 [RQ Bayes 0/1] Start. Branch 0
16:32:39 [RQ Bayes 0/2] Start. Branch 0
16:32:39 [RQ Bayes 1/2] Start. Branch 0
17:20:45 [RQ Bayes 0/1] BF computed: A:0; B:1; BF:0.0 	Reset remormalisation record: False
17:20:45 [RQ Bayes 0/1] Redis SET bayes_factors_db, pair: 0,1 bayes: 1e-160
17:20:45 [RQ Bayes 0/1] Redis SET bayes_factors_winners_db, pair: 0,1 winner: 1
17:20:45 [RQ Bayes 0/1] Finished. rq time:  2886.4271347522736
17:25:51 [RQ Bayes 0/2] BF computed: A:0; B:2; BF:0.0 	Reset remormalisation record: False
17:25:51 [RQ Bayes 0/2] Redis SET bayes_factors_db, pair: 0,2 bayes: 1e-160
17:25:51 [RQ Bayes 0/2] Redis SET bayes_factors_winners_db, pair: 0,2 winner: 2
17:25:51 [RQ Bayes 0/2] Finished. rq time:  3193.0532994270325
17:28:20 [RQ Bayes 1/2] BF computed: A:1; B:2; BF:0.0 	Reset remormalisation record: False
17:28:20 [RQ Bayes 1/2] Redis SET bayes_factors_db, pair: 1,2 bayes: 1.10856581217e-23
17:28:20 [RQ Bayes 1/2] Redis SET bayes_factors_winners_db, pair: 1,2 winner: 2
17:28:20 [RQ Bayes 1/2] Finished. rq time:  3341.6519346237183
17:28:20 [QMD 8] compareModelsWithinBranch 0 active_models_in_branch_old: [0.0, 1.0, 2.0] active_models_in_branch_new: [0, 1, 2]
17:28:20 [QMD 8] [compareModelsWithinBranch 0] Point to 1 (comparison 0/1)
17:28:20 [QMD 8] [compareModelsWithinBranch 0] Point to 2 (comparison 0/2)
17:28:20 [QMD 8] [compareModelsWithinBranch 0] Point to 2 (comparison 1/2)
17:28:20 [QMD 8] Model points for branch 0 {0: 0, 1: 1, 2: 2}
17:28:20 [QMD 8] Champion of branch  0  is  zTi (2)
17:28:20 [QMD 8] Spawning. Growth rule: two_qubit_ising_rotation_hyperfine_transverse. Depth: 1
17:28:20 [QMD 8] After model generation for growth rule two_qubit_ising_rotation_hyperfine_transverse SPAWN STAGE: [None] 
new models: ['yTiPPzTi', 'xTiPPzTi']
17:28:20 [QMD 8] Branch 1 growth rule two_qubit_ising_rotation_hyperfine_transverse has 2 new models ['xTiPPzTi', 'yTiPPzTi']
17:28:20 [DB] Model  xTiPPzTi  not previously considered -- adding.
17:28:20 [QMD 8] Model  xTiPPzTi 
	computed already:  False 
	ID: 3.0
17:28:20 [DB] Model  yTiPPzTi  not previously considered -- adding.
17:28:20 [QMD 8] Model  yTiPPzTi 
	computed already:  False 
	ID: 4.0
17:28:20 [QMD 8] Num models already computed on branch  1 = 0
17:28:20 [QMD 8] Models to add to new branch ( 1 ):  ['yTiPPzTi', 'xTiPPzTi']
17:28:20 [QMD 8] learnModelFromBranchID branch 1 : ['xTiPPzTi', 'yTiPPzTi']
17:28:20 [QMD 8] learnModelFromBranchID. Setting active branches on redis for branch 1 to 0
17:28:20 [QMD 8] branch 1 precomputed: []
17:28:20 [QMD 8] Branch  1 has unlearned models: ['xTiPPzTi', 'yTiPPzTi']
17:28:20 [QMD 8] Model  xTiPPzTi being passed to learnModel function
17:28:20 [QMD 8] Model xTiPPzTi added to queue.
17:28:20 [QMD 8] Model  yTiPPzTi being passed to learnModel function
17:28:20 [QMD 8] Model yTiPPzTi added to queue.
17:28:20 [QMD 8] learnModelFromBranchID finished, branch 1
17:28:25 [QML 4] QML for  yTiPPzTi
17:28:25 [QML 4] Getting prior for model: yTiPPzTi Specific terms: {'xTi': [4.0, 1.5], 'yTi': [4.0, 1.5], 'zTi': [4.0, 1.5], 'xTx': [4.0, 1.5], 'yTy': [4.0, 1.5], 'zTz': [4.0, 1.5], 'xTy': [4.0, 1.5], 'xTz': [4.0, 1.5], 'yTz': [4.0, 1.5]}
17:28:25 [QML 4] Normal Prior 
Means: [ 4.  4.] 
Cov mtx: [[ 2.25  0.  ]
 [ 0.    2.25]] 
Samples: [[ 5.77445575  5.65593278]
 [ 2.85105915  4.4241634 ]
 [ 2.31478257  3.69572423]
 [ 5.66321588  3.38099876]
 [ 4.20495455  0.54636528]
 [ 4.59605444  5.53922657]
 [ 5.01463047  3.32622211]
 [ 4.15815029  5.5234368 ]
 [ 2.88288783  4.36147799]
 [ 4.31516781  5.26505164]]
17:28:25 [GenSim (QML 4)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
17:28:25 [QML 4] Initialization Ready
17:28:25 [RQ Learn 4.0] Time to unpickle and initialise QML class: 0.09633612632751465
17:28:25 [RQ Learn 4.0] Updating model.
17:28:25 [QML 4] Experiment 0
17:28:25 [QML 4] Initial time selected >  0.14
17:28:26 [QML 3] QML for  xTiPPzTi
17:28:26 [QML 3] Getting prior for model: xTiPPzTi Specific terms: {'xTi': [4.0, 1.5], 'yTi': [4.0, 1.5], 'zTi': [4.0, 1.5], 'xTx': [4.0, 1.5], 'yTy': [4.0, 1.5], 'zTz': [4.0, 1.5], 'xTy': [4.0, 1.5], 'xTz': [4.0, 1.5], 'yTz': [4.0, 1.5]}
17:28:26 [QML 3] Normal Prior 
Means: [ 4.  4.] 
Cov mtx: [[ 2.25  0.  ]
 [ 0.    2.25]] 
Samples: [[ 5.26532851  3.84202635]
 [ 5.05732481  3.62314103]
 [ 6.18398398  3.57670763]
 [ 2.71585569  3.40632779]
 [ 3.17686761  5.8961519 ]
 [ 2.95149535  5.42613713]
 [ 4.78992756  6.58687901]
 [ 4.00770754  4.52174409]
 [ 6.41330685  3.88793077]
 [ 2.83193885  4.1532051 ]]
17:28:26 [GenSim (QML 3)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
17:28:26 [QML 3] Initialization Ready
17:28:26 [RQ Learn 3.0] Time to unpickle and initialise QML class: 0.09217381477355957
17:28:26 [RQ Learn 3.0] Updating model.
17:28:26 [QML 3] Experiment 0
17:28:26 [QML 3] Initial time selected >  0.34
17:30:45 [QML 3] Experiment 75
17:30:46 [QML 4] Experiment 75
17:33:3 [QML 3] Experiment 150
17:33:7 [QML 4] Experiment 150
17:35:25 [QML 3] Experiment 225
17:35:26 [QML 4] Experiment 225
17:37:46 [QML 4] Experiment 300
17:37:46 [QML 3] Experiment 300
17:40:5 [QML 3] Experiment 375
17:40:7 [QML 4] Experiment 375
17:42:26 [QML 3] Experiment 450
17:42:28 [QML 4] Experiment 450
17:44:37 [QML 4] Experiment 525
17:44:37 [QML 3] Experiment 525
17:47:1 [QML 4] Experiment 600
17:47:4 [QML 3] Experiment 600
17:49:27 [QML 4] Experiment 675
17:49:31 [QML 3] Experiment 675
17:51:52 [QML 4] Results for QHL on  yTiPPzTi
17:51:52 [QML 4] Final time selected > 3.24
17:51:52 [QML 4] Cumulative time.	 Datum: 0.1246485710144043 	 Update: 1404.9361221790314
17:51:52 [QML 4] Final Parameters mean and stdev (term  yTi ): [ 0.02445796  1.43451233]
17:51:52 [QML 4] Final Parameters mean and stdev (term  zTi ): [ 1.88870556  0.05976184]
17:51:52 [RQ Learn 4.0] Time for update alone: 1406.7431502342224
17:51:52 [RQ Learn 4.0] Redis learned_models_info added to db for model: 4.0
17:51:52 [RQ Learn 4.0] Redis SET learned_models_ids: 4.0 ; set True
17:51:52 [RQ Learn 4.0] Learned. rq time: 1406.9592006206512
17:51:57 [QML 3] Results for QHL on  xTiPPzTi
17:51:57 [QML 3] Final time selected > 3.24
17:51:57 [QML 3] Cumulative time.	 Datum: 0.13004040718078613 	 Update: 1409.1822650432587
17:51:57 [QML 3] Final Parameters mean and stdev (term  xTi ): [-0.50051462  1.69956166]
17:51:57 [QML 3] Final Parameters mean and stdev (term  zTi ): [ 1.93398151  0.04888278]
17:51:57 [RQ Learn 3.0] Time for update alone: 1411.0573782920837
17:51:57 [RQ Learn 3.0] Redis learned_models_info added to db for model: 3.0
17:51:57 [RQ Learn 3.0] Redis SET learned_models_ids: 3.0 ; set True
17:51:57 [QMD 8] All models on branch 1 have finished learning.
17:51:57 [RQ Learn 3.0] Learned. rq time: 1411.275099515915
17:51:57 [QMD 8] remoteBayesFromBranchID 1 model id list: [3.0, 4.0]
17:51:57 [QMD 8] Computing BF for pair 3,4
17:51:57 [QMD 8] Bayes factor calculation queued. Model IDs 3.0 4.0
17:52:3 [GenSim (Bayes 3.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
17:52:3 [GenSim (Bayes 4.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
17:52:3 [RQ Bayes 3.0/4.0] Start. Branch 1
18:38:16 [RQ Bayes 3.0/4.0] BF computed: A:3.0; B:4.0; BF:2.470531603404106e+18 	Reset remormalisation record: False
18:38:16 [RQ Bayes 3.0/4.0] Redis SET bayes_factors_db, pair: 3,4 bayes: 2.4705316034e+18
18:38:16 [RQ Bayes 3.0/4.0] Redis SET bayes_factors_winners_db, pair: 3,4 winner: 3.0
18:38:16 [RQ Bayes 3.0/4.0] Finished. rq time:  2773.6533403396606
18:38:17 [QMD 8] compareModelsWithinBranch 1 active_models_in_branch_old: [3.0, 4.0] active_models_in_branch_new: [3.0, 4.0]
18:38:17 [QMD 8] [compareModelsWithinBranch 1] Point to 3 (comparison 3.0/4.0)
18:38:17 [QMD 8] Model points for branch 1 {3.0: 1, 4.0: 0}
18:38:17 [QMD 8] Champion of branch  1  is  xTiPPzTi (3)
18:38:17 [QMD 8] Spawning. Growth rule: two_qubit_ising_rotation_hyperfine_transverse. Depth: 2
18:38:17 [QMD 8] After model generation for growth rule two_qubit_ising_rotation_hyperfine_transverse SPAWN STAGE: [None] 
new models: ['xTiPPyTiPPzTi']
18:38:17 [QMD 8] Branch 2 growth rule two_qubit_ising_rotation_hyperfine_transverse has 1 new models ['xTiPPyTiPPzTi']
18:38:17 [DB] Model  xTiPPyTiPPzTi  not previously considered -- adding.
18:38:17 [QMD 8] Model  xTiPPyTiPPzTi 
	computed already:  False 
	ID: 5.0
18:38:17 [QMD 8] Num models already computed on branch  2 = 0
18:38:17 [QMD 8] Models to add to new branch ( 2 ):  ['xTiPPyTiPPzTi']
18:38:17 [QMD 8] learnModelFromBranchID branch 2 : ['xTiPPyTiPPzTi']
18:38:17 [QMD 8] learnModelFromBranchID. Setting active branches on redis for branch 2 to 0
18:38:17 [QMD 8] branch 2 precomputed: []
18:38:17 [QMD 8] Branch  2 has unlearned models: ['xTiPPyTiPPzTi']
18:38:17 [QMD 8] Model  xTiPPyTiPPzTi being passed to learnModel function
18:38:17 [QMD 8] Model xTiPPyTiPPzTi added to queue.
18:38:17 [QMD 8] learnModelFromBranchID finished, branch 2
18:38:23 [QML 5] QML for  xTiPPyTiPPzTi
18:38:23 [QML 5] Getting prior for model: xTiPPyTiPPzTi Specific terms: {'xTi': [4.0, 1.5], 'yTi': [4.0, 1.5], 'zTi': [4.0, 1.5], 'xTx': [4.0, 1.5], 'yTy': [4.0, 1.5], 'zTz': [4.0, 1.5], 'xTy': [4.0, 1.5], 'xTz': [4.0, 1.5], 'yTz': [4.0, 1.5]}
18:38:23 [QML 5] Normal Prior 
Means: [ 4.  4.  4.] 
Cov mtx: [[ 2.25  0.    0.  ]
 [ 0.    2.25  0.  ]
 [ 0.    0.    2.25]] 
Samples: [[ 2.87387221  6.33129665  2.34030569]
 [ 3.24378208  4.38836802  3.10845994]
 [ 5.07557786  1.86465248  4.9010041 ]
 [ 3.31483902  3.53331671  4.41507085]
 [ 2.95266321  5.61135423  4.57103063]
 [ 4.95264536  6.68769543  4.80685666]
 [ 4.69289894  5.59264517  2.3926764 ]
 [ 1.88007686  6.03019815  5.47054451]
 [ 3.29577607  3.53394785  2.86447862]
 [ 2.72107204  5.21482469  3.45917718]]
18:38:23 [GenSim (QML 5)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
18:38:23 [QML 5] Initialization Ready
18:38:23 [RQ Learn 5.0] Time to unpickle and initialise QML class: 0.09378361701965332
18:38:23 [RQ Learn 5.0] Updating model.
18:38:23 [QML 5] Experiment 0
18:38:23 [QML 5] Initial time selected >  0.11
18:40:45 [QML 5] Experiment 75
18:43:12 [QML 5] Experiment 150
18:45:36 [QML 5] Experiment 225
18:48:2 [QML 5] Experiment 300
18:50:30 [QML 5] Experiment 375
18:52:50 [QML 5] Experiment 450
18:55:15 [QML 5] Experiment 525
18:57:41 [QML 5] Experiment 600
19:0:7 [QML 5] Experiment 675
19:2:33 [QML 5] Results for QHL on  xTiPPyTiPPzTi
19:2:33 [QML 5] Final time selected > 3.24
19:2:33 [QML 5] Cumulative time.	 Datum: 0.13485503196716309 	 Update: 1447.933086156845
19:2:33 [QML 5] Final Parameters mean and stdev (term  xTi ): [ 0.46073038  0.08216813]
19:2:33 [QML 5] Final Parameters mean and stdev (term  yTi ): [ 5.37746602  0.07118561]
19:2:33 [QML 5] Final Parameters mean and stdev (term  zTi ): [ 3.52439508  0.11509345]
19:2:33 [RQ Learn 5.0] Time for update alone: 1450.1686599254608
19:2:33 [RQ Learn 5.0] Redis learned_models_info added to db for model: 5.0
19:2:33 [RQ Learn 5.0] Redis SET learned_models_ids: 5.0 ; set True
19:2:33 [QMD 8] All models on branch 2 have finished learning.
19:2:33 [RQ Learn 5.0] Learned. rq time: 1450.40140914917
19:2:33 [QMD 8] remoteBayesFromBranchID 2 model id list: [5.0]
19:2:33 [QMD 8] compareModelsWithinBranch 2 active_models_in_branch_old: [5.0] active_models_in_branch_new: [5.0]
19:2:33 [QMD 8] Model points for branch 2 {5.0: 0}
19:2:33 [QMD 8] Champion of branch  2  is  xTiPPyTiPPzTi (5)
19:2:33 [QMD 8] Spawning. Growth rule: two_qubit_ising_rotation_hyperfine_transverse. Depth: 3
19:2:33 [QMD 8] After model generation for growth rule two_qubit_ising_rotation_hyperfine_transverse SPAWN STAGE: [None] 
new models: ['xTiPPyTiPPyTyPPzTi', 'xTiPPyTiPPzTiPPzTz', 'xTiPPxTxPPyTiPPzTi']
19:2:33 [QMD 8] Branch 3 growth rule two_qubit_ising_rotation_hyperfine_transverse has 3 new models ['xTiPPyTiPPzTiPPzTz', 'xTiPPxTxPPyTiPPzTi', 'xTiPPyTiPPyTyPPzTi']
19:2:33 [DB] Model  xTiPPyTiPPzTiPPzTz  not previously considered -- adding.
19:2:33 [QMD 8] Model  xTiPPyTiPPzTiPPzTz 
	computed already:  False 
	ID: 6.0
19:2:33 [DB] Model  xTiPPxTxPPyTiPPzTi  not previously considered -- adding.
19:2:33 [QMD 8] Model  xTiPPxTxPPyTiPPzTi 
	computed already:  False 
	ID: 7.0
19:2:33 [DB] Model  xTiPPyTiPPyTyPPzTi  not previously considered -- adding.
19:2:33 [QMD 8] Model  xTiPPyTiPPyTyPPzTi 
	computed already:  False 
	ID: 8.0
19:2:33 [QMD 8] Num models already computed on branch  3 = 0
19:2:33 [QMD 8] Models to add to new branch ( 3 ):  ['xTiPPyTiPPyTyPPzTi', 'xTiPPyTiPPzTiPPzTz', 'xTiPPxTxPPyTiPPzTi']
19:2:33 [QMD 8] learnModelFromBranchID branch 3 : ['xTiPPyTiPPzTiPPzTz', 'xTiPPxTxPPyTiPPzTi', 'xTiPPyTiPPyTyPPzTi']
19:2:33 [QMD 8] learnModelFromBranchID. Setting active branches on redis for branch 3 to 0
19:2:33 [QMD 8] branch 3 precomputed: []
19:2:33 [QMD 8] Branch  3 has unlearned models: ['xTiPPyTiPPzTiPPzTz', 'xTiPPxTxPPyTiPPzTi', 'xTiPPyTiPPyTyPPzTi']
19:2:33 [QMD 8] Model  xTiPPyTiPPzTiPPzTz being passed to learnModel function
19:2:33 [QMD 8] Model xTiPPyTiPPzTiPPzTz added to queue.
19:2:33 [QMD 8] Model  xTiPPxTxPPyTiPPzTi being passed to learnModel function
19:2:33 [QMD 8] Model xTiPPxTxPPyTiPPzTi added to queue.
19:2:33 [QMD 8] Model  xTiPPyTiPPyTyPPzTi being passed to learnModel function
19:2:33 [QMD 8] Model xTiPPyTiPPyTyPPzTi added to queue.
19:2:33 [QMD 8] learnModelFromBranchID finished, branch 3
19:2:39 [QML 7] QML for  xTiPPxTxPPyTiPPzTi
19:2:39 [QML 6] QML for  xTiPPyTiPPzTiPPzTz
19:2:39 [QML 7] Getting prior for model: xTiPPxTxPPyTiPPzTi Specific terms: {'xTi': [4.0, 1.5], 'yTi': [4.0, 1.5], 'zTi': [4.0, 1.5], 'xTx': [4.0, 1.5], 'yTy': [4.0, 1.5], 'zTz': [4.0, 1.5], 'xTy': [4.0, 1.5], 'xTz': [4.0, 1.5], 'yTz': [4.0, 1.5]}
19:2:39 [QML 6] Getting prior for model: xTiPPyTiPPzTiPPzTz Specific terms: {'xTi': [4.0, 1.5], 'yTi': [4.0, 1.5], 'zTi': [4.0, 1.5], 'xTx': [4.0, 1.5], 'yTy': [4.0, 1.5], 'zTz': [4.0, 1.5], 'xTy': [4.0, 1.5], 'xTz': [4.0, 1.5], 'yTz': [4.0, 1.5]}
19:2:39 [QML 7] Normal Prior 
Means: [ 4.  4.  4.  4.] 
Cov mtx: [[ 2.25  0.    0.    0.  ]
 [ 0.    2.25  0.    0.  ]
 [ 0.    0.    2.25  0.  ]
 [ 0.    0.    0.    2.25]] 
Samples: [[ 1.94736077  5.14695472  3.15503024  5.75966925]
 [ 2.60536356  2.54516394  2.78688123  4.50957872]
 [ 0.84217136  3.39949948  5.92886993  4.6653084 ]
 [ 5.92697388  6.60009711  0.31406909  5.54511514]
 [ 6.24432268  3.68462845  5.5166274   2.01748489]
 [ 2.56852254  3.09846369  3.11131385  3.02417239]
 [ 4.16537145  4.12079685  4.44210034  3.86678084]
 [ 4.09913655  1.37999646  2.47647065  2.39941998]
 [ 3.79952448  5.94293738  3.529179    2.49496667]
 [ 2.47485976  3.6473758   6.86332699  1.96331602]]
19:2:39 [GenSim (QML 7)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
19:2:39 [QML 6] Normal Prior 
Means: [ 4.  4.  4.  4.] 
Cov mtx: [[ 2.25  0.    0.    0.  ]
 [ 0.    2.25  0.    0.  ]
 [ 0.    0.    2.25  0.  ]
 [ 0.    0.    0.    2.25]] 
Samples: [[ 4.26511373  5.85075181  2.41933289  3.05188499]
 [ 3.06857613  4.42305498  2.84853216  5.78814507]
 [ 4.29558376  3.22398425  4.00839307  5.68280421]
 [ 4.88602229  3.48497858  6.04207127  4.45169979]
 [ 6.6027438   4.00626437  4.16584087  4.63021192]
 [ 3.93065744  4.27203903  5.20387147  3.84844328]
 [ 6.08400742  2.5431569   5.30014527  6.84764742]
 [ 4.94148199  5.03692777  3.76054828  4.05542892]
 [ 3.49389454  3.80729804  6.7364757   2.01032795]
 [ 2.69278802  5.95211012  2.50436522  3.68417799]]
19:2:39 [GenSim (QML 6)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
19:2:39 [QML 7] Initialization Ready
19:2:39 [RQ Learn 7.0] Time to unpickle and initialise QML class: 0.09537959098815918
19:2:39 [RQ Learn 7.0] Updating model.
19:2:39 [QML 7] Experiment 0
19:2:39 [QML 6] Initialization Ready
19:2:39 [RQ Learn 6.0] Time to unpickle and initialise QML class: 0.09701228141784668
19:2:39 [RQ Learn 6.0] Updating model.
19:2:39 [QML 7] Initial time selected >  0.22
19:2:39 [QML 6] Experiment 0
19:2:39 [QML 6] Initial time selected >  0.13
19:2:39 [QML 8] QML for  xTiPPyTiPPyTyPPzTi
19:2:39 [QML 8] Getting prior for model: xTiPPyTiPPyTyPPzTi Specific terms: {'xTi': [4.0, 1.5], 'yTi': [4.0, 1.5], 'zTi': [4.0, 1.5], 'xTx': [4.0, 1.5], 'yTy': [4.0, 1.5], 'zTz': [4.0, 1.5], 'xTy': [4.0, 1.5], 'xTz': [4.0, 1.5], 'yTz': [4.0, 1.5]}
19:2:39 [QML 8] Normal Prior 
Means: [ 4.  4.  4.  4.] 
Cov mtx: [[ 2.25  0.    0.    0.  ]
 [ 0.    2.25  0.    0.  ]
 [ 0.    0.    2.25  0.  ]
 [ 0.    0.    0.    2.25]] 
Samples: [[ 4.23999724  4.22859238  4.7978179   4.36211905]
 [ 2.96570154  2.78066207  2.55098668  2.63286168]
 [ 2.99576632  4.34400414  3.13097846  4.34971788]
 [ 3.74491768  0.37362962  4.29106698  6.36345476]
 [ 3.3091766   4.5012109   1.94277864  5.61702372]
 [ 5.66490314  3.72904995  5.32431054  2.52165656]
 [ 1.99639033  3.66766278  5.71844806  5.119564  ]
 [ 3.05549619  5.31487196  3.30341444  3.94032102]
 [ 6.06801152  5.82338821  4.13013969  5.10396594]
 [ 1.14564253  4.2279743   4.56092359  2.94406256]]
19:2:39 [GenSim (QML 8)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
19:2:39 [QML 8] Initialization Ready
19:2:39 [RQ Learn 8.0] Time to unpickle and initialise QML class: 0.09758424758911133
19:2:39 [RQ Learn 8.0] Updating model.
19:2:39 [QML 8] Experiment 0
19:2:39 [QML 8] Initial time selected >  0.21
19:4:56 [QML 7] Experiment 75
19:4:56 [QML 8] Experiment 75
19:4:59 [QML 6] Experiment 75
19:7:12 [QML 8] Experiment 150
19:7:16 [QML 7] Experiment 150
19:7:25 [QML 6] Experiment 150
19:9:32 [QML 8] Experiment 225
19:9:42 [QML 7] Experiment 225
19:9:54 [QML 6] Experiment 225
19:11:56 [QML 8] Experiment 300
19:12:10 [QML 7] Experiment 300
19:12:24 [QML 6] Experiment 300
19:14:22 [QML 8] Experiment 375
19:14:39 [QML 7] Experiment 375
19:14:54 [QML 6] Experiment 375
19:16:43 [QML 8] Experiment 450
19:17:2 [QML 7] Experiment 450
19:17:19 [QML 6] Experiment 450
19:19:6 [QML 8] Experiment 525
19:19:31 [QML 7] Experiment 525
19:19:46 [QML 6] Experiment 525
19:21:33 [QML 8] Experiment 600
19:21:59 [QML 7] Experiment 600
19:22:15 [QML 6] Experiment 600
19:24:2 [QML 8] Experiment 675
19:24:27 [QML 7] Experiment 675
19:24:44 [QML 6] Experiment 675
19:26:31 [QML 8] Results for QHL on  xTiPPyTiPPyTyPPzTi
19:26:31 [QML 8] Final time selected > 3.24
19:26:31 [QML 8] Cumulative time.	 Datum: 0.13425135612487793 	 Update: 1429.3916699886322
19:26:31 [QML 8] Final Parameters mean and stdev (term  xTi ): [-0.09883486  0.29488195]
19:26:31 [QML 8] Final Parameters mean and stdev (term  yTi ): [ 3.10676659  0.17650268]
19:26:31 [QML 8] Final Parameters mean and stdev (term  yTy ): [ 2.99999974  0.14746826]
19:26:31 [QML 8] Final Parameters mean and stdev (term  zTi ): [ 1.99702703  0.08745851]
19:26:31 [RQ Learn 8.0] Time for update alone: 1431.8622505664825
19:26:31 [RQ Learn 8.0] Redis learned_models_info added to db for model: 8.0
19:26:31 [RQ Learn 8.0] Redis SET learned_models_ids: 8.0 ; set True
19:26:31 [RQ Learn 8.0] Learned. rq time: 1432.1124079227448
19:26:55 [QML 7] Results for QHL on  xTiPPxTxPPyTiPPzTi
19:26:55 [QML 7] Final time selected > 3.24
19:26:55 [QML 7] Cumulative time.	 Datum: 0.12359809875488281 	 Update: 1454.0530104637146
19:26:55 [QML 7] Final Parameters mean and stdev (term  xTi ): [ 0.14941656  0.07466613]
19:26:55 [QML 7] Final Parameters mean and stdev (term  xTx ): [ 2.36151712  0.10986179]
19:26:55 [QML 7] Final Parameters mean and stdev (term  yTi ): [ 4.88360072  0.05368726]
19:26:55 [QML 7] Final Parameters mean and stdev (term  zTi ): [ 4.97480651  0.03140579]
19:26:55 [RQ Learn 7.0] Time for update alone: 1456.383312702179
19:26:55 [RQ Learn 7.0] Redis learned_models_info added to db for model: 7.0
19:26:55 [RQ Learn 7.0] Redis SET learned_models_ids: 7.0 ; set True
19:26:55 [RQ Learn 7.0] Learned. rq time: 1456.6238050460815
19:27:13 [QML 6] Results for QHL on  xTiPPyTiPPzTiPPzTz
19:27:13 [QML 6] Final time selected > 3.24
19:27:13 [QML 6] Cumulative time.	 Datum: 0.12150025367736816 	 Update: 1471.8747494220734
19:27:13 [QML 6] Final Parameters mean and stdev (term  xTi ): [ 0.88109112  0.21539872]
19:27:13 [QML 6] Final Parameters mean and stdev (term  yTi ): [ 5.373278   0.1408395]
19:27:13 [QML 6] Final Parameters mean and stdev (term  zTi ): [ 0.21684191  0.44570527]
19:27:13 [QML 6] Final Parameters mean and stdev (term  zTz ): [ 3.03618796  0.26005347]
19:27:13 [RQ Learn 6.0] Time for update alone: 1474.1979007720947
19:27:13 [RQ Learn 6.0] Redis learned_models_info added to db for model: 6.0
19:27:13 [RQ Learn 6.0] Redis SET learned_models_ids: 6.0 ; set True
19:27:13 [QMD 8] All models on branch 3 have finished learning.
19:27:13 [RQ Learn 6.0] Learned. rq time: 1474.4358820915222
19:27:13 [QMD 8] remoteBayesFromBranchID 3 model id list: [6.0, 7.0, 8.0]
19:27:13 [QMD 8] Computing BF for pair 6,7
19:27:13 [QMD 8] Bayes factor calculation queued. Model IDs 6.0 7.0
19:27:13 [QMD 8] Computing BF for pair 6,8
19:27:13 [QMD 8] Bayes factor calculation queued. Model IDs 6.0 8.0
19:27:13 [QMD 8] Computing BF for pair 7,8
19:27:13 [QMD 8] Bayes factor calculation queued. Model IDs 7.0 8.0
19:27:20 [GenSim (Bayes 6.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
19:27:20 [GenSim (Bayes 6.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
19:27:20 [GenSim (Bayes 8.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
19:27:20 [GenSim (Bayes 7.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
19:27:20 [RQ Bayes 6.0/8.0] Start. Branch 3
19:27:20 [RQ Bayes 6.0/7.0] Start. Branch 3
19:27:21 [GenSim (Bayes 7.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
19:27:21 [GenSim (Bayes 8.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
19:27:21 [RQ Bayes 7.0/8.0] Start. Branch 3
20:15:26 [RQ Bayes 7.0/8.0] BF computed: A:7.0; B:8.0; BF:0.0 	Reset remormalisation record: False
20:15:26 [RQ Bayes 7.0/8.0] Redis SET bayes_factors_db, pair: 7,8 bayes: 1e-160
20:15:26 [RQ Bayes 7.0/8.0] Redis SET bayes_factors_winners_db, pair: 7,8 winner: 8.0
20:15:26 [RQ Bayes 7.0/8.0] Finished. rq time:  2885.493395090103
20:15:38 [RQ Bayes 6.0/7.0] BF computed: A:6.0; B:7.0; BF:4.22443615212349e+228 	Reset remormalisation record: False
20:15:38 [RQ Bayes 6.0/7.0] Redis SET bayes_factors_db, pair: 6,7 bayes: 1e+160
20:15:38 [RQ Bayes 6.0/7.0] Redis SET bayes_factors_winners_db, pair: 6,7 winner: 6.0
20:15:38 [RQ Bayes 6.0/7.0] Finished. rq time:  2898.255933523178
20:15:51 [RQ Bayes 6.0/8.0] BF computed: A:6.0; B:8.0; BF:0.0 	Reset remormalisation record: False
20:15:51 [RQ Bayes 6.0/8.0] Redis SET bayes_factors_db, pair: 6,8 bayes: 5.8144032096e-09
20:15:51 [RQ Bayes 6.0/8.0] Redis SET bayes_factors_winners_db, pair: 6,8 winner: 8.0
20:15:51 [RQ Bayes 6.0/8.0] Finished. rq time:  2910.9881196022034
20:15:51 [QMD 8] compareModelsWithinBranch 3 active_models_in_branch_old: [6.0, 7.0, 8.0] active_models_in_branch_new: [6.0, 7.0, 8.0]
20:15:51 [QMD 8] [compareModelsWithinBranch 3] Point to 6 (comparison 6.0/7.0)
20:15:51 [QMD 8] [compareModelsWithinBranch 3] Point to 8 (comparison 6.0/8.0)
20:15:51 [QMD 8] [compareModelsWithinBranch 3] Point to 8 (comparison 7.0/8.0)
20:15:51 [QMD 8] Model points for branch 3 {6.0: 1, 7.0: 0, 8.0: 2}
20:15:51 [QMD 8] Champion of branch  3  is  xTiPPyTiPPyTyPPzTi (8)
20:15:51 [QMD 8] Spawning. Growth rule: two_qubit_ising_rotation_hyperfine_transverse. Depth: 4
20:15:51 [QMD 8] After model generation for growth rule two_qubit_ising_rotation_hyperfine_transverse SPAWN STAGE: [None] 
new models: ['xTiPPyTiPPyTyPPzTiPPzTz', 'xTiPPxTxPPyTiPPyTyPPzTi']
20:15:51 [QMD 8] Branch 4 growth rule two_qubit_ising_rotation_hyperfine_transverse has 2 new models ['xTiPPxTxPPyTiPPyTyPPzTi', 'xTiPPyTiPPyTyPPzTiPPzTz']
20:15:51 [DB] Model  xTiPPxTxPPyTiPPyTyPPzTi  not previously considered -- adding.
20:15:51 [QMD 8] Model  xTiPPxTxPPyTiPPyTyPPzTi 
	computed already:  False 
	ID: 9.0
20:15:51 [DB] Model  xTiPPyTiPPyTyPPzTiPPzTz  not previously considered -- adding.
20:15:51 [QMD 8] Model  xTiPPyTiPPyTyPPzTiPPzTz 
	computed already:  False 
	ID: 10.0
20:15:51 [QMD 8] Num models already computed on branch  4 = 0
20:15:51 [QMD 8] Models to add to new branch ( 4 ):  ['xTiPPyTiPPyTyPPzTiPPzTz', 'xTiPPxTxPPyTiPPyTyPPzTi']
20:15:51 [QMD 8] learnModelFromBranchID branch 4 : ['xTiPPxTxPPyTiPPyTyPPzTi', 'xTiPPyTiPPyTyPPzTiPPzTz']
20:15:51 [QMD 8] learnModelFromBranchID. Setting active branches on redis for branch 4 to 0
20:15:51 [QMD 8] branch 4 precomputed: []
20:15:51 [QMD 8] Branch  4 has unlearned models: ['xTiPPxTxPPyTiPPyTyPPzTi', 'xTiPPyTiPPyTyPPzTiPPzTz']
20:15:51 [QMD 8] Model  xTiPPxTxPPyTiPPyTyPPzTi being passed to learnModel function
20:15:51 [QMD 8] Model xTiPPxTxPPyTiPPyTyPPzTi added to queue.
20:15:51 [QMD 8] Model  xTiPPyTiPPyTyPPzTiPPzTz being passed to learnModel function
20:15:51 [QMD 8] Model xTiPPyTiPPyTyPPzTiPPzTz added to queue.
20:15:51 [QMD 8] learnModelFromBranchID finished, branch 4
20:15:56 [QML 10] QML for  xTiPPyTiPPyTyPPzTiPPzTz
20:15:56 [QML 10] Getting prior for model: xTiPPyTiPPyTyPPzTiPPzTz Specific terms: {'xTi': [4.0, 1.5], 'yTi': [4.0, 1.5], 'zTi': [4.0, 1.5], 'xTx': [4.0, 1.5], 'yTy': [4.0, 1.5], 'zTz': [4.0, 1.5], 'xTy': [4.0, 1.5], 'xTz': [4.0, 1.5], 'yTz': [4.0, 1.5]}
20:15:56 [QML 10] Normal Prior 
Means: [ 4.  4.  4.  4.  4.] 
Cov mtx: [[ 2.25  0.    0.    0.    0.  ]
 [ 0.    2.25  0.    0.    0.  ]
 [ 0.    0.    2.25  0.    0.  ]
 [ 0.    0.    0.    2.25  0.  ]
 [ 0.    0.    0.    0.    2.25]] 
Samples: [[ 5.32921563  1.43146906  4.72932037  2.45080885  2.27461736]
 [ 5.18044078  3.30657802  4.03873562  2.40777252  4.38549163]
 [ 1.355826    3.88439169  4.29671834  3.88583545  5.03880953]
 [ 5.05667025  3.85435681  2.03292971  4.18872977  3.03434281]
 [ 3.29484316  3.05309356  1.06462686  5.36820324  6.31722596]
 [ 3.17984183  5.64292586  3.04904455  2.17284262  3.29433995]
 [ 5.684727    0.88765583  1.61035248  5.57737423  1.13850627]
 [ 2.76002788  7.34139358  7.62307865  6.6861659   6.48228996]
 [ 5.02414998  3.75738925  4.70703673  3.26525266  2.5046407 ]
 [ 3.2783768   1.44772004  5.10881035  3.16907078  5.40018946]]
20:15:56 [GenSim (QML 10)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
20:15:56 [QML 10] Initialization Ready
20:15:56 [RQ Learn 10.0] Time to unpickle and initialise QML class: 0.09006190299987793
20:15:56 [RQ Learn 10.0] Updating model.
20:15:56 [QML 10] Experiment 0
20:15:56 [QML 10] Initial time selected >  0.17
20:15:57 [QML 9] QML for  xTiPPxTxPPyTiPPyTyPPzTi
20:15:57 [QML 9] Getting prior for model: xTiPPxTxPPyTiPPyTyPPzTi Specific terms: {'xTi': [4.0, 1.5], 'yTi': [4.0, 1.5], 'zTi': [4.0, 1.5], 'xTx': [4.0, 1.5], 'yTy': [4.0, 1.5], 'zTz': [4.0, 1.5], 'xTy': [4.0, 1.5], 'xTz': [4.0, 1.5], 'yTz': [4.0, 1.5]}
20:15:57 [QML 9] Normal Prior 
Means: [ 4.  4.  4.  4.  4.] 
Cov mtx: [[ 2.25  0.    0.    0.    0.  ]
 [ 0.    2.25  0.    0.    0.  ]
 [ 0.    0.    2.25  0.    0.  ]
 [ 0.    0.    0.    2.25  0.  ]
 [ 0.    0.    0.    0.    2.25]] 
Samples: [[ 2.89529134  3.05822205  5.26935412  4.72414572  6.71529381]
 [ 5.81539698  0.56737626  4.81088605  3.56901265  2.54915454]
 [ 4.54506667  5.92899968  5.83116577  2.87967834  5.70953081]
 [ 5.08667086  3.81934651  2.01257957  1.8770906   5.71911079]
 [ 4.20524258  4.61386823  4.08483682  5.30671403  3.57154537]
 [ 1.83764447  1.19968364  1.94779684  1.71548937  3.16404422]
 [ 5.65563104  2.54223464  3.7192309   5.26060925  1.88050954]
 [ 2.39767957  3.8108436   4.41870447  5.16727311  5.07775294]
 [ 6.73450842  5.5837518   5.00387718  3.17469811  3.55389945]
 [ 1.84552005  5.78113305  3.95399075  5.73654577  4.52877203]]
20:15:57 [GenSim (QML 9)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
20:15:57 [QML 9] Initialization Ready
20:15:57 [RQ Learn 9.0] Time to unpickle and initialise QML class: 0.09430718421936035
20:15:57 [RQ Learn 9.0] Updating model.
20:15:57 [QML 9] Experiment 0
20:15:57 [QML 9] Initial time selected >  0.1
20:18:6 [QML 10] Experiment 75
20:18:8 [QML 9] Experiment 75
20:20:19 [QML 10] Experiment 150
20:20:33 [QML 9] Experiment 150
20:22:42 [QML 10] Experiment 225
20:22:58 [QML 9] Experiment 225
20:25:2 [QML 10] Experiment 300
20:25:23 [QML 9] Experiment 300
20:27:22 [QML 10] Experiment 375
20:27:50 [QML 9] Experiment 375
20:29:45 [QML 10] Experiment 450
20:30:12 [QML 9] Experiment 450
20:32:10 [QML 10] Experiment 525
20:32:37 [QML 9] Experiment 525
20:34:39 [QML 10] Experiment 600
20:35:2 [QML 9] Experiment 600
20:37:7 [QML 10] Experiment 675
20:37:29 [QML 9] Experiment 675
20:39:36 [QML 10] Results for QHL on  xTiPPyTiPPyTyPPzTiPPzTz
20:39:36 [QML 10] Final time selected > 3.24
20:39:36 [QML 10] Cumulative time.	 Datum: 0.11961746215820312 	 Update: 1417.2419755458832
20:39:36 [QML 10] Final Parameters mean and stdev (term  xTi ): [-0.0837089   0.46799116]
20:39:36 [QML 10] Final Parameters mean and stdev (term  yTi ): [ 2.94946994  0.28483388]
20:39:36 [QML 10] Final Parameters mean and stdev (term  yTy ): [ 3.0175633   0.21517036]
20:39:36 [QML 10] Final Parameters mean and stdev (term  zTi ): [ 1.97319285  0.10855228]
20:39:36 [QML 10] Final Parameters mean and stdev (term  zTz ): [-0.21027669  0.17721518]
20:39:36 [RQ Learn 10.0] Time for update alone: 1419.8791239261627
20:39:36 [RQ Learn 10.0] Redis learned_models_info added to db for model: 10.0
20:39:36 [RQ Learn 10.0] Redis SET learned_models_ids: 10.0 ; set True
20:39:36 [RQ Learn 10.0] Learned. rq time: 1420.1324486732483
20:39:54 [QML 9] Results for QHL on  xTiPPxTxPPyTiPPyTyPPzTi
20:39:54 [QML 9] Final time selected > 3.24
20:39:54 [QML 9] Cumulative time.	 Datum: 0.13356781005859375 	 Update: 1434.9164142608643
20:39:54 [QML 9] Final Parameters mean and stdev (term  xTi ): [ 1.07137177  0.1086184 ]
20:39:54 [QML 9] Final Parameters mean and stdev (term  xTx ): [ 5.45044185  0.10368137]
20:39:54 [QML 9] Final Parameters mean and stdev (term  yTi ): [ 2.61930341  0.1370756 ]
20:39:54 [QML 9] Final Parameters mean and stdev (term  yTy ): [ 6.19283772  0.07200959]
20:39:54 [QML 9] Final Parameters mean and stdev (term  zTi ): [ 0.11331496  0.07559542]
20:39:54 [RQ Learn 9.0] Time for update alone: 1437.8457159996033
20:39:55 [RQ Learn 9.0] Redis learned_models_info added to db for model: 9.0
20:39:55 [RQ Learn 9.0] Redis SET learned_models_ids: 9.0 ; set True
20:39:55 [QMD 8] All models on branch 4 have finished learning.
20:39:55 [RQ Learn 9.0] Learned. rq time: 1438.103345632553
20:39:55 [QMD 8] remoteBayesFromBranchID 4 model id list: [9.0, 10.0]
20:39:55 [QMD 8] Computing BF for pair 9,10
20:39:55 [QMD 8] Bayes factor calculation queued. Model IDs 9.0 10.0
20:40:1 [GenSim (Bayes 9.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
20:40:1 [GenSim (Bayes 10.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
20:40:1 [RQ Bayes 9.0/10.0] Start. Branch 4
21:27:11 [RQ Bayes 9.0/10.0] BF computed: A:9.0; B:10.0; BF:0.0 	Reset remormalisation record: False
21:27:11 [RQ Bayes 9.0/10.0] Redis SET bayes_factors_db, pair: 9,10 bayes: 9.29288166177e-06
21:27:11 [RQ Bayes 9.0/10.0] Redis SET bayes_factors_winners_db, pair: 9,10 winner: 10.0
21:27:11 [RQ Bayes 9.0/10.0] Finished. rq time:  2830.658720254898
21:27:11 [QMD 8] compareModelsWithinBranch 4 active_models_in_branch_old: [9.0, 10.0] active_models_in_branch_new: [9.0, 10.0]
21:27:11 [QMD 8] [compareModelsWithinBranch 4] Point to 10 (comparison 9.0/10.0)
21:27:11 [QMD 8] Model points for branch 4 {9.0: 0, 10.0: 1}
21:27:11 [QMD 8] Champion of branch  4  is  xTiPPyTiPPyTyPPzTiPPzTz (10)
21:27:11 [QMD 8] Spawning. Growth rule: two_qubit_ising_rotation_hyperfine_transverse. Depth: 5
21:27:11 [QMD 8] After model generation for growth rule two_qubit_ising_rotation_hyperfine_transverse SPAWN STAGE: [None] 
new models: ['xTiPPxTxPPyTiPPyTyPPzTiPPzTz']
21:27:11 [QMD 8] Branch 5 growth rule two_qubit_ising_rotation_hyperfine_transverse has 1 new models ['xTiPPxTxPPyTiPPyTyPPzTiPPzTz']
21:27:11 [DB] Model  xTiPPxTxPPyTiPPyTyPPzTiPPzTz  not previously considered -- adding.
21:27:11 [QMD 8] Model  xTiPPxTxPPyTiPPyTyPPzTiPPzTz 
	computed already:  False 
	ID: 11.0
21:27:11 [QMD 8] Num models already computed on branch  5 = 0
21:27:11 [QMD 8] Models to add to new branch ( 5 ):  ['xTiPPxTxPPyTiPPyTyPPzTiPPzTz']
21:27:11 [QMD 8] learnModelFromBranchID branch 5 : ['xTiPPxTxPPyTiPPyTyPPzTiPPzTz']
21:27:11 [QMD 8] learnModelFromBranchID. Setting active branches on redis for branch 5 to 0
21:27:11 [QMD 8] branch 5 precomputed: []
21:27:11 [QMD 8] Branch  5 has unlearned models: ['xTiPPxTxPPyTiPPyTyPPzTiPPzTz']
21:27:11 [QMD 8] Model  xTiPPxTxPPyTiPPyTyPPzTiPPzTz being passed to learnModel function
21:27:11 [QMD 8] Model xTiPPxTxPPyTiPPyTyPPzTiPPzTz added to queue.
21:27:11 [QMD 8] learnModelFromBranchID finished, branch 5
21:27:18 [QML 11] QML for  xTiPPxTxPPyTiPPyTyPPzTiPPzTz
21:27:18 [QML 11] Getting prior for model: xTiPPxTxPPyTiPPyTyPPzTiPPzTz Specific terms: {'xTi': [4.0, 1.5], 'yTi': [4.0, 1.5], 'zTi': [4.0, 1.5], 'xTx': [4.0, 1.5], 'yTy': [4.0, 1.5], 'zTz': [4.0, 1.5], 'xTy': [4.0, 1.5], 'xTz': [4.0, 1.5], 'yTz': [4.0, 1.5]}
21:27:18 [QML 11] Normal Prior 
Means: [ 4.  4.  4.  4.  4.  4.] 
Cov mtx: [[ 2.25  0.    0.    0.    0.    0.  ]
 [ 0.    2.25  0.    0.    0.    0.  ]
 [ 0.    0.    2.25  0.    0.    0.  ]
 [ 0.    0.    0.    2.25  0.    0.  ]
 [ 0.    0.    0.    0.    2.25  0.  ]
 [ 0.    0.    0.    0.    0.    2.25]] 
Samples: [[ 5.46015083  4.94240435  6.16926889  1.65590315  7.39490955  2.39012948]
 [ 3.61394693  6.44502988  2.23083502  4.17009441  4.87134985  3.82543879]
 [ 2.10706473  4.58589997  4.80294405  5.2844462   4.27635595  2.17796532]
 [ 1.18330807  3.00310347  2.40852542  3.29104518  5.2944708   3.01299656]
 [ 4.63686317  4.24556465  2.50102105  3.8094131   3.80685276  6.16292935]
 [ 5.853953    3.48037615  2.29396543  2.64568346  2.68787525  3.67205325]
 [ 4.37393845  6.11080853  3.66966182  1.82111093  5.29212771  1.36282446]
 [ 1.22242255  3.25326486  4.19521937  5.1830949   4.7311887   5.96095751]
 [ 6.16427619  4.65204328  2.90975218  2.82308669  4.98196593  3.38232082]
 [ 4.94396109  5.26793468  4.58717663  2.17877897  2.74929187  5.64615322]]
21:27:18 [GenSim (QML 11)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
21:27:18 [QML 11] Initialization Ready
21:27:18 [RQ Learn 11.0] Time to unpickle and initialise QML class: 0.10154938697814941
21:27:18 [RQ Learn 11.0] Updating model.
21:27:18 [QML 11] Experiment 0
21:27:18 [QML 11] Initial time selected >  0.1
21:29:42 [QML 11] Experiment 75
21:31:58 [QML 11] Experiment 150
21:34:16 [QML 11] Experiment 225
21:36:39 [QML 11] Experiment 300
21:39:4 [QML 11] Experiment 375
21:41:28 [QML 11] Experiment 450
21:43:55 [QML 11] Experiment 525
21:46:21 [QML 11] Experiment 600
21:48:48 [QML 11] Experiment 675
21:51:16 [QML 11] Results for QHL on  xTiPPxTxPPyTiPPyTyPPzTiPPzTz
21:51:16 [QML 11] Final time selected > 3.24
21:51:16 [QML 11] Cumulative time.	 Datum: 0.13567209243774414 	 Update: 1434.2743186950684
21:51:16 [QML 11] Final Parameters mean and stdev (term  xTi ): [-1.05663152  0.29386402]
21:51:16 [QML 11] Final Parameters mean and stdev (term  xTx ): [ 6.55479935  0.48265942]
21:51:16 [QML 11] Final Parameters mean and stdev (term  yTi ): [ 6.09030552  0.20046096]
21:51:16 [QML 11] Final Parameters mean and stdev (term  yTy ): [ 2.67049224  0.11140114]
21:51:16 [QML 11] Final Parameters mean and stdev (term  zTi ): [ 3.05276582  0.18823352]
21:51:16 [QML 11] Final Parameters mean and stdev (term  zTz ): [ 1.51275889  0.27275568]
21:51:16 [RQ Learn 11.0] Time for update alone: 1437.5092873573303
21:51:16 [RQ Learn 11.0] Redis learned_models_info added to db for model: 11.0
21:51:16 [RQ Learn 11.0] Redis SET learned_models_ids: 11.0 ; set True
21:51:16 [QMD 8] All models on branch 5 have finished learning.
21:51:16 [RQ Learn 11.0] Learned. rq time: 1437.792367696762
21:51:16 [QMD 8] remoteBayesFromBranchID 5 model id list: [11.0]
21:51:16 [QMD 8] compareModelsWithinBranch 5 active_models_in_branch_old: [11.0] active_models_in_branch_new: [11.0]
21:51:16 [QMD 8] Model points for branch 5 {11.0: 0}
21:51:16 [QMD 8] Champion of branch  5  is  xTiPPxTxPPyTiPPyTyPPzTiPPzTz (11)
21:51:16 [QMD 8] Spawning. Growth rule: two_qubit_ising_rotation_hyperfine_transverse. Depth: 6
21:51:16 [QMD 8] After model generation for growth rule two_qubit_ising_rotation_hyperfine_transverse SPAWN STAGE: [None] 
new models: ['xTiPPxTxPPyTiPPyTyPPyTzPPzTiPPzTz', 'xTiPPxTxPPxTzPPyTiPPyTyPPzTiPPzTz', 'xTiPPxTxPPxTyPPyTiPPyTyPPzTiPPzTz']
21:51:16 [QMD 8] Branch 6 growth rule two_qubit_ising_rotation_hyperfine_transverse has 3 new models ['xTiPPxTxPPyTiPPyTyPPyTzPPzTiPPzTz', 'xTiPPxTxPPxTzPPyTiPPyTyPPzTiPPzTz', 'xTiPPxTxPPxTyPPyTiPPyTyPPzTiPPzTz']
21:51:16 [DB] Model  xTiPPxTxPPyTiPPyTyPPyTzPPzTiPPzTz  not previously considered -- adding.
21:51:16 [QMD 8] Model  xTiPPxTxPPyTiPPyTyPPyTzPPzTiPPzTz 
	computed already:  False 
	ID: 12.0
21:51:16 [DB] Model  xTiPPxTxPPxTzPPyTiPPyTyPPzTiPPzTz  not previously considered -- adding.
21:51:16 [QMD 8] Model  xTiPPxTxPPxTzPPyTiPPyTyPPzTiPPzTz 
	computed already:  False 
	ID: 13.0
21:51:16 [DB] Model  xTiPPxTxPPxTyPPyTiPPyTyPPzTiPPzTz  not previously considered -- adding.
21:51:16 [QMD 8] Model  xTiPPxTxPPxTyPPyTiPPyTyPPzTiPPzTz 
	computed already:  False 
	ID: 14.0
21:51:16 [QMD 8] Num models already computed on branch  6 = 0
21:51:16 [QMD 8] Models to add to new branch ( 6 ):  ['xTiPPxTxPPyTiPPyTyPPyTzPPzTiPPzTz', 'xTiPPxTxPPxTzPPyTiPPyTyPPzTiPPzTz', 'xTiPPxTxPPxTyPPyTiPPyTyPPzTiPPzTz']
21:51:16 [QMD 8] learnModelFromBranchID branch 6 : ['xTiPPxTxPPyTiPPyTyPPyTzPPzTiPPzTz', 'xTiPPxTxPPxTzPPyTiPPyTyPPzTiPPzTz', 'xTiPPxTxPPxTyPPyTiPPyTyPPzTiPPzTz']
21:51:16 [QMD 8] learnModelFromBranchID. Setting active branches on redis for branch 6 to 0
21:51:16 [QMD 8] branch 6 precomputed: []
21:51:16 [QMD 8] Branch  6 has unlearned models: ['xTiPPxTxPPyTiPPyTyPPyTzPPzTiPPzTz', 'xTiPPxTxPPxTzPPyTiPPyTyPPzTiPPzTz', 'xTiPPxTxPPxTyPPyTiPPyTyPPzTiPPzTz']
21:51:16 [QMD 8] Model  xTiPPxTxPPyTiPPyTyPPyTzPPzTiPPzTz being passed to learnModel function
21:51:16 [QMD 8] Model xTiPPxTxPPyTiPPyTyPPyTzPPzTiPPzTz added to queue.
21:51:16 [QMD 8] Model  xTiPPxTxPPxTzPPyTiPPyTyPPzTiPPzTz being passed to learnModel function
21:51:16 [QMD 8] Model xTiPPxTxPPxTzPPyTiPPyTyPPzTiPPzTz added to queue.
21:51:16 [QMD 8] Model  xTiPPxTxPPxTyPPyTiPPyTyPPzTiPPzTz being passed to learnModel function
21:51:16 [QMD 8] Model xTiPPxTxPPxTyPPyTiPPyTyPPzTiPPzTz added to queue.
21:51:16 [QMD 8] learnModelFromBranchID finished, branch 6
21:51:22 [QML 12] QML for  xTiPPxTxPPyTiPPyTyPPyTzPPzTiPPzTz
21:51:22 [QML 14] QML for  xTiPPxTxPPxTyPPyTiPPyTyPPzTiPPzTz
21:51:22 [QML 13] QML for  xTiPPxTxPPxTzPPyTiPPyTyPPzTiPPzTz
21:51:22 [QML 12] Getting prior for model: xTiPPxTxPPyTiPPyTyPPyTzPPzTiPPzTz Specific terms: {'xTi': [4.0, 1.5], 'yTi': [4.0, 1.5], 'zTi': [4.0, 1.5], 'xTx': [4.0, 1.5], 'yTy': [4.0, 1.5], 'zTz': [4.0, 1.5], 'xTy': [4.0, 1.5], 'xTz': [4.0, 1.5], 'yTz': [4.0, 1.5]}
21:51:22 [QML 13] Getting prior for model: xTiPPxTxPPxTzPPyTiPPyTyPPzTiPPzTz Specific terms: {'xTi': [4.0, 1.5], 'yTi': [4.0, 1.5], 'zTi': [4.0, 1.5], 'xTx': [4.0, 1.5], 'yTy': [4.0, 1.5], 'zTz': [4.0, 1.5], 'xTy': [4.0, 1.5], 'xTz': [4.0, 1.5], 'yTz': [4.0, 1.5]}
21:51:22 [QML 14] Getting prior for model: xTiPPxTxPPxTyPPyTiPPyTyPPzTiPPzTz Specific terms: {'xTi': [4.0, 1.5], 'yTi': [4.0, 1.5], 'zTi': [4.0, 1.5], 'xTx': [4.0, 1.5], 'yTy': [4.0, 1.5], 'zTz': [4.0, 1.5], 'xTy': [4.0, 1.5], 'xTz': [4.0, 1.5], 'yTz': [4.0, 1.5]}
21:51:22 [QML 12] Normal Prior 
Means: [ 4.  4.  4.  4.  4.  4.  4.] 
Cov mtx: [[ 2.25  0.    0.    0.    0.    0.    0.  ]
 [ 0.    2.25  0.    0.    0.    0.    0.  ]
 [ 0.    0.    2.25  0.    0.    0.    0.  ]
 [ 0.    0.    0.    2.25  0.    0.    0.  ]
 [ 0.    0.    0.    0.    2.25  0.    0.  ]
 [ 0.    0.    0.    0.    0.    2.25  0.  ]
 [ 0.    0.    0.    0.    0.    0.    2.25]] 
Samples: [[ 7.32132859  4.28985554  3.48040489  2.3685636   2.87960374  3.71856392
   4.26887916]
 [ 1.76074978  3.70023793  4.10973904  4.34749761  5.68208296  1.64588911
   5.45671776]
 [ 5.09995945  4.07084714  3.84431684  2.97928195  5.34505587  2.94254733
   2.84107247]
 [ 8.24914167  7.03532191  5.52221215  2.86534715  3.01153335  3.78244199
   1.09621461]
 [ 5.31056513  3.26249912  4.65154808  4.69056035  3.60187864  3.33824097
   5.28753368]
 [ 5.16198061  5.22080184  4.07927315  2.8191578   2.1200667   4.85162659
   3.80736302]
 [ 5.61679777  3.07688042  5.85936582  2.10666032  4.26386086  3.32472381
   4.00093251]
 [ 6.02433198  5.34162426  0.58938215  4.84880308  2.17321034  6.90244418
   3.38442555]
 [ 4.16688783  2.9596276   5.29695955  2.5694205   5.71316931  5.57942147
   5.93703996]
 [ 4.14609525  4.08503274  5.47508054  5.30434714  4.63524942  5.08266275
   6.40224692]]
21:51:22 [GenSim (QML 12)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
21:51:22 [QML 14] Normal Prior 
Means: [ 4.  4.  4.  4.  4.  4.  4.] 
Cov mtx: [[ 2.25  0.    0.    0.    0.    0.    0.  ]
 [ 0.    2.25  0.    0.    0.    0.    0.  ]
 [ 0.    0.    2.25  0.    0.    0.    0.  ]
 [ 0.    0.    0.    2.25  0.    0.    0.  ]
 [ 0.    0.    0.    0.    2.25  0.    0.  ]
 [ 0.    0.    0.    0.    0.    2.25  0.  ]
 [ 0.    0.    0.    0.    0.    0.    2.25]] 
Samples: [[ 4.0464624   4.23167904  2.74956061  4.35510854  4.84300966  5.92243435
   5.88477759]
 [ 5.96319481  3.41776612  5.58048259  3.13861933  3.01669602  4.84895899
   1.4462193 ]
 [ 6.17268208  5.47639877  4.7656758   4.15621271  8.36821479  2.78352077
   4.76895449]
 [ 4.70572972  3.64266102  3.15627493  3.67938676  4.94896532  5.3609765
   2.5360461 ]
 [ 3.25299143  3.74537938  1.66637593  4.39369853  1.35346376  3.6352347
   2.43809388]
 [ 4.15575851  3.35718526  5.2755254   3.34042601  3.95922106  2.99831386
   2.17333428]
 [ 7.06350473  2.85390687  3.50629899  2.94337336  2.49393638  5.49792503
   1.46380645]
 [ 4.35913629  5.55441591  5.94425559  4.6857474   5.85620316  6.29003558
   2.19005849]
 [ 4.01166296  2.70631388  4.82395228  2.81211402  3.08675096  3.18908197
   3.73827172]
 [ 2.844933    5.94290414  0.99962096  4.65492611  3.79103379  2.40835336
   5.27540652]]
21:51:22 [QML 13] Normal Prior 
Means: [ 4.  4.  4.  4.  4.  4.  4.] 
Cov mtx: [[ 2.25  0.    0.    0.    0.    0.    0.  ]
 [ 0.    2.25  0.    0.    0.    0.    0.  ]
 [ 0.    0.    2.25  0.    0.    0.    0.  ]
 [ 0.    0.    0.    2.25  0.    0.    0.  ]
 [ 0.    0.    0.    0.    2.25  0.    0.  ]
 [ 0.    0.    0.    0.    0.    2.25  0.  ]
 [ 0.    0.    0.    0.    0.    0.    2.25]] 
Samples: [[ 5.97121764  4.3049616   4.63361346  6.02840562  2.05033041  0.68798353
   5.64885329]
 [ 4.62518727  5.05930853  3.55106144  5.84303434  3.57270568  1.51757512
   1.7020328 ]
 [ 3.98161171  4.83667241  4.32108481  4.60437421  3.30577087  2.32825011
   3.63717017]
 [ 3.13921183  2.50623696  2.58222015  5.03609631  3.239912    3.04244391
   3.34494397]
 [ 5.18929928  5.07845484  1.37156475  3.00988185  4.06248084  3.81742238
   4.32211795]
 [ 3.55061173  0.36018899  2.31953745  3.41087135  4.08495998  5.43534127
   4.12477444]
 [ 4.77854612  6.42361057  1.42664364  4.20817146  3.67649119  7.42873101
   2.11883275]
 [ 5.7760604   2.82834305  1.28907009  2.37685142  4.94348205  2.33411281
   6.10309409]
 [ 4.61077728  5.29903696  3.63702257  1.39931935  5.47134932  4.5860984
   4.43321017]
 [ 3.77027353  3.85734804  3.15377023  5.0913567   3.05168079  6.61306843
   3.77261508]]
21:51:22 [GenSim (QML 14)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
21:51:22 [GenSim (QML 13)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
21:51:22 [QML 12] Initialization Ready
21:51:22 [RQ Learn 12.0] Time to unpickle and initialise QML class: 0.10396742820739746
21:51:22 [RQ Learn 12.0] Updating model.
21:51:22 [QML 12] Experiment 0
21:51:22 [QML 14] Initialization Ready
21:51:22 [QML 13] Initialization Ready
21:51:22 [RQ Learn 14.0] Time to unpickle and initialise QML class: 0.10583209991455078
21:51:22 [QML 12] Initial time selected >  0.12
21:51:22 [RQ Learn 13.0] Time to unpickle and initialise QML class: 0.10614395141601562
21:51:22 [RQ Learn 14.0] Updating model.
21:51:22 [RQ Learn 13.0] Updating model.
21:51:22 [QML 14] Experiment 0
21:51:22 [QML 13] Experiment 0
21:51:22 [QML 14] Initial time selected >  0.09
21:51:22 [QML 13] Initial time selected >  0.09
21:53:35 [QML 12] Experiment 75
21:53:36 [QML 14] Experiment 75
21:53:36 [QML 13] Experiment 75
21:55:51 [QML 14] Experiment 150
21:55:52 [QML 12] Experiment 150
21:55:56 [QML 13] Experiment 150
21:58:6 [QML 14] Experiment 225
21:58:7 [QML 12] Experiment 225
21:58:13 [QML 13] Experiment 225
22:0:21 [QML 12] Experiment 300
22:0:28 [QML 14] Experiment 300
22:0:32 [QML 13] Experiment 300
22:2:37 [QML 12] Experiment 375
22:2:44 [QML 14] Experiment 375
22:2:48 [QML 13] Experiment 375
22:4:57 [QML 12] Experiment 450
22:5:4 [QML 14] Experiment 450
22:5:9 [QML 13] Experiment 450
22:7:19 [QML 12] Experiment 525
22:7:28 [QML 14] Experiment 525
22:7:32 [QML 13] Experiment 525
22:9:43 [QML 12] Experiment 600
22:9:53 [QML 14] Experiment 600
22:9:56 [QML 13] Experiment 600
22:12:7 [QML 12] Experiment 675
22:12:17 [QML 14] Experiment 675
22:12:20 [QML 13] Experiment 675
22:14:33 [QML 12] Results for QHL on  xTiPPxTxPPyTiPPyTyPPyTzPPzTiPPzTz
22:14:33 [QML 12] Final time selected > 3.24
22:14:33 [QML 12] Cumulative time.	 Datum: 0.12089085578918457 	 Update: 1387.756459236145
22:14:33 [QML 12] Final Parameters mean and stdev (term  xTi ): [ 1.84975774  0.34248344]
22:14:33 [QML 12] Final Parameters mean and stdev (term  xTx ): [ 4.240725    0.96281283]
22:14:33 [QML 12] Final Parameters mean and stdev (term  yTi ): [ 3.79877915  0.59746496]
22:14:33 [QML 12] Final Parameters mean and stdev (term  yTy ): [ 1.80310413  0.33692626]
22:14:33 [QML 12] Final Parameters mean and stdev (term  yTz ): [ 2.57559655  0.22775714]
22:14:33 [QML 12] Final Parameters mean and stdev (term  zTi ): [ 1.88253866  0.29885531]
22:14:33 [QML 12] Final Parameters mean and stdev (term  zTz ): [ 3.12416965  0.84983703]
22:14:33 [RQ Learn 12.0] Time for update alone: 1391.2089476585388
22:14:33 [RQ Learn 12.0] Redis learned_models_info added to db for model: 12.0
22:14:33 [RQ Learn 12.0] Redis SET learned_models_ids: 12.0 ; set True
22:14:33 [RQ Learn 12.0] Learned. rq time: 1391.500334262848
22:14:44 [QML 14] Results for QHL on  xTiPPxTxPPxTyPPyTiPPyTyPPzTiPPzTz
22:14:44 [QML 14] Final time selected > 3.24
22:14:44 [QML 14] Cumulative time.	 Datum: 0.11957836151123047 	 Update: 1398.3562495708466
22:14:44 [QML 14] Final Parameters mean and stdev (term  xTi ): [ 1.65982442  0.42919888]
22:14:44 [QML 14] Final Parameters mean and stdev (term  xTx ): [ 5.75798516  0.32616346]
22:14:44 [QML 14] Final Parameters mean and stdev (term  xTy ): [ 1.7012939   0.32389453]
22:14:44 [QML 14] Final Parameters mean and stdev (term  yTi ): [ 4.25512192  0.84719768]
22:14:44 [QML 14] Final Parameters mean and stdev (term  yTy ): [ 5.18520277  0.61382315]
22:14:44 [QML 14] Final Parameters mean and stdev (term  zTi ): [ 0.62440668  0.23850511]
22:14:44 [QML 14] Final Parameters mean and stdev (term  zTz ): [ 0.4649436   0.32728505]
22:14:44 [RQ Learn 14.0] Time for update alone: 1401.7840151786804
22:14:44 [RQ Learn 14.0] Redis learned_models_info added to db for model: 14.0
22:14:44 [RQ Learn 14.0] Redis SET learned_models_ids: 14.0 ; set True
22:14:44 [RQ Learn 14.0] Learned. rq time: 1402.0707054138184
22:14:47 [QML 13] Results for QHL on  xTiPPxTxPPxTzPPyTiPPyTyPPzTiPPzTz
22:14:47 [QML 13] Final time selected > 3.24
22:14:47 [QML 13] Cumulative time.	 Datum: 0.11961483955383301 	 Update: 1401.4493687152863
22:14:47 [QML 13] Final Parameters mean and stdev (term  xTi ): [ 1.32479534  0.3768683 ]
22:14:47 [QML 13] Final Parameters mean and stdev (term  xTx ): [ 4.81867505  0.4865366 ]
22:14:47 [QML 13] Final Parameters mean and stdev (term  xTz ): [ 2.58622616  0.94149917]
22:14:47 [QML 13] Final Parameters mean and stdev (term  yTi ): [ 7.72385004  0.51087289]
22:14:47 [QML 13] Final Parameters mean and stdev (term  yTy ): [ 5.53994871  0.49522734]
22:14:47 [QML 13] Final Parameters mean and stdev (term  zTi ): [ 5.02670376  0.55709643]
22:14:47 [QML 13] Final Parameters mean and stdev (term  zTz ): [ 6.26696158  0.71320708]
22:14:47 [RQ Learn 13.0] Time for update alone: 1404.8640797138214
22:14:47 [RQ Learn 13.0] Redis learned_models_info added to db for model: 13.0
22:14:47 [RQ Learn 13.0] Redis SET learned_models_ids: 13.0 ; set True
22:14:47 [QMD 8] All models on branch 6 have finished learning.
22:14:47 [RQ Learn 13.0] Learned. rq time: 1405.147644996643
22:14:47 [QMD 8] remoteBayesFromBranchID 6 model id list: [12.0, 13.0, 14.0]
22:14:47 [QMD 8] Computing BF for pair 12,13
22:14:47 [QMD 8] Bayes factor calculation queued. Model IDs 12.0 13.0
22:14:47 [QMD 8] Computing BF for pair 12,14
22:14:47 [QMD 8] Bayes factor calculation queued. Model IDs 12.0 14.0
22:14:47 [QMD 8] Computing BF for pair 13,14
22:14:47 [QMD 8] Bayes factor calculation queued. Model IDs 13.0 14.0
22:14:52 [GenSim (Bayes 12.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
22:14:52 [GenSim (Bayes 13.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
22:14:52 [RQ Bayes 12.0/13.0] Start. Branch 6
22:14:53 [GenSim (Bayes 13.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
22:14:53 [GenSim (Bayes 12.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
22:14:53 [GenSim (Bayes 14.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
22:14:53 [GenSim (Bayes 14.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
22:14:53 [RQ Bayes 13.0/14.0] Start. Branch 6
22:14:53 [RQ Bayes 12.0/14.0] Start. Branch 6
23:1:5 [RQ Bayes 12.0/14.0] BF computed: A:12.0; B:14.0; BF:0.0 	Reset remormalisation record: False
23:1:5 [RQ Bayes 12.0/14.0] Redis SET bayes_factors_db, pair: 12,14 bayes: 2.67045034347e-09
23:1:5 [RQ Bayes 12.0/14.0] Redis SET bayes_factors_winners_db, pair: 12,14 winner: 14.0
23:1:5 [RQ Bayes 12.0/14.0] Finished. rq time:  2772.7151958942413
23:1:32 [RQ Bayes 13.0/14.0] BF computed: A:13.0; B:14.0; BF:0.0 	Reset remormalisation record: False
23:1:32 [RQ Bayes 13.0/14.0] Redis SET bayes_factors_db, pair: 13,14 bayes: 6.61932552532e-17
23:1:32 [RQ Bayes 13.0/14.0] Redis SET bayes_factors_winners_db, pair: 13,14 winner: 14.0
23:1:32 [RQ Bayes 13.0/14.0] Finished. rq time:  2799.004010438919
23:1:54 [RQ Bayes 12.0/13.0] BF computed: A:12.0; B:13.0; BF:0.0 	Reset remormalisation record: False
23:1:54 [RQ Bayes 12.0/13.0] Redis SET bayes_factors_db, pair: 12,13 bayes: 4.81996934763e-08
23:1:54 [RQ Bayes 12.0/13.0] Redis SET bayes_factors_winners_db, pair: 12,13 winner: 13.0
23:1:54 [RQ Bayes 12.0/13.0] Finished. rq time:  2821.583910226822
23:1:54 [QMD 8] compareModelsWithinBranch 6 active_models_in_branch_old: [12.0, 13.0, 14.0] active_models_in_branch_new: [12.0, 13.0, 14.0]
23:1:54 [QMD 8] [compareModelsWithinBranch 6] Point to 13 (comparison 12.0/13.0)
23:1:54 [QMD 8] [compareModelsWithinBranch 6] Point to 14 (comparison 12.0/14.0)
23:1:54 [QMD 8] [compareModelsWithinBranch 6] Point to 14 (comparison 13.0/14.0)
23:1:54 [QMD 8] Model points for branch 6 {12.0: 0, 13.0: 1, 14.0: 2}
23:1:54 [QMD 8] Champion of branch  6  is  xTiPPxTxPPxTyPPyTiPPyTyPPzTiPPzTz (14)
23:1:54 [QMD 8] Spawning. Growth rule: two_qubit_ising_rotation_hyperfine_transverse. Depth: 7
23:1:54 [QMD 8] After model generation for growth rule two_qubit_ising_rotation_hyperfine_transverse SPAWN STAGE: [None] 
new models: ['xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPzTiPPzTz', 'xTiPPxTxPPxTyPPyTiPPyTyPPyTzPPzTiPPzTz']
23:1:54 [QMD 8] Branch 7 growth rule two_qubit_ising_rotation_hyperfine_transverse has 2 new models ['xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPzTiPPzTz', 'xTiPPxTxPPxTyPPyTiPPyTyPPyTzPPzTiPPzTz']
23:1:54 [DB] Model  xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPzTiPPzTz  not previously considered -- adding.
23:1:54 [QMD 8] Model  xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPzTiPPzTz 
	computed already:  False 
	ID: 15.0
23:1:54 [DB] Model  xTiPPxTxPPxTyPPyTiPPyTyPPyTzPPzTiPPzTz  not previously considered -- adding.
23:1:54 [QMD 8] Model  xTiPPxTxPPxTyPPyTiPPyTyPPyTzPPzTiPPzTz 
	computed already:  False 
	ID: 16.0
23:1:54 [QMD 8] Num models already computed on branch  7 = 0
23:1:54 [QMD 8] Models to add to new branch ( 7 ):  ['xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPzTiPPzTz', 'xTiPPxTxPPxTyPPyTiPPyTyPPyTzPPzTiPPzTz']
23:1:54 [QMD 8] learnModelFromBranchID branch 7 : ['xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPzTiPPzTz', 'xTiPPxTxPPxTyPPyTiPPyTyPPyTzPPzTiPPzTz']
23:1:54 [QMD 8] learnModelFromBranchID. Setting active branches on redis for branch 7 to 0
23:1:54 [QMD 8] branch 7 precomputed: []
23:1:54 [QMD 8] Branch  7 has unlearned models: ['xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPzTiPPzTz', 'xTiPPxTxPPxTyPPyTiPPyTyPPyTzPPzTiPPzTz']
23:1:54 [QMD 8] Model  xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPzTiPPzTz being passed to learnModel function
23:1:54 [QMD 8] Model xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPzTiPPzTz added to queue.
23:1:54 [QMD 8] Model  xTiPPxTxPPxTyPPyTiPPyTyPPyTzPPzTiPPzTz being passed to learnModel function
23:1:54 [QMD 8] Model xTiPPxTxPPxTyPPyTiPPyTyPPyTzPPzTiPPzTz added to queue.
23:1:54 [QMD 8] learnModelFromBranchID finished, branch 7
23:1:59 [QML 15] QML for  xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPzTiPPzTz
23:1:59 [QML 16] QML for  xTiPPxTxPPxTyPPyTiPPyTyPPyTzPPzTiPPzTz
23:1:59 [QML 15] Getting prior for model: xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPzTiPPzTz Specific terms: {'xTi': [4.0, 1.5], 'yTi': [4.0, 1.5], 'zTi': [4.0, 1.5], 'xTx': [4.0, 1.5], 'yTy': [4.0, 1.5], 'zTz': [4.0, 1.5], 'xTy': [4.0, 1.5], 'xTz': [4.0, 1.5], 'yTz': [4.0, 1.5]}
23:1:59 [QML 16] Getting prior for model: xTiPPxTxPPxTyPPyTiPPyTyPPyTzPPzTiPPzTz Specific terms: {'xTi': [4.0, 1.5], 'yTi': [4.0, 1.5], 'zTi': [4.0, 1.5], 'xTx': [4.0, 1.5], 'yTy': [4.0, 1.5], 'zTz': [4.0, 1.5], 'xTy': [4.0, 1.5], 'xTz': [4.0, 1.5], 'yTz': [4.0, 1.5]}
23:1:59 [QML 15] Normal Prior 
Means: [ 4.  4.  4.  4.  4.  4.  4.  4.] 
Cov mtx: [[ 2.25  0.    0.    0.    0.    0.    0.    0.  ]
 [ 0.    2.25  0.    0.    0.    0.    0.    0.  ]
 [ 0.    0.    2.25  0.    0.    0.    0.    0.  ]
 [ 0.    0.    0.    2.25  0.    0.    0.    0.  ]
 [ 0.    0.    0.    0.    2.25  0.    0.    0.  ]
 [ 0.    0.    0.    0.    0.    2.25  0.    0.  ]
 [ 0.    0.    0.    0.    0.    0.    2.25  0.  ]
 [ 0.    0.    0.    0.    0.    0.    0.    2.25]] 
Samples: [[ 2.86135487  5.59404675  3.71850894  1.41799362  4.69023694  2.06059512
   4.09974867  4.13891923]
 [ 4.91567743  4.31343617  4.0704954   2.71354522  1.35044909  3.21830258
   3.10002781  0.62069448]
 [ 4.07486375  2.56412108  1.38254322  4.34438359  4.54248892  4.27564024
   4.96367603  4.65374768]
 [ 5.17830407  0.76614439  6.54733631  3.65912299  4.55749208  6.29124294
   3.45441202  6.84147172]
 [ 2.67805499  2.0355892   4.92458415  1.35621755  3.68971455  2.85916108
   6.33550755  2.96833733]
 [ 5.66552246  3.10613903  5.02730819  3.6308243   4.9878895   4.44657925
   4.61662411  3.2387194 ]
 [ 2.49418662  5.0914615   1.12073934  1.87970482  4.97192341  3.29276639
   4.42634804  4.81057003]
 [ 3.61071213  2.64074873  1.29469491  4.08199494  2.37710931  4.80155733
   7.26886854  3.04870854]
 [ 4.47866819  3.37835591  3.33985397  4.94660125  4.32272186  6.34545743
   6.15199831  2.75034428]
 [ 3.09391916  6.18278616  5.40127462  2.74205443  3.59613144  3.16609493
   4.95240399  5.27824922]]
23:1:59 [GenSim (QML 15)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
23:1:59 [QML 16] Normal Prior 
Means: [ 4.  4.  4.  4.  4.  4.  4.  4.] 
Cov mtx: [[ 2.25  0.    0.    0.    0.    0.    0.    0.  ]
 [ 0.    2.25  0.    0.    0.    0.    0.    0.  ]
 [ 0.    0.    2.25  0.    0.    0.    0.    0.  ]
 [ 0.    0.    0.    2.25  0.    0.    0.    0.  ]
 [ 0.    0.    0.    0.    2.25  0.    0.    0.  ]
 [ 0.    0.    0.    0.    0.    2.25  0.    0.  ]
 [ 0.    0.    0.    0.    0.    0.    2.25  0.  ]
 [ 0.    0.    0.    0.    0.    0.    0.    2.25]] 
Samples: [[ 5.86499207  5.81482371  3.14725952  6.57043789  4.3769509   5.24824345
   3.03468755  4.8559514 ]
 [ 3.94230534  6.11751582  3.83319334  5.90751252  4.17931368  4.6719446
   4.33878263  4.50161574]
 [ 4.0825271   4.42096602  4.20530545  2.38479255  4.91911522  4.92702374
   3.63461258  4.67360412]
 [ 3.05926198  7.01950016  3.15858664  3.61133208  3.92134135  4.90679101
   5.63060459  4.58633189]
 [ 2.52362745  3.50458262  4.52193881  2.43905268  6.59269247  6.36006048
   4.14894735  1.33227613]
 [ 3.4200408   3.90995899  4.54668295  1.58716382  2.99829949  5.02496483
   5.51818832  2.86397496]
 [ 3.53781751  3.45126303  3.54383344  3.25066679  5.45975008  5.5475839
   3.55172622  7.26603181]
 [ 4.61391353  3.55481503  4.49954557  3.09303203  3.6810938   4.35983469
   1.80736011  3.07102285]
 [ 2.87313905  5.82893952  3.44358137  3.80370868  5.97035875  3.37991165
   4.67983718  2.96506965]
 [ 2.68024038  3.45463686  2.19468107  4.34660656  4.52254854  5.88003519
   3.89013183  2.2094089 ]]
23:1:59 [GenSim (QML 16)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
23:1:59 [QML 15] Initialization Ready
23:1:59 [RQ Learn 15.0] Time to unpickle and initialise QML class: 0.09369158744812012
23:1:59 [RQ Learn 15.0] Updating model.
23:1:59 [QML 15] Experiment 0
23:1:59 [QML 15] Initial time selected >  0.09
23:1:59 [QML 16] Initialization Ready
23:1:59 [RQ Learn 16.0] Time to unpickle and initialise QML class: 0.097991943359375
23:1:59 [RQ Learn 16.0] Updating model.
23:1:59 [QML 16] Experiment 0
23:1:59 [QML 16] Initial time selected >  0.1
23:4:8 [QML 15] Experiment 75
23:4:10 [QML 16] Experiment 75
23:6:19 [QML 15] Experiment 150
23:6:21 [QML 16] Experiment 150
23:8:30 [QML 16] Experiment 225
23:8:32 [QML 15] Experiment 225
23:10:39 [QML 16] Experiment 300
23:10:44 [QML 15] Experiment 300
23:12:51 [QML 16] Experiment 375
23:13:1 [QML 15] Experiment 375
23:15:13 [QML 16] Experiment 450
23:15:23 [QML 15] Experiment 450
23:17:41 [QML 16] Experiment 525
23:17:50 [QML 15] Experiment 525
23:20:7 [QML 16] Experiment 600
23:20:16 [QML 15] Experiment 600
23:22:40 [QML 16] Experiment 675
23:22:49 [QML 15] Experiment 675
23:25:9 [QML 16] Results for QHL on  xTiPPxTxPPxTyPPyTiPPyTyPPyTzPPzTiPPzTz
23:25:9 [QML 16] Final time selected > 3.24
23:25:9 [QML 16] Cumulative time.	 Datum: 0.11857366561889648 	 Update: 1385.9086940288544
23:25:9 [QML 16] Final Parameters mean and stdev (term  xTi ): [ 1.3264187   0.26602363]
23:25:9 [QML 16] Final Parameters mean and stdev (term  xTx ): [ 5.60730013  0.48007392]
23:25:9 [QML 16] Final Parameters mean and stdev (term  xTy ): [ 1.92122895  0.57157162]
23:25:9 [QML 16] Final Parameters mean and stdev (term  yTi ): [ 3.7976109   0.72283106]
23:25:9 [QML 16] Final Parameters mean and stdev (term  yTy ): [ 1.60385158  0.30770861]
23:25:9 [QML 16] Final Parameters mean and stdev (term  yTz ): [ 3.07983211  0.66988952]
23:25:9 [QML 16] Final Parameters mean and stdev (term  zTi ): [ 2.24720383  0.3191715 ]
23:25:9 [QML 16] Final Parameters mean and stdev (term  zTz ): [ 2.45606735  0.30496728]
23:25:9 [RQ Learn 16.0] Time for update alone: 1389.8764147758484
23:25:9 [RQ Learn 16.0] Redis learned_models_info added to db for model: 16.0
23:25:9 [RQ Learn 16.0] Redis SET learned_models_ids: 16.0 ; set True
23:25:9 [RQ Learn 16.0] Learned. rq time: 1390.1770927906036
23:25:17 [QML 15] Results for QHL on  xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPzTiPPzTz
23:25:17 [QML 15] Final time selected > 3.24
23:25:17 [QML 15] Cumulative time.	 Datum: 0.1205892562866211 	 Update: 1393.708872795105
23:25:17 [QML 15] Final Parameters mean and stdev (term  xTi ): [ 1.13117552  1.10778801]
23:25:17 [QML 15] Final Parameters mean and stdev (term  xTx ): [ 4.82826139  0.99337086]
23:25:17 [QML 15] Final Parameters mean and stdev (term  xTy ): [ 2.58417095  0.54910091]
23:25:17 [QML 15] Final Parameters mean and stdev (term  xTz ): [ 2.15953821  2.02342001]
23:25:17 [QML 15] Final Parameters mean and stdev (term  yTi ): [ 5.11373771  1.48384609]
23:25:17 [QML 15] Final Parameters mean and stdev (term  yTy ): [ 4.62348973  1.6858131 ]
23:25:17 [QML 15] Final Parameters mean and stdev (term  zTi ): [ 1.57078372  1.51269918]
23:25:17 [QML 15] Final Parameters mean and stdev (term  zTz ): [ 1.93318461  0.51302536]
23:25:17 [RQ Learn 15.0] Time for update alone: 1397.7070569992065
23:25:17 [RQ Learn 15.0] Redis learned_models_info added to db for model: 15.0
23:25:17 [RQ Learn 15.0] Redis SET learned_models_ids: 15.0 ; set True
23:25:17 [QMD 8] All models on branch 7 have finished learning.
23:25:17 [RQ Learn 15.0] Learned. rq time: 1398.0038626194
23:25:17 [QMD 8] remoteBayesFromBranchID 7 model id list: [15.0, 16.0]
23:25:17 [QMD 8] Computing BF for pair 15,16
23:25:17 [QMD 8] Bayes factor calculation queued. Model IDs 15.0 16.0
23:25:23 [GenSim (Bayes 15.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
23:25:23 [GenSim (Bayes 16.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
23:25:23 [RQ Bayes 15.0/16.0] Start. Branch 7
0:11:26 [RQ Bayes 15.0/16.0] BF computed: A:15.0; B:16.0; BF:0.0 	Reset remormalisation record: False
0:11:26 [RQ Bayes 15.0/16.0] Redis SET bayes_factors_db, pair: 15,16 bayes: 6.08911711289e-11
0:11:26 [RQ Bayes 15.0/16.0] Redis SET bayes_factors_winners_db, pair: 15,16 winner: 16.0
0:11:26 [RQ Bayes 15.0/16.0] Finished. rq time:  2763.4770436286926
0:11:26 [QMD 8] compareModelsWithinBranch 7 active_models_in_branch_old: [15.0, 16.0] active_models_in_branch_new: [15.0, 16.0]
0:11:26 [QMD 8] [compareModelsWithinBranch 7] Point to 16 (comparison 15.0/16.0)
0:11:26 [QMD 8] Model points for branch 7 {15.0: 0, 16.0: 1}
0:11:26 [QMD 8] Champion of branch  7  is  xTiPPxTxPPxTyPPyTiPPyTyPPyTzPPzTiPPzTz (16)
0:11:26 [QMD 8] Spawning. Growth rule: two_qubit_ising_rotation_hyperfine_transverse. Depth: 8
0:11:26 [QMD 8] After model generation for growth rule two_qubit_ising_rotation_hyperfine_transverse SPAWN STAGE: [None] 
new models: ['xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPyTzPPzTiPPzTz']
0:11:26 [QMD 8] Branch 8 growth rule two_qubit_ising_rotation_hyperfine_transverse has 1 new models ['xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPyTzPPzTiPPzTz']
0:11:26 [DB] Model  xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPyTzPPzTiPPzTz  not previously considered -- adding.
0:11:26 [QMD 8] Model  xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPyTzPPzTiPPzTz 
	computed already:  False 
	ID: 17.0
0:11:26 [QMD 8] Num models already computed on branch  8 = 0
0:11:26 [QMD 8] Models to add to new branch ( 8 ):  ['xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPyTzPPzTiPPzTz']
0:11:26 [QMD 8] learnModelFromBranchID branch 8 : ['xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPyTzPPzTiPPzTz']
0:11:26 [QMD 8] learnModelFromBranchID. Setting active branches on redis for branch 8 to 0
0:11:26 [QMD 8] branch 8 precomputed: []
0:11:26 [QMD 8] Branch  8 has unlearned models: ['xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPyTzPPzTiPPzTz']
0:11:26 [QMD 8] Model  xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPyTzPPzTiPPzTz being passed to learnModel function
0:11:26 [QMD 8] Model xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPyTzPPzTiPPzTz added to queue.
0:11:26 [QMD 8] learnModelFromBranchID finished, branch 8
0:11:26 [QMD 8] All trees have completed. Num complete: 1
0:11:32 [QML 17] QML for  xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPyTzPPzTiPPzTz
0:11:33 [QML 17] Getting prior for model: xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPyTzPPzTiPPzTz Specific terms: {'xTi': [4.0, 1.5], 'yTi': [4.0, 1.5], 'zTi': [4.0, 1.5], 'xTx': [4.0, 1.5], 'yTy': [4.0, 1.5], 'zTz': [4.0, 1.5], 'xTy': [4.0, 1.5], 'xTz': [4.0, 1.5], 'yTz': [4.0, 1.5]}
0:11:33 [QML 17] Normal Prior 
Means: [ 4.  4.  4.  4.  4.  4.  4.  4.  4.] 
Cov mtx: [[ 2.25  0.    0.    0.    0.    0.    0.    0.    0.  ]
 [ 0.    2.25  0.    0.    0.    0.    0.    0.    0.  ]
 [ 0.    0.    2.25  0.    0.    0.    0.    0.    0.  ]
 [ 0.    0.    0.    2.25  0.    0.    0.    0.    0.  ]
 [ 0.    0.    0.    0.    2.25  0.    0.    0.    0.  ]
 [ 0.    0.    0.    0.    0.    2.25  0.    0.    0.  ]
 [ 0.    0.    0.    0.    0.    0.    2.25  0.    0.  ]
 [ 0.    0.    0.    0.    0.    0.    0.    2.25  0.  ]
 [ 0.    0.    0.    0.    0.    0.    0.    0.    2.25]] 
Samples: [[ 3.29222535  6.90698263  2.64340197  3.28164606  4.66853873  2.97228941
   5.91634392  3.84968458  2.74487864]
 [ 3.86234915  3.98579022  2.9459127   3.78334758  4.65957084  4.57691772
   4.81741427  3.03912107  4.44646252]
 [ 5.52985529  5.57267628  4.35054779  2.51214232  3.24854927  4.25358003
   6.35527842  3.79367068  4.32772384]
 [ 3.03734103  5.16546261  1.90192978  5.45688824  4.32675475  3.86016487
   5.26759597  2.74016397  5.43063252]
 [ 3.32834272  2.22303464  1.46513581  3.13265922  5.25008116  6.76081945
   3.72879952  4.84040604  4.11551129]
 [ 4.2560038   3.37836482  4.64388841  5.82534258  3.11164302  4.62407964
   4.13010649  4.693531    2.83995874]
 [ 5.61416811  2.20274098  4.57529248  2.99190192  3.61166659  2.76708291
   6.16594305  3.82602675  4.10392842]
 [ 4.29866552  3.40407507  2.53627989  3.61392167  5.32285176  5.63474178
   2.11395634  6.41880944  3.00758031]
 [ 3.25158094  2.0848843   5.73002679  4.87718442  5.60448974  2.92866213
   6.42571964  4.85893409  5.2635289 ]
 [ 7.66864709  3.21227602  7.87998712  5.84132332  2.69261539  3.53619972
   4.12163065  4.26923937  1.57007072]]
0:11:33 [GenSim (QML 17)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
0:11:33 [QML 17] Initialization Ready
0:11:33 [RQ Learn 17.0] Time to unpickle and initialise QML class: 0.0996561050415039
0:11:33 [RQ Learn 17.0] Updating model.
0:11:33 [QML 17] Experiment 0
0:11:33 [QML 17] Initial time selected >  0.11
0:13:39 [QML 17] Experiment 75
0:15:46 [QML 17] Experiment 150
0:17:54 [QML 17] Experiment 225
0:20:5 [QML 17] Experiment 300
0:22:15 [QML 17] Experiment 375
0:24:40 [QML 17] Experiment 450
0:27:4 [QML 17] Experiment 525
0:29:29 [QML 17] Experiment 600
0:31:54 [QML 17] Experiment 675
0:34:20 [QML 17] Results for QHL on  xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPyTzPPzTiPPzTz
0:34:20 [QML 17] Final time selected > 3.24
0:34:20 [QML 17] Cumulative time.	 Datum: 0.13066530227661133 	 Update: 1362.5784816741943
0:34:20 [QML 17] Final Parameters mean and stdev (term  xTi ): [ 2.29894666  1.6645063 ]
0:34:20 [QML 17] Final Parameters mean and stdev (term  xTx ): [ 0.97239573  3.82872137]
0:34:20 [QML 17] Final Parameters mean and stdev (term  xTy ): [ 1.85319033  1.86401101]
0:34:20 [QML 17] Final Parameters mean and stdev (term  xTz ): [ 2.8765996   2.63485136]
0:34:20 [QML 17] Final Parameters mean and stdev (term  yTi ): [ 0.22061376  2.54408586]
0:34:20 [QML 17] Final Parameters mean and stdev (term  yTy ): [ 3.57651052  2.79170135]
0:34:20 [QML 17] Final Parameters mean and stdev (term  yTz ): [ 5.31070429  1.09753455]
0:34:20 [QML 17] Final Parameters mean and stdev (term  zTi ): [ 1.29481538  1.44642205]
0:34:20 [QML 17] Final Parameters mean and stdev (term  zTz ): [ 2.08808828  1.30632898]
0:34:20 [RQ Learn 17.0] Time for update alone: 1367.111474275589
0:34:20 [RQ Learn 17.0] Redis learned_models_info added to db for model: 17.0
0:34:20 [RQ Learn 17.0] Redis SET learned_models_ids: 17.0 ; set True
0:34:20 [QMD 8] remoteBayesFromBranchID 8 model id list: [17.0]
0:34:20 [RQ Learn 17.0] Learned. rq time: 1367.417620897293
0:34:20 [QMD 8] compareModelsWithinBranch 8 active_models_in_branch_old: [17.0] active_models_in_branch_new: [17.0]
0:34:20 [QMD 8] Model points for branch 8 {17.0: 0}
0:34:20 [QMD 8] Champion of branch  8  is  xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPyTzPPzTiPPzTz (17)
0:34:20 [QMD 8] Active branch champs at start of final Bayes comp: [2, 3, 5, 8, 10, 11, 14, 16, 17]
0:34:20 [QMD 8] Model 2 doesn't have a parent to compare with.
0:34:20 [QMD 8] Bayes factor calculation queued. Model IDs 2 3
0:34:20 [QMD 8] Comparing child  3 with parent 2
0:34:20 [QMD 8] Bayes factor calculation queued. Model IDs 3 5
0:34:20 [QMD 8] Comparing child  5 with parent 3
0:34:20 [QMD 8] Bayes factor calculation queued. Model IDs 5 8
0:34:20 [QMD 8] Comparing child  8 with parent 5
0:34:20 [QMD 8] Bayes factor calculation queued. Model IDs 8 10
0:34:20 [QMD 8] Comparing child  10 with parent 8
0:34:20 [QMD 8] Bayes factor calculation queued. Model IDs 10 11
0:34:20 [QMD 8] Comparing child  11 with parent 10
0:34:20 [QMD 8] Bayes factor calculation queued. Model IDs 11 14
0:34:20 [QMD 8] Comparing child  14 with parent 11
0:34:20 [QMD 8] Bayes factor calculation queued. Model IDs 14 16
0:34:20 [QMD 8] Comparing child  16 with parent 14
0:34:20 [QMD 8] Bayes factor calculation queued. Model IDs 16 17
0:34:20 [QMD 8] Comparing child  17 with parent 16
0:34:20 [QMD 8] Final Bayes Comparisons. 
Entering while loop in final bayes fnc. 
active branch champs:  [2, 3, 5, 8, 10, 11, 14, 16, 17]
0:34:20 [QMD 8] Waiting on parent/child Bayes factors.
0:34:20 [QMD 8] Waiting on parent/child Bayes factors.
0:34:25 [GenSim (Bayes 2)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
0:34:25 [GenSim (Bayes 11)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
0:34:26 [GenSim (Bayes 3)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
0:34:26 [RQ Bayes 2/3] Start. Branch None
0:34:26 [GenSim (Bayes 14)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
0:34:26 [RQ Bayes 11/14] Start. Branch None
0:34:26 [GenSim (Bayes 3)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
0:34:26 [GenSim (Bayes 8)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
0:34:26 [GenSim (Bayes 10)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
0:34:26 [GenSim (Bayes 5)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
0:34:26 [GenSim (Bayes 5)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
0:34:26 [RQ Bayes 3/5] Start. Branch None
0:34:26 [GenSim (Bayes 10)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
0:34:26 [GenSim (Bayes 11)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
0:34:26 [RQ Bayes 8/10] Start. Branch None
0:34:26 [RQ Bayes 10/11] Start. Branch None
0:34:26 [GenSim (Bayes 8)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
0:34:26 [RQ Bayes 5/8] Start. Branch None
1:22:2 [RQ Bayes 10/11] BF computed: A:10; B:11; BF:0.0 	Reset remormalisation record: False
1:22:2 [RQ Bayes 10/11] Redis SET bayes_factors_db, pair: 10,11 bayes: 0.000755781808161
1:22:2 [RQ Bayes 10/11] Redis SET bayes_factors_winners_db, pair: 10,11 winner: 11
1:22:2 [RQ Bayes 10/11] Finished. rq time:  2855.9428803920746
1:22:8 [GenSim (Bayes 14)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
1:22:8 [GenSim (Bayes 16)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
1:22:8 [RQ Bayes 14/16] Start. Branch None
1:22:22 [RQ Bayes 8/10] BF computed: A:8; B:10; BF:0.02 	Reset remormalisation record: False
1:22:22 [RQ Bayes 8/10] Redis SET bayes_factors_db, pair: 8,10 bayes: 0.0226826516615
1:22:22 [RQ Bayes 8/10] Neither model much better.
1:22:22 [RQ Bayes 8/10] Finished. rq time:  2876.138214826584
1:22:26 [GenSim (Bayes 16)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
1:22:26 [GenSim (Bayes 17)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
1:22:26 [RQ Bayes 16/17] Start. Branch None
1:22:51 [RQ Bayes 3/5] BF computed: A:3; B:5; BF:3.11262582229829e+68 	Reset remormalisation record: False
1:22:51 [RQ Bayes 3/5] Redis SET bayes_factors_db, pair: 3,5 bayes: 3.1126258223e+68
1:22:51 [RQ Bayes 3/5] Redis SET bayes_factors_winners_db, pair: 3,5 winner: 3
1:22:51 [RQ Bayes 3/5] Finished. rq time:  2905.535053730011
1:22:57 [RQ Bayes 11/14] BF computed: A:11; B:14; BF:2194726729.61 	Reset remormalisation record: False
1:22:57 [RQ Bayes 11/14] Redis SET bayes_factors_db, pair: 11,14 bayes: 2194726729.61
1:22:57 [RQ Bayes 11/14] Redis SET bayes_factors_winners_db, pair: 11,14 winner: 11
1:22:57 [RQ Bayes 11/14] Finished. rq time:  2911.7178905010223
1:23:7 [RQ Bayes 5/8] BF computed: A:5; B:8; BF:0.0 	Reset remormalisation record: False
1:23:7 [RQ Bayes 5/8] Redis SET bayes_factors_db, pair: 5,8 bayes: 7.72023949119e-82
1:23:7 [RQ Bayes 5/8] Redis SET bayes_factors_winners_db, pair: 5,8 winner: 8
1:23:7 [RQ Bayes 5/8] Finished. rq time:  2921.452198266983
1:30:4 [RQ Bayes 2/3] BF computed: A:2; B:3; BF:0.0 	Reset remormalisation record: False
1:30:4 [RQ Bayes 2/3] Redis SET bayes_factors_db, pair: 2,3 bayes: 1e-160
1:30:4 [RQ Bayes 2/3] Redis SET bayes_factors_winners_db, pair: 2,3 winner: 3
1:30:4 [RQ Bayes 2/3] Finished. rq time:  3338.3748524188995
1:30:4 [QMD 8] Waiting on parent/child Bayes factors.
1:30:4 [QMD 8] Waiting on parent/child Bayes factors.
1:30:4 [QMD 8] Waiting on parent/child Bayes factors.
1:30:4 [QMD 8] Waiting on parent/child Bayes factors.
1:30:4 [QMD 8] Waiting on parent/child Bayes factors.
1:30:4 [QMD 8] Waiting on parent/child Bayes factors.
2:7:31 [RQ Bayes 14/16] BF computed: A:14; B:16; BF:2315519.88 	Reset remormalisation record: False
2:7:31 [RQ Bayes 14/16] Redis SET bayes_factors_db, pair: 14,16 bayes: 2315519.88437
2:7:31 [RQ Bayes 14/16] Redis SET bayes_factors_winners_db, pair: 14,16 winner: 14
2:7:31 [RQ Bayes 14/16] Finished. rq time:  2723.2359499931335
2:7:31 [QMD 8] Waiting on parent/child Bayes factors.
2:7:54 [RQ Bayes 16/17] BF computed: A:16; B:17; BF:0.0 	Reset remormalisation record: False
2:7:54 [RQ Bayes 16/17] Redis SET bayes_factors_db, pair: 16,17 bayes: 0.00376326758078
2:7:54 [RQ Bayes 16/17] Redis SET bayes_factors_winners_db, pair: 16,17 winner: 17
2:7:54 [RQ Bayes 16/17] Finished. rq time:  2728.2197999954224
2:7:54 [QMD 8] child doesn't have active parent
2:7:54 [QMD 8] Spawned model 3 stronger than parent; deactivating model 2
2:7:54 [QMD 8] Spawned model 8 stronger than parent; deactivating model 5
2:7:54 [QMD 8] Parent model, 11 stronger than spawned; deactivating model 14
2:7:54 [QMD 8] Parent/child comparisons and deactivations complete.
2:7:54 [QMD 8] Active branch champs after  parental collapse (final Bayes comp): [3, 8, 10, 11, 16, 17]
2:7:54 [QMD 8] ActiveTreeBranchChamps: {'two_qubit_ising_rotation_hyperfine_transverse': [3, 8, 10, 11, 16, 17]}
2:7:54 [QMD 8] Branch 9 growth rule two_qubit_ising_rotation_hyperfine_transverse has 6 new models ['xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPyTzPPzTiPPzTz', 'xTiPPxTxPPxTyPPyTiPPyTyPPyTzPPzTiPPzTz', 'xTiPPxTxPPyTiPPyTyPPzTiPPzTz', 'xTiPPzTi', 'xTiPPyTiPPyTyPPzTi', 'xTiPPyTiPPyTyPPzTiPPzTz']
2:7:54 [DB] Model xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPyTzPPzTiPPzTz  previously considered.
2:7:54 [QMD 8] Model  xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPyTzPPzTiPPzTz 
	computed already:  True 
	ID: 17.0
2:7:54 [DB] Model xTiPPxTxPPxTyPPyTiPPyTyPPyTzPPzTiPPzTz  previously considered.
2:7:54 [QMD 8] Model  xTiPPxTxPPxTyPPyTiPPyTyPPyTzPPzTiPPzTz 
	computed already:  True 
	ID: 16.0
2:7:54 [DB] Model xTiPPxTxPPyTiPPyTyPPzTiPPzTz  previously considered.
2:7:54 [QMD 8] Model  xTiPPxTxPPyTiPPyTyPPzTiPPzTz 
	computed already:  True 
	ID: 11.0
2:7:54 [DB] Model xTiPPzTi  previously considered.
2:7:54 [QMD 8] Model  xTiPPzTi 
	computed already:  True 
	ID: 3.0
2:7:54 [DB] Model xTiPPyTiPPyTyPPzTi  previously considered.
2:7:54 [QMD 8] Model  xTiPPyTiPPyTyPPzTi 
	computed already:  True 
	ID: 8.0
2:7:54 [DB] Model xTiPPyTiPPyTyPPzTiPPzTz  previously considered.
2:7:54 [QMD 8] Model  xTiPPyTiPPyTyPPzTiPPzTz 
	computed already:  True 
	ID: 10.0
2:7:54 [QMD 8] Num models already computed on branch  9 = 6
2:7:54 [QMD 8] learnModelFromBranchID branch 9 : ['xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPyTzPPzTiPPzTz', 'xTiPPxTxPPxTyPPyTiPPyTyPPyTzPPzTiPPzTz', 'xTiPPxTxPPyTiPPyTyPPzTiPPzTz', 'xTiPPzTi', 'xTiPPyTiPPyTyPPzTi', 'xTiPPyTiPPyTyPPzTiPPzTz']
2:7:54 [QMD 8] learnModelFromBranchID. Setting active branches on redis for branch 9 to 6
2:7:54 [QMD 8] branch 9 precomputed: ['xTiPPxTxPPxTyPPxTzPPyTiPPyTyPPyTzPPzTiPPzTz', 'xTiPPxTxPPxTyPPyTiPPyTyPPyTzPPzTiPPzTz', 'xTiPPxTxPPyTiPPyTyPPzTiPPzTz', 'xTiPPzTi', 'xTiPPyTiPPyTyPPzTi', 'xTiPPyTiPPyTyPPzTiPPzTz']
2:7:54 [QMD 8] Branch  9 has unlearned models: []
2:7:54 [QMD 8] learnModelFromBranchID finished, branch 9
2:7:54 [QMD 8] remoteBayesFromBranchID 9 model id list: [17.0, 16.0, 11.0, 3.0, 8.0, 10.0]
2:7:54 [QMD 8] Computing BF for pair 16,17
2:7:54 [QMD 8] Bayes factor calculation queued. Model IDs 17.0 16.0
2:7:54 [QMD 8] Computing BF for pair 11,17
2:7:54 [QMD 8] Bayes factor calculation queued. Model IDs 17.0 11.0
2:7:54 [QMD 8] Computing BF for pair 3,17
2:7:54 [QMD 8] Bayes factor calculation queued. Model IDs 17.0 3.0
2:7:54 [QMD 8] Computing BF for pair 8,17
2:7:54 [QMD 8] Bayes factor calculation queued. Model IDs 17.0 8.0
2:7:54 [QMD 8] Computing BF for pair 10,17
2:7:54 [QMD 8] Bayes factor calculation queued. Model IDs 17.0 10.0
2:7:54 [QMD 8] Computing BF for pair 11,16
2:7:54 [QMD 8] Bayes factor calculation queued. Model IDs 16.0 11.0
2:7:54 [QMD 8] Computing BF for pair 3,16
2:7:54 [QMD 8] Bayes factor calculation queued. Model IDs 16.0 3.0
2:7:54 [QMD 8] Computing BF for pair 8,16
2:7:54 [QMD 8] Bayes factor calculation queued. Model IDs 16.0 8.0
2:7:54 [QMD 8] Computing BF for pair 10,16
2:7:54 [QMD 8] Bayes factor calculation queued. Model IDs 16.0 10.0
2:7:54 [QMD 8] Computing BF for pair 3,11
2:7:54 [QMD 8] Bayes factor calculation queued. Model IDs 11.0 3.0
2:7:54 [QMD 8] Computing BF for pair 8,11
2:7:54 [QMD 8] Bayes factor calculation queued. Model IDs 11.0 8.0
2:7:54 [QMD 8] Computing BF for pair 10,11
2:7:54 [QMD 8] Bayes factor calculation queued. Model IDs 11.0 10.0
2:7:54 [QMD 8] Computing BF for pair 3,8
2:7:54 [QMD 8] Bayes factor calculation queued. Model IDs 3.0 8.0
2:7:54 [QMD 8] Computing BF for pair 3,10
2:7:54 [QMD 8] Bayes factor calculation queued. Model IDs 3.0 10.0
2:7:54 [QMD 8] Computing BF for pair 8,10
2:7:54 [QMD 8] Bayes factor calculation queued. Model IDs 8.0 10.0
2:8:0 [GenSim (Bayes 16.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
2:8:0 [GenSim (Bayes 17.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
2:8:0 [GenSim (Bayes 17.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
2:8:0 [GenSim (Bayes 17.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
2:8:0 [GenSim (Bayes 11.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
2:8:0 [GenSim (Bayes 3.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
2:8:0 [GenSim (Bayes 16.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
2:8:0 [GenSim (Bayes 10.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
2:8:0 [RQ Bayes 16.0/11.0] Start. Branch 9
2:8:0 [RQ Bayes 17.0/3.0] Start. Branch 9
2:8:0 [RQ Bayes 17.0/10.0] Start. Branch 9
2:8:0 [RQ Bayes 17.0/16.0] Start. Branch 9
2:8:0 [GenSim (Bayes 17.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
2:8:0 [GenSim (Bayes 17.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
2:8:0 [GenSim (Bayes 11.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
2:8:0 [GenSim (Bayes 8.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
2:8:0 [RQ Bayes 17.0/11.0] Start. Branch 9
2:8:0 [RQ Bayes 17.0/8.0] Start. Branch 9
2:55:23 [RQ Bayes 17.0/16.0] BF computed: A:17.0; B:16.0; BF:0.0 	Reset remormalisation record: False
2:55:23 [RQ Bayes 17.0/16.0] Redis SET bayes_factors_db, pair: 16,17 bayes: 12562184.5525
2:55:23 [RQ Bayes 17.0/16.0] Redis SET bayes_factors_winners_db, pair: 16,17 winner: 16.0
2:55:23 [RQ Bayes 17.0/16.0] Finished. rq time:  2843.617982149124
2:55:29 [GenSim (Bayes 16.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
2:55:30 [GenSim (Bayes 3.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
2:55:30 [RQ Bayes 16.0/3.0] Start. Branch 9
2:55:58 [RQ Bayes 16.0/11.0] BF computed: A:16.0; B:11.0; BF:0.0 	Reset remormalisation record: False
2:55:58 [RQ Bayes 16.0/11.0] Redis SET bayes_factors_db, pair: 11,16 bayes: 46475980.5499
2:55:58 [RQ Bayes 16.0/11.0] Redis SET bayes_factors_winners_db, pair: 11,16 winner: 11.0
2:55:58 [RQ Bayes 16.0/11.0] Finished. rq time:  2878.911279439926
2:56:3 [GenSim (Bayes 16.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
2:56:4 [GenSim (Bayes 8.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
2:56:4 [RQ Bayes 16.0/8.0] Start. Branch 9
2:56:4 [RQ Bayes 17.0/3.0] BF computed: A:17.0; B:3.0; BF:7535391.59 	Reset remormalisation record: False
2:56:4 [RQ Bayes 17.0/3.0] Redis SET bayes_factors_db, pair: 3,17 bayes: 1.32707104579e-07
2:56:4 [RQ Bayes 17.0/3.0] Redis SET bayes_factors_winners_db, pair: 3,17 winner: 17.0
2:56:4 [RQ Bayes 17.0/3.0] Finished. rq time:  2884.892009973526
2:56:5 [RQ Bayes 17.0/10.0] BF computed: A:17.0; B:10.0; BF:0.0 	Reset remormalisation record: False
2:56:5 [RQ Bayes 17.0/10.0] Redis SET bayes_factors_db, pair: 10,17 bayes: 24302144.8866
2:56:5 [RQ Bayes 17.0/10.0] Redis SET bayes_factors_winners_db, pair: 10,17 winner: 10.0
2:56:5 [RQ Bayes 17.0/10.0] Finished. rq time:  2885.8370752334595
2:56:10 [GenSim (Bayes 16.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
2:56:10 [GenSim (Bayes 10.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
2:56:10 [RQ Bayes 16.0/10.0] Start. Branch 9
2:56:10 [GenSim (Bayes 11.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
2:56:11 [GenSim (Bayes 3.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
2:56:11 [RQ Bayes 11.0/3.0] Start. Branch 9
2:56:43 [RQ Bayes 17.0/8.0] BF computed: A:17.0; B:8.0; BF:0.0 	Reset remormalisation record: False
2:56:43 [RQ Bayes 17.0/8.0] Redis SET bayes_factors_db, pair: 8,17 bayes: 140574447.772
2:56:43 [RQ Bayes 17.0/8.0] Redis SET bayes_factors_winners_db, pair: 8,17 winner: 8.0
2:56:43 [RQ Bayes 17.0/8.0] Finished. rq time:  2922.5461626052856
2:56:47 [RQ Bayes 17.0/11.0] BF computed: A:17.0; B:11.0; BF:0.0 	Reset remormalisation record: False
2:56:47 [RQ Bayes 17.0/11.0] Redis SET bayes_factors_db, pair: 11,17 bayes: 1143223345.07
2:56:47 [RQ Bayes 17.0/11.0] Redis SET bayes_factors_winners_db, pair: 11,17 winner: 11.0
2:56:47 [RQ Bayes 17.0/11.0] Finished. rq time:  2926.688846349716
2:56:48 [GenSim (Bayes 11.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
2:56:48 [GenSim (Bayes 8.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
2:56:48 [RQ Bayes 11.0/8.0] Start. Branch 9
2:56:52 [GenSim (Bayes 11.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
2:56:52 [GenSim (Bayes 10.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
2:56:52 [RQ Bayes 11.0/10.0] Start. Branch 9
3:43:31 [RQ Bayes 16.0/3.0] BF computed: A:16.0; B:3.0; BF:0.0 	Reset remormalisation record: False
3:43:31 [RQ Bayes 16.0/3.0] Redis SET bayes_factors_db, pair: 3,16 bayes: 6006897.02981
3:43:31 [RQ Bayes 16.0/3.0] Redis SET bayes_factors_winners_db, pair: 3,16 winner: 3.0
3:43:31 [RQ Bayes 16.0/3.0] Finished. rq time:  2882.012853860855
3:43:38 [GenSim (Bayes 3.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
3:43:38 [GenSim (Bayes 8.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
3:43:38 [RQ Bayes 3.0/8.0] Start. Branch 9
3:43:53 [RQ Bayes 16.0/10.0] BF computed: A:16.0; B:10.0; BF:0.0 	Reset remormalisation record: False
3:43:53 [RQ Bayes 16.0/10.0] Redis SET bayes_factors_db, pair: 10,16 bayes: 4.95106880351e+12
3:43:53 [RQ Bayes 16.0/10.0] Redis SET bayes_factors_winners_db, pair: 10,16 winner: 10.0
3:43:53 [RQ Bayes 16.0/10.0] Finished. rq time:  2863.9703397750854
3:43:58 [GenSim (Bayes 3.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
3:43:58 [GenSim (Bayes 10.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
3:43:58 [RQ Bayes 3.0/10.0] Start. Branch 9
3:44:4 [RQ Bayes 11.0/3.0] BF computed: A:11.0; B:3.0; BF:1.9982259431676356e+20 	Reset remormalisation record: False
3:44:4 [RQ Bayes 11.0/3.0] Redis SET bayes_factors_db, pair: 3,11 bayes: 5.00443907967e-21
3:44:4 [RQ Bayes 11.0/3.0] Redis SET bayes_factors_winners_db, pair: 3,11 winner: 11.0
3:44:4 [RQ Bayes 11.0/3.0] Finished. rq time:  2873.9512281417847
3:44:9 [GenSim (Bayes 8.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
3:44:9 [GenSim (Bayes 10.0)] probe[(0,1)] [ 0.70675111 -7.41070079e-04j  0.70746188 +5.77768757e-06j]
3:44:9 [RQ Bayes 8.0/10.0] Start. Branch 9
3:44:21 [RQ Bayes 16.0/8.0] BF computed: A:16.0; B:8.0; BF:0.0 	Reset remormalisation record: False
3:44:21 [RQ Bayes 16.0/8.0] Redis SET bayes_factors_db, pair: 8,16 bayes: 339.134524114
3:44:21 [RQ Bayes 16.0/8.0] Redis SET bayes_factors_winners_db, pair: 8,16 winner: 8.0
3:44:21 [RQ Bayes 16.0/8.0] Finished. rq time:  2898.023310661316
3:45:52 [RQ Bayes 11.0/8.0] BF computed: A:11.0; B:8.0; BF:0.0 	Reset remormalisation record: False
3:45:52 [RQ Bayes 11.0/8.0] Redis SET bayes_factors_db, pair: 8,11 bayes: 45450550.5384
3:45:52 [RQ Bayes 11.0/8.0] Redis SET bayes_factors_winners_db, pair: 8,11 winner: 8.0
3:45:52 [RQ Bayes 11.0/8.0] Finished. rq time:  2943.3632457256317
3:45:59 [RQ Bayes 11.0/10.0] BF computed: A:11.0; B:10.0; BF:0.0 	Reset remormalisation record: False
3:45:59 [RQ Bayes 11.0/10.0] Redis SET bayes_factors_db, pair: 10,11 bayes: 4927757209.21
3:45:59 [RQ Bayes 11.0/10.0] Redis SET bayes_factors_winners_db, pair: 10,11 winner: 10.0
3:45:59 [RQ Bayes 11.0/10.0] Finished. rq time:  2947.53661608696
4:31:3 [RQ Bayes 3.0/8.0] BF computed: A:3.0; B:8.0; BF:0.0 	Reset remormalisation record: False
4:31:3 [RQ Bayes 3.0/8.0] Redis SET bayes_factors_db, pair: 3,8 bayes: 1.95019427431e-23
4:31:3 [RQ Bayes 3.0/8.0] Redis SET bayes_factors_winners_db, pair: 3,8 winner: 8.0
4:31:3 [RQ Bayes 3.0/8.0] Finished. rq time:  2845.3710997104645
4:31:4 [RQ Bayes 3.0/10.0] BF computed: A:3.0; B:10.0; BF:0.0 	Reset remormalisation record: False
4:31:4 [RQ Bayes 3.0/10.0] Redis SET bayes_factors_db, pair: 3,10 bayes: 8.14227675368e-18
4:31:4 [RQ Bayes 3.0/10.0] Redis SET bayes_factors_winners_db, pair: 3,10 winner: 10.0
4:31:4 [RQ Bayes 3.0/10.0] Finished. rq time:  2826.129877090454
4:31:24 [RQ Bayes 8.0/10.0] BF computed: A:8.0; B:10.0; BF:18090559.24 	Reset remormalisation record: False
4:31:24 [RQ Bayes 8.0/10.0] Redis SET bayes_factors_db, pair: 8,10 bayes: 18090559.242
4:31:24 [RQ Bayes 8.0/10.0] Redis SET bayes_factors_winners_db, pair: 8,10 winner: 8.0
4:31:24 [RQ Bayes 8.0/10.0] Finished. rq time:  2834.4627096652985
4:31:24 [QMD 8] compareModelsWithinBranch 9 active_models_in_branch_old: [] active_models_in_branch_new: [17.0, 16.0, 11.0, 3.0, 8.0, 10.0]
4:31:24 [QMD 8] [compareModelsWithinBranch 9] Point to 16 (comparison 17.0/16.0)
4:31:24 [QMD 8] [compareModelsWithinBranch 9] Point to 11 (comparison 17.0/11.0)
4:31:24 [QMD 8] [compareModelsWithinBranch 9] Point to 17 (comparison 17.0/3.0)
4:31:24 [QMD 8] [compareModelsWithinBranch 9] Point to 8 (comparison 17.0/8.0)
4:31:24 [QMD 8] [compareModelsWithinBranch 9] Point to 10 (comparison 17.0/10.0)
4:31:24 [QMD 8] [compareModelsWithinBranch 9] Point to 11 (comparison 16.0/11.0)
4:31:24 [QMD 8] [compareModelsWithinBranch 9] Point to 3 (comparison 16.0/3.0)
4:31:24 [QMD 8] [compareModelsWithinBranch 9] Point to 8 (comparison 16.0/8.0)
4:31:24 [QMD 8] [compareModelsWithinBranch 9] Point to 10 (comparison 16.0/10.0)
4:31:24 [QMD 8] [compareModelsWithinBranch 9] Point to 11 (comparison 11.0/3.0)
4:31:24 [QMD 8] [compareModelsWithinBranch 9] Point to 8 (comparison 11.0/8.0)
4:31:24 [QMD 8] [compareModelsWithinBranch 9] Point to 10 (comparison 11.0/10.0)
4:31:24 [QMD 8] [compareModelsWithinBranch 9] Point to 8 (comparison 3.0/8.0)
4:31:24 [QMD 8] [compareModelsWithinBranch 9] Point to 10 (comparison 3.0/10.0)
4:31:24 [QMD 8] [compareModelsWithinBranch 9] Point to 8 (comparison 8.0/10.0)
4:31:24 [QMD 8] Model points for branch 9 {17.0: 1, 16.0: 1, 11.0: 3, 3.0: 1, 8.0: 5, 10.0: 4}
4:31:24 [QMD 8] Champion of branch  9  is  xTiPPyTiPPyTyPPzTi (8)
4:31:24 [QMD 8] Ghost Branch 9 deactivating model 3.0
4:31:24 [QMD 8] Ghost Branch 9 deactivating model 10.0
4:31:24 [QMD 8] Ghost Branch 9 deactivating model 11.0
4:31:24 [QMD 8] Ghost Branch 9 deactivating model 16.0
4:31:24 [QMD 8] Ghost Branch 9 deactivating model 17.0
4:31:24 [QMD 8] F i n a l   t r e e   c o m p a r i s o n s   c o m p l e t e .
4:31:24 [QMD 8] After initial interbranch comparisons,                 remaining active branch champions: [8.0]
4:31:24 [QMD 8] Waiting on result of  Bayes comparisons from given list: [8.0]
4:31:24 [QMD 8] After final Bayes comparisons (of branch champions) {8.0: 0}
4:31:24 [QMD 8] Final winner =  xTiPPyTiPPyTyPPzTi
4:31:24[QML:Reduced 8; QMD 8] Computing expectation values. 
Measurement Type: hahn_evolution 
LearnedHamiltonian [[ 1.99702703+0.j          0.00000000+0.j         -0.09883486-3.10676659j
  -2.99999974+0.j        ]
 [ 0.00000000+0.j          1.99702703+0.j          2.99999974+0.j
  -0.09883486-3.10676659j]
 [-0.09883486+3.10676659j  2.99999974+0.j         -1.99702703+0.j
   0.00000000+0.j        ]
 [-2.99999974+0.j         -0.09883486+3.10676659j  0.00000000+0.j
  -1.99702703+0.j        ]] 
Probe: [ 0.49971827 -4.83795104e-04j  0.50013082 +2.23249446e-04j
  0.50031730 -2.46059755e-05j  0.49983262 -6.92224955e-04j] 
Times: [0.0, 0.01, 0.02, 0.029999999999999999, 0.040000000000000001, 0.050000000000000003, 0.059999999999999998, 0.070000000000000007, 0.080000000000000002, 0.089999999999999997, 0.10000000000000001, 0.11, 0.12, 0.13, 0.14000000000000001, 0.14999999999999999, 0.16, 0.17000000000000001, 0.17999999999999999, 0.19, 0.20000000000000001, 0.20999999999999999, 0.22, 0.23000000000000001, 0.23999999999999999, 0.25, 0.26000000000000001, 0.27000000000000002, 0.28000000000000003, 0.28999999999999998, 0.29999999999999999, 0.31, 0.32000000000000001, 0.33000000000000002, 0.34000000000000002, 0.34999999999999998, 0.35999999999999999, 0.37, 0.38, 0.39000000000000001, 0.40000000000000002, 0.40999999999999998, 0.41999999999999998, 0.42999999999999999, 0.44, 0.45000000000000001, 0.46000000000000002, 0.46999999999999997, 0.47999999999999998, 0.48999999999999999, 0.5, 0.51000000000000001, 0.52000000000000002, 0.53000000000000003, 0.54000000000000004, 0.55000000000000004, 0.56000000000000005, 0.56999999999999995, 0.57999999999999996, 0.58999999999999997, 0.59999999999999998, 0.60999999999999999, 0.62, 0.63, 0.64000000000000001, 0.65000000000000002, 0.66000000000000003, 0.67000000000000004, 0.68000000000000005, 0.68999999999999995, 0.69999999999999996, 0.70999999999999996, 0.71999999999999997, 0.72999999999999998, 0.73999999999999999, 0.75, 0.76000000000000001, 0.77000000000000002, 0.78000000000000003, 0.79000000000000004, 0.80000000000000004, 0.81000000000000005, 0.81999999999999995, 0.82999999999999996, 0.83999999999999997, 0.84999999999999998, 0.85999999999999999, 0.87, 0.88, 0.89000000000000001, 0.90000000000000002, 0.91000000000000003, 0.92000000000000004, 0.93000000000000005, 0.93999999999999995, 0.94999999999999996, 0.95999999999999996, 0.96999999999999997, 0.97999999999999998, 0.98999999999999999, 1.0, 1.01, 1.02, 1.03, 1.04, 1.05, 1.0600000000000001, 1.0700000000000001, 1.0800000000000001, 1.0900000000000001, 1.1000000000000001, 1.1100000000000001, 1.1200000000000001, 1.1299999999999999, 1.1399999999999999, 1.1499999999999999, 1.1599999999999999, 1.1699999999999999, 1.1799999999999999, 1.1899999999999999, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3, 1.3100000000000001, 1.3200000000000001, 1.3300000000000001, 1.3400000000000001, 1.3500000000000001, 1.3600000000000001, 1.3700000000000001, 1.3799999999999999, 1.3899999999999999, 1.3999999999999999, 1.4099999999999999, 1.4199999999999999, 1.4299999999999999, 1.4399999999999999, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5, 1.51, 1.52, 1.53, 1.54, 1.55, 1.5600000000000001, 1.5700000000000001, 1.5800000000000001, 1.5900000000000001, 1.6000000000000001, 1.6100000000000001, 1.6200000000000001, 1.6299999999999999, 1.6399999999999999, 1.6499999999999999, 1.6599999999999999, 1.6699999999999999, 1.6799999999999999, 1.6899999999999999, 1.7, 1.71, 1.72, 1.73, 1.74, 1.75, 1.76, 1.77, 1.78, 1.79, 1.8, 1.8100000000000001, 1.8200000000000001, 1.8300000000000001, 1.8400000000000001, 1.8500000000000001, 1.8600000000000001, 1.8700000000000001, 1.8799999999999999, 1.8899999999999999, 1.8999999999999999, 1.9099999999999999, 1.9199999999999999, 1.9299999999999999, 1.9399999999999999, 1.95, 1.96, 1.97, 1.98, 1.99, 2.0, 2.0099999999999998, 2.02, 2.0299999999999998, 2.04, 2.0499999999999998, 2.0600000000000001, 2.0699999999999998, 2.0800000000000001, 2.0899999999999999, 2.1000000000000001, 2.1099999999999999, 2.1200000000000001, 2.1299999999999999, 2.1400000000000001, 2.1499999999999999, 2.1600000000000001, 2.1699999999999999, 2.1800000000000002, 2.1899999999999999, 2.2000000000000002, 2.21, 2.2200000000000002, 2.23, 2.2400000000000002, 2.25, 2.2599999999999998, 2.27, 2.2799999999999998, 2.29, 2.2999999999999998, 2.3100000000000001, 2.3199999999999998, 2.3300000000000001, 2.3399999999999999, 2.3500000000000001, 2.3599999999999999, 2.3700000000000001, 2.3799999999999999, 2.3900000000000001, 2.3999999999999999, 2.4100000000000001, 2.4199999999999999, 2.4300000000000002, 2.4399999999999999, 2.4500000000000002, 2.46, 2.4700000000000002, 2.48, 2.4900000000000002, 2.5, 2.5099999999999998, 2.52, 2.5299999999999998, 2.54, 2.5499999999999998, 2.5600000000000001, 2.5699999999999998, 2.5800000000000001, 2.5899999999999999, 2.6000000000000001, 2.6099999999999999, 2.6200000000000001, 2.6299999999999999, 2.6400000000000001, 2.6499999999999999, 2.6600000000000001, 2.6699999999999999, 2.6800000000000002, 2.6899999999999999, 2.7000000000000002, 2.71, 2.7200000000000002, 2.73, 2.7400000000000002, 2.75, 2.7599999999999998, 2.77, 2.7799999999999998, 2.79, 2.7999999999999998, 2.8100000000000001, 2.8199999999999998, 2.8300000000000001, 2.8399999999999999, 2.8500000000000001, 2.8599999999999999, 2.8700000000000001, 2.8799999999999999, 2.8900000000000001, 2.8999999999999999, 2.9100000000000001, 2.9199999999999999, 2.9300000000000002, 2.9399999999999999, 2.9500000000000002, 2.96, 2.9700000000000002, 2.98, 2.9900000000000002, 3.0, 3.0099999999999998, 3.02, 3.0299999999999998, 3.04, 3.0499999999999998, 3.0600000000000001, 3.0699999999999998, 3.0800000000000001, 3.0899999999999999, 3.1000000000000001, 3.1099999999999999, 3.1200000000000001, 3.1299999999999999, 3.1400000000000001, 3.1499999999999999, 3.1600000000000001, 3.1699999999999999, 3.1800000000000002, 3.1899999999999999, 3.2000000000000002, 3.21, 3.2200000000000002, 3.23, 3.2400000000000002, 3.25, 3.2599999999999998, 3.27, 3.2799999999999998, 3.29, 3.2999999999999998, 3.3100000000000001, 3.3199999999999998, 3.3300000000000001, 3.3399999999999999, 3.3500000000000001, 3.3599999999999999, 3.3700000000000001, 3.3799999999999999, 3.3900000000000001, 3.3999999999999999, 3.4100000000000001, 3.4199999999999999, 3.4300000000000002, 3.4399999999999999, 3.4500000000000002, 3.46, 3.4700000000000002, 3.48, 3.4900000000000002, 3.5, 3.5099999999999998, 3.52, 3.5299999999999998, 3.54, 3.5499999999999998, 3.5600000000000001, 3.5699999999999998, 3.5800000000000001, 3.5899999999999999, 3.6000000000000001, 3.6099999999999999, 3.6200000000000001, 3.6299999999999999, 3.6400000000000001, 3.6499999999999999, 3.6600000000000001, 3.6699999999999999, 3.6800000000000002, 3.6899999999999999, 3.7000000000000002, 3.71, 3.7200000000000002, 3.73, 3.7400000000000002, 3.75, 3.7599999999999998, 3.77, 3.7799999999999998, 3.79, 3.7999999999999998, 3.8100000000000001, 3.8199999999999998, 3.8300000000000001, 3.8399999999999999, 3.8500000000000001, 3.8599999999999999, 3.8700000000000001, 3.8799999999999999, 3.8900000000000001, 3.8999999999999999, 3.9100000000000001, 3.9199999999999999, 3.9300000000000002, 3.9399999999999999, 3.9500000000000002, 3.96, 3.9700000000000002, 3.98, 3.9900000000000002, 4.0, 4.0099999999999998, 4.0199999999999996, 4.0300000000000002, 4.04, 4.0499999999999998, 4.0599999999999996, 4.0700000000000003, 4.0800000000000001, 4.0899999999999999, 4.0999999999999996, 4.1100000000000003, 4.1200000000000001, 4.1299999999999999, 4.1399999999999997, 4.1500000000000004, 4.1600000000000001, 4.1699999999999999, 4.1799999999999997, 4.1900000000000004, 4.2000000000000002, 4.21, 4.2199999999999998, 4.2300000000000004, 4.2400000000000002]
4:31:24[QML:Reduced 8; QMD 8] [compute expectation values] times to compute: [0.0, 0.01, 0.02, 0.029999999999999999, 0.040000000000000001, 0.050000000000000003, 0.059999999999999998, 0.070000000000000007, 0.080000000000000002, 0.089999999999999997, 0.10000000000000001, 0.11, 0.12, 0.13, 0.14000000000000001, 0.14999999999999999, 0.16, 0.17000000000000001, 0.17999999999999999, 0.19, 0.20000000000000001, 0.20999999999999999, 0.22, 0.23000000000000001, 0.23999999999999999, 0.25, 0.26000000000000001, 0.27000000000000002, 0.28000000000000003, 0.28999999999999998, 0.29999999999999999, 0.31, 0.32000000000000001, 0.33000000000000002, 0.34000000000000002, 0.34999999999999998, 0.35999999999999999, 0.37, 0.38, 0.39000000000000001, 0.40000000000000002, 0.40999999999999998, 0.41999999999999998, 0.42999999999999999, 0.44, 0.45000000000000001, 0.46000000000000002, 0.46999999999999997, 0.47999999999999998, 0.48999999999999999, 0.5, 0.51000000000000001, 0.52000000000000002, 0.53000000000000003, 0.54000000000000004, 0.55000000000000004, 0.56000000000000005, 0.56999999999999995, 0.57999999999999996, 0.58999999999999997, 0.59999999999999998, 0.60999999999999999, 0.62, 0.63, 0.64000000000000001, 0.65000000000000002, 0.66000000000000003, 0.67000000000000004, 0.68000000000000005, 0.68999999999999995, 0.69999999999999996, 0.70999999999999996, 0.71999999999999997, 0.72999999999999998, 0.73999999999999999, 0.75, 0.76000000000000001, 0.77000000000000002, 0.78000000000000003, 0.79000000000000004, 0.80000000000000004, 0.81000000000000005, 0.81999999999999995, 0.82999999999999996, 0.83999999999999997, 0.84999999999999998, 0.85999999999999999, 0.87, 0.88, 0.89000000000000001, 0.90000000000000002, 0.91000000000000003, 0.92000000000000004, 0.93000000000000005, 0.93999999999999995, 0.94999999999999996, 0.95999999999999996, 0.96999999999999997, 0.97999999999999998, 0.98999999999999999, 1.0, 1.01, 1.02, 1.03, 1.04, 1.05, 1.0600000000000001, 1.0700000000000001, 1.0800000000000001, 1.0900000000000001, 1.1000000000000001, 1.1100000000000001, 1.1200000000000001, 1.1299999999999999, 1.1399999999999999, 1.1499999999999999, 1.1599999999999999, 1.1699999999999999, 1.1799999999999999, 1.1899999999999999, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3, 1.3100000000000001, 1.3200000000000001, 1.3300000000000001, 1.3400000000000001, 1.3500000000000001, 1.3600000000000001, 1.3700000000000001, 1.3799999999999999, 1.3899999999999999, 1.3999999999999999, 1.4099999999999999, 1.4199999999999999, 1.4299999999999999, 1.4399999999999999, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5, 1.51, 1.52, 1.53, 1.54, 1.55, 1.5600000000000001, 1.5700000000000001, 1.5800000000000001, 1.5900000000000001, 1.6000000000000001, 1.6100000000000001, 1.6200000000000001, 1.6299999999999999, 1.6399999999999999, 1.6499999999999999, 1.6599999999999999, 1.6699999999999999, 1.6799999999999999, 1.6899999999999999, 1.7, 1.71, 1.72, 1.73, 1.74, 1.75, 1.76, 1.77, 1.78, 1.79, 1.8, 1.8100000000000001, 1.8200000000000001, 1.8300000000000001, 1.8400000000000001, 1.8500000000000001, 1.8600000000000001, 1.8700000000000001, 1.8799999999999999, 1.8899999999999999, 1.8999999999999999, 1.9099999999999999, 1.9199999999999999, 1.9299999999999999, 1.9399999999999999, 1.95, 1.96, 1.97, 1.98, 1.99, 2.0, 2.0099999999999998, 2.02, 2.0299999999999998, 2.04, 2.0499999999999998, 2.0600000000000001, 2.0699999999999998, 2.0800000000000001, 2.0899999999999999, 2.1000000000000001, 2.1099999999999999, 2.1200000000000001, 2.1299999999999999, 2.1400000000000001, 2.1499999999999999, 2.1600000000000001, 2.1699999999999999, 2.1800000000000002, 2.1899999999999999, 2.2000000000000002, 2.21, 2.2200000000000002, 2.23, 2.2400000000000002, 2.25, 2.2599999999999998, 2.27, 2.2799999999999998, 2.29, 2.2999999999999998, 2.3100000000000001, 2.3199999999999998, 2.3300000000000001, 2.3399999999999999, 2.3500000000000001, 2.3599999999999999, 2.3700000000000001, 2.3799999999999999, 2.3900000000000001, 2.3999999999999999, 2.4100000000000001, 2.4199999999999999, 2.4300000000000002, 2.4399999999999999, 2.4500000000000002, 2.46, 2.4700000000000002, 2.48, 2.4900000000000002, 2.5, 2.5099999999999998, 2.52, 2.5299999999999998, 2.54, 2.5499999999999998, 2.5600000000000001, 2.5699999999999998, 2.5800000000000001, 2.5899999999999999, 2.6000000000000001, 2.6099999999999999, 2.6200000000000001, 2.6299999999999999, 2.6400000000000001, 2.6499999999999999, 2.6600000000000001, 2.6699999999999999, 2.6800000000000002, 2.6899999999999999, 2.7000000000000002, 2.71, 2.7200000000000002, 2.73, 2.7400000000000002, 2.75, 2.7599999999999998, 2.77, 2.7799999999999998, 2.79, 2.7999999999999998, 2.8100000000000001, 2.8199999999999998, 2.8300000000000001, 2.8399999999999999, 2.8500000000000001, 2.8599999999999999, 2.8700000000000001, 2.8799999999999999, 2.8900000000000001, 2.8999999999999999, 2.9100000000000001, 2.9199999999999999, 2.9300000000000002, 2.9399999999999999, 2.9500000000000002, 2.96, 2.9700000000000002, 2.98, 2.9900000000000002, 3.0, 3.0099999999999998, 3.02, 3.0299999999999998, 3.04, 3.0499999999999998, 3.0600000000000001, 3.0699999999999998, 3.0800000000000001, 3.0899999999999999, 3.1000000000000001, 3.1099999999999999, 3.1200000000000001, 3.1299999999999999, 3.1400000000000001, 3.1499999999999999, 3.1600000000000001, 3.1699999999999999, 3.1800000000000002, 3.1899999999999999, 3.2000000000000002, 3.21, 3.2200000000000002, 3.23, 3.2400000000000002, 3.25, 3.2599999999999998, 3.27, 3.2799999999999998, 3.29, 3.2999999999999998, 3.3100000000000001, 3.3199999999999998, 3.3300000000000001, 3.3399999999999999, 3.3500000000000001, 3.3599999999999999, 3.3700000000000001, 3.3799999999999999, 3.3900000000000001, 3.3999999999999999, 3.4100000000000001, 3.4199999999999999, 3.4300000000000002, 3.4399999999999999, 3.4500000000000002, 3.46, 3.4700000000000002, 3.48, 3.4900000000000002, 3.5, 3.5099999999999998, 3.52, 3.5299999999999998, 3.54, 3.5499999999999998, 3.5600000000000001, 3.5699999999999998, 3.5800000000000001, 3.5899999999999999, 3.6000000000000001, 3.6099999999999999, 3.6200000000000001, 3.6299999999999999, 3.6400000000000001, 3.6499999999999999, 3.6600000000000001, 3.6699999999999999, 3.6800000000000002, 3.6899999999999999, 3.7000000000000002, 3.71, 3.7200000000000002, 3.73, 3.7400000000000002, 3.75, 3.7599999999999998, 3.77, 3.7799999999999998, 3.79, 3.7999999999999998, 3.8100000000000001, 3.8199999999999998, 3.8300000000000001, 3.8399999999999999, 3.8500000000000001, 3.8599999999999999, 3.8700000000000001, 3.8799999999999999, 3.8900000000000001, 3.8999999999999999, 3.9100000000000001, 3.9199999999999999, 3.9300000000000002, 3.9399999999999999, 3.9500000000000002, 3.96, 3.9700000000000002, 3.98, 3.9900000000000002, 4.0, 4.0099999999999998, 4.0199999999999996, 4.0300000000000002, 4.04, 4.0499999999999998, 4.0599999999999996, 4.0700000000000003, 4.0800000000000001, 4.0899999999999999, 4.0999999999999996, 4.1100000000000003, 4.1200000000000001, 4.1299999999999999, 4.1399999999999997, 4.1500000000000004, 4.1600000000000001, 4.1699999999999999, 4.1799999999999997, 4.1900000000000004, 4.2000000000000002, 4.21, 4.2199999999999998, 4.2300000000000004, 4.2400000000000002]
4:31:24 [QMD 8] Num params - champ: 4 ; 	 true: 6
4:31:24 [QMD 8] Using default times to plot expectation values for num qubits: 2
4:31:24[QML:Reduced 8; QMD 8] R squared by epoch function for xTiPPyTiPPyTyPPzTi Times passed: [0.0, 0.01, 0.02, 0.029999999999999999, 0.040000000000000001, 0.050000000000000003, 0.059999999999999998, 0.070000000000000007, 0.080000000000000002, 0.089999999999999997, 0.10000000000000001, 0.11, 0.12, 0.13, 0.14000000000000001, 0.14999999999999999, 0.16, 0.17000000000000001, 0.17999999999999999, 0.19, 0.20000000000000001, 0.20999999999999999, 0.22, 0.23000000000000001, 0.23999999999999999, 0.25, 0.26000000000000001, 0.27000000000000002, 0.28000000000000003, 0.28999999999999998, 0.29999999999999999, 0.31, 0.32000000000000001, 0.33000000000000002, 0.34000000000000002, 0.34999999999999998, 0.35999999999999999, 0.37, 0.38, 0.39000000000000001, 0.40000000000000002, 0.40999999999999998, 0.41999999999999998, 0.42999999999999999, 0.44, 0.45000000000000001, 0.46000000000000002, 0.46999999999999997, 0.47999999999999998, 0.48999999999999999, 0.5, 0.51000000000000001, 0.52000000000000002, 0.53000000000000003, 0.54000000000000004, 0.55000000000000004, 0.56000000000000005, 0.56999999999999995, 0.57999999999999996, 0.58999999999999997, 0.59999999999999998, 0.60999999999999999, 0.62, 0.63, 0.64000000000000001, 0.65000000000000002, 0.66000000000000003, 0.67000000000000004, 0.68000000000000005, 0.68999999999999995, 0.69999999999999996, 0.70999999999999996, 0.71999999999999997, 0.72999999999999998, 0.73999999999999999, 0.75, 0.76000000000000001, 0.77000000000000002, 0.78000000000000003, 0.79000000000000004, 0.80000000000000004, 0.81000000000000005, 0.81999999999999995, 0.82999999999999996, 0.83999999999999997, 0.84999999999999998, 0.85999999999999999, 0.87, 0.88, 0.89000000000000001, 0.90000000000000002, 0.91000000000000003, 0.92000000000000004, 0.93000000000000005, 0.93999999999999995, 0.94999999999999996, 0.95999999999999996, 0.96999999999999997, 0.97999999999999998, 0.98999999999999999, 1.0, 1.01, 1.02, 1.03, 1.04, 1.05, 1.0600000000000001, 1.0700000000000001, 1.0800000000000001, 1.0900000000000001, 1.1000000000000001, 1.1100000000000001, 1.1200000000000001, 1.1299999999999999, 1.1399999999999999, 1.1499999999999999, 1.1599999999999999, 1.1699999999999999, 1.1799999999999999, 1.1899999999999999, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3, 1.3100000000000001, 1.3200000000000001, 1.3300000000000001, 1.3400000000000001, 1.3500000000000001, 1.3600000000000001, 1.3700000000000001, 1.3799999999999999, 1.3899999999999999, 1.3999999999999999, 1.4099999999999999, 1.4199999999999999, 1.4299999999999999, 1.4399999999999999, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5, 1.51, 1.52, 1.53, 1.54, 1.55, 1.5600000000000001, 1.5700000000000001, 1.5800000000000001, 1.5900000000000001, 1.6000000000000001, 1.6100000000000001, 1.6200000000000001, 1.6299999999999999, 1.6399999999999999, 1.6499999999999999, 1.6599999999999999, 1.6699999999999999, 1.6799999999999999, 1.6899999999999999, 1.7, 1.71, 1.72, 1.73, 1.74, 1.75, 1.76, 1.77, 1.78, 1.79, 1.8, 1.8100000000000001, 1.8200000000000001, 1.8300000000000001, 1.8400000000000001, 1.8500000000000001, 1.8600000000000001, 1.8700000000000001, 1.8799999999999999, 1.8899999999999999, 1.8999999999999999, 1.9099999999999999, 1.9199999999999999, 1.9299999999999999, 1.9399999999999999, 1.95, 1.96, 1.97, 1.98, 1.99, 2.0, 2.0099999999999998, 2.02, 2.0299999999999998, 2.04, 2.0499999999999998, 2.0600000000000001, 2.0699999999999998, 2.0800000000000001, 2.0899999999999999, 2.1000000000000001, 2.1099999999999999, 2.1200000000000001, 2.1299999999999999, 2.1400000000000001, 2.1499999999999999, 2.1600000000000001, 2.1699999999999999, 2.1800000000000002, 2.1899999999999999, 2.2000000000000002, 2.21, 2.2200000000000002, 2.23, 2.2400000000000002, 2.25, 2.2599999999999998, 2.27, 2.2799999999999998, 2.29, 2.2999999999999998, 2.3100000000000001, 2.3199999999999998, 2.3300000000000001, 2.3399999999999999, 2.3500000000000001, 2.3599999999999999, 2.3700000000000001, 2.3799999999999999, 2.3900000000000001, 2.3999999999999999, 2.4100000000000001, 2.4199999999999999, 2.4300000000000002, 2.4399999999999999, 2.4500000000000002, 2.46, 2.4700000000000002, 2.48, 2.4900000000000002, 2.5, 2.5099999999999998, 2.52, 2.5299999999999998, 2.54, 2.5499999999999998, 2.5600000000000001, 2.5699999999999998, 2.5800000000000001, 2.5899999999999999, 2.6000000000000001, 2.6099999999999999, 2.6200000000000001, 2.6299999999999999, 2.6400000000000001, 2.6499999999999999, 2.6600000000000001, 2.6699999999999999, 2.6800000000000002, 2.6899999999999999, 2.7000000000000002, 2.71, 2.7200000000000002, 2.73, 2.7400000000000002, 2.75, 2.7599999999999998, 2.77, 2.7799999999999998, 2.79, 2.7999999999999998, 2.8100000000000001, 2.8199999999999998, 2.8300000000000001, 2.8399999999999999, 2.8500000000000001, 2.8599999999999999, 2.8700000000000001, 2.8799999999999999, 2.8900000000000001, 2.8999999999999999, 2.9100000000000001, 2.9199999999999999, 2.9300000000000002, 2.9399999999999999, 2.9500000000000002, 2.96, 2.9700000000000002, 2.98, 2.9900000000000002, 3.0, 3.0099999999999998, 3.02, 3.0299999999999998, 3.04, 3.0499999999999998, 3.0600000000000001, 3.0699999999999998, 3.0800000000000001, 3.0899999999999999, 3.1000000000000001, 3.1099999999999999, 3.1200000000000001, 3.1299999999999999, 3.1400000000000001, 3.1499999999999999, 3.1600000000000001, 3.1699999999999999, 3.1800000000000002, 3.1899999999999999, 3.2000000000000002, 3.21, 3.2200000000000002, 3.23, 3.2400000000000002, 3.25, 3.2599999999999998, 3.27, 3.2799999999999998, 3.29, 3.2999999999999998, 3.3100000000000001, 3.3199999999999998, 3.3300000000000001, 3.3399999999999999, 3.3500000000000001, 3.3599999999999999, 3.3700000000000001, 3.3799999999999999, 3.3900000000000001, 3.3999999999999999, 3.4100000000000001, 3.4199999999999999, 3.4300000000000002, 3.4399999999999999, 3.4500000000000002, 3.46, 3.4700000000000002, 3.48, 3.4900000000000002, 3.5, 3.5099999999999998, 3.52, 3.5299999999999998, 3.54, 3.5499999999999998, 3.5600000000000001, 3.5699999999999998, 3.5800000000000001, 3.5899999999999999, 3.6000000000000001, 3.6099999999999999, 3.6200000000000001, 3.6299999999999999, 3.6400000000000001, 3.6499999999999999, 3.6600000000000001, 3.6699999999999999, 3.6800000000000002, 3.6899999999999999, 3.7000000000000002, 3.71, 3.7200000000000002, 3.73, 3.7400000000000002, 3.75, 3.7599999999999998, 3.77, 3.7799999999999998, 3.79, 3.7999999999999998, 3.8100000000000001, 3.8199999999999998, 3.8300000000000001, 3.8399999999999999, 3.8500000000000001, 3.8599999999999999, 3.8700000000000001, 3.8799999999999999, 3.8900000000000001, 3.8999999999999999, 3.9100000000000001, 3.9199999999999999, 3.9300000000000002, 3.9399999999999999, 3.9500000000000002, 3.96, 3.9700000000000002, 3.98, 3.9900000000000002, 4.0, 4.0099999999999998, 4.0199999999999996, 4.0300000000000002, 4.04, 4.0499999999999998, 4.0599999999999996, 4.0700000000000003, 4.0800000000000001, 4.0899999999999999, 4.0999999999999996, 4.1100000000000003, 4.1200000000000001, 4.1299999999999999, 4.1399999999999997, 4.1500000000000004, 4.1600000000000001, 4.1699999999999999, 4.1799999999999997, 4.1900000000000004, 4.2000000000000002, 4.21, 4.2199999999999998, 4.2300000000000004, 4.2400000000000002]
4:31:27[QML:Reduced 2; QMD 8] Computing expectation values. 
Measurement Type: hahn_evolution 
LearnedHamiltonian [[ 2.15314366+0.j  0.00000000+0.j  0.00000000+0.j  0.00000000+0.j]
 [ 0.00000000+0.j  2.15314366+0.j  0.00000000+0.j  0.00000000+0.j]
 [ 0.00000000+0.j  0.00000000+0.j -2.15314366+0.j  0.00000000+0.j]
 [ 0.00000000+0.j  0.00000000+0.j  0.00000000+0.j -2.15314366+0.j]] 
Probe: [ 0.49971827 -4.83795104e-04j  0.50013082 +2.23249446e-04j
  0.50031730 -2.46059755e-05j  0.49983262 -6.92224955e-04j] 
Times: [0.0, 0.01, 0.02, 0.029999999999999999, 0.040000000000000001, 0.050000000000000003, 0.059999999999999998, 0.070000000000000007, 0.080000000000000002, 0.089999999999999997, 0.10000000000000001, 0.11, 0.12, 0.13, 0.14000000000000001, 0.14999999999999999, 0.16, 0.17000000000000001, 0.17999999999999999, 0.19, 0.20000000000000001, 0.20999999999999999, 0.22, 0.23000000000000001, 0.23999999999999999, 0.25, 0.26000000000000001, 0.27000000000000002, 0.28000000000000003, 0.28999999999999998, 0.29999999999999999, 0.31, 0.32000000000000001, 0.33000000000000002, 0.34000000000000002, 0.34999999999999998, 0.35999999999999999, 0.37, 0.38, 0.39000000000000001, 0.40000000000000002, 0.40999999999999998, 0.41999999999999998, 0.42999999999999999, 0.44, 0.45000000000000001, 0.46000000000000002, 0.46999999999999997, 0.47999999999999998, 0.48999999999999999, 0.5, 0.51000000000000001, 0.52000000000000002, 0.53000000000000003, 0.54000000000000004, 0.55000000000000004, 0.56000000000000005, 0.56999999999999995, 0.57999999999999996, 0.58999999999999997, 0.59999999999999998, 0.60999999999999999, 0.62, 0.63, 0.64000000000000001, 0.65000000000000002, 0.66000000000000003, 0.67000000000000004, 0.68000000000000005, 0.68999999999999995, 0.69999999999999996, 0.70999999999999996, 0.71999999999999997, 0.72999999999999998, 0.73999999999999999, 0.75, 0.76000000000000001, 0.77000000000000002, 0.78000000000000003, 0.79000000000000004, 0.80000000000000004, 0.81000000000000005, 0.81999999999999995, 0.82999999999999996, 0.83999999999999997, 0.84999999999999998, 0.85999999999999999, 0.87, 0.88, 0.89000000000000001, 0.90000000000000002, 0.91000000000000003, 0.92000000000000004, 0.93000000000000005, 0.93999999999999995, 0.94999999999999996, 0.95999999999999996, 0.96999999999999997, 0.97999999999999998, 0.98999999999999999, 1.0, 1.01, 1.02, 1.03, 1.04, 1.05, 1.0600000000000001, 1.0700000000000001, 1.0800000000000001, 1.0900000000000001, 1.1000000000000001, 1.1100000000000001, 1.1200000000000001, 1.1299999999999999, 1.1399999999999999, 1.1499999999999999, 1.1599999999999999, 1.1699999999999999, 1.1799999999999999, 1.1899999999999999, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3, 1.3100000000000001, 1.3200000000000001, 1.3300000000000001, 1.3400000000000001, 1.3500000000000001, 1.3600000000000001, 1.3700000000000001, 1.3799999999999999, 1.3899999999999999, 1.3999999999999999, 1.4099999999999999, 1.4199999999999999, 1.4299999999999999, 1.4399999999999999, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5, 1.51, 1.52, 1.53, 1.54, 1.55, 1.5600000000000001, 1.5700000000000001, 1.5800000000000001, 1.5900000000000001, 1.6000000000000001, 1.6100000000000001, 1.6200000000000001, 1.6299999999999999, 1.6399999999999999, 1.6499999999999999, 1.6599999999999999, 1.6699999999999999, 1.6799999999999999, 1.6899999999999999, 1.7, 1.71, 1.72, 1.73, 1.74, 1.75, 1.76, 1.77, 1.78, 1.79, 1.8, 1.8100000000000001, 1.8200000000000001, 1.8300000000000001, 1.8400000000000001, 1.8500000000000001, 1.8600000000000001, 1.8700000000000001, 1.8799999999999999, 1.8899999999999999, 1.8999999999999999, 1.9099999999999999, 1.9199999999999999, 1.9299999999999999, 1.9399999999999999, 1.95, 1.96, 1.97, 1.98, 1.99, 2.0, 2.0099999999999998, 2.02, 2.0299999999999998, 2.04, 2.0499999999999998, 2.0600000000000001, 2.0699999999999998, 2.0800000000000001, 2.0899999999999999, 2.1000000000000001, 2.1099999999999999, 2.1200000000000001, 2.1299999999999999, 2.1400000000000001, 2.1499999999999999, 2.1600000000000001, 2.1699999999999999, 2.1800000000000002, 2.1899999999999999, 2.2000000000000002, 2.21, 2.2200000000000002, 2.23, 2.2400000000000002, 2.25, 2.2599999999999998, 2.27, 2.2799999999999998, 2.29, 2.2999999999999998, 2.3100000000000001, 2.3199999999999998, 2.3300000000000001, 2.3399999999999999, 2.3500000000000001, 2.3599999999999999, 2.3700000000000001, 2.3799999999999999, 2.3900000000000001, 2.3999999999999999, 2.4100000000000001, 2.4199999999999999, 2.4300000000000002, 2.4399999999999999, 2.4500000000000002, 2.46, 2.4700000000000002, 2.48, 2.4900000000000002, 2.5, 2.5099999999999998, 2.52, 2.5299999999999998, 2.54, 2.5499999999999998, 2.5600000000000001, 2.5699999999999998, 2.5800000000000001, 2.5899999999999999, 2.6000000000000001, 2.6099999999999999, 2.6200000000000001, 2.6299999999999999, 2.6400000000000001, 2.6499999999999999, 2.6600000000000001, 2.6699999999999999, 2.6800000000000002, 2.6899999999999999, 2.7000000000000002, 2.71, 2.7200000000000002, 2.73, 2.7400000000000002, 2.75, 2.7599999999999998, 2.77, 2.7799999999999998, 2.79, 2.7999999999999998, 2.8100000000000001, 2.8199999999999998, 2.8300000000000001, 2.8399999999999999, 2.8500000000000001, 2.8599999999999999, 2.8700000000000001, 2.8799999999999999, 2.8900000000000001, 2.8999999999999999, 2.9100000000000001, 2.9199999999999999, 2.9300000000000002, 2.9399999999999999, 2.9500000000000002, 2.96, 2.9700000000000002, 2.98, 2.9900000000000002, 3.0, 3.0099999999999998, 3.02, 3.0299999999999998, 3.04, 3.0499999999999998, 3.0600000000000001, 3.0699999999999998, 3.0800000000000001, 3.0899999999999999, 3.1000000000000001, 3.1099999999999999, 3.1200000000000001, 3.1299999999999999, 3.1400000000000001, 3.1499999999999999, 3.1600000000000001, 3.1699999999999999, 3.1800000000000002, 3.1899999999999999, 3.2000000000000002, 3.21, 3.2200000000000002, 3.23, 3.2400000000000002, 3.25, 3.2599999999999998, 3.27, 3.2799999999999998, 3.29, 3.2999999999999998, 3.3100000000000001, 3.3199999999999998, 3.3300000000000001, 3.3399999999999999, 3.3500000000000001, 3.3599999999999999, 3.3700000000000001, 3.3799999999999999, 3.3900000000000001, 3.3999999999999999, 3.4100000000000001, 3.4199999999999999, 3.4300000000000002, 3.4399999999999999, 3.4500000000000002, 3.46, 3.4700000000000002, 3.48, 3.4900000000000002, 3.5, 3.5099999999999998, 3.52, 3.5299999999999998, 3.54, 3.5499999999999998, 3.5600000000000001, 3.5699999999999998, 3.5800000000000001, 3.5899999999999999, 3.6000000000000001, 3.6099999999999999, 3.6200000000000001, 3.6299999999999999, 3.6400000000000001, 3.6499999999999999, 3.6600000000000001, 3.6699999999999999, 3.6800000000000002, 3.6899999999999999, 3.7000000000000002, 3.71, 3.7200000000000002, 3.73, 3.7400000000000002, 3.75, 3.7599999999999998, 3.77, 3.7799999999999998, 3.79, 3.7999999999999998, 3.8100000000000001, 3.8199999999999998, 3.8300000000000001, 3.8399999999999999, 3.8500000000000001, 3.8599999999999999, 3.8700000000000001, 3.8799999999999999, 3.8900000000000001, 3.8999999999999999, 3.9100000000000001, 3.9199999999999999, 3.9300000000000002, 3.9399999999999999, 3.9500000000000002, 3.96, 3.9700000000000002, 3.98, 3.9900000000000002, 4.0, 4.0099999999999998, 4.0199999999999996, 4.0300000000000002, 4.04, 4.0499999999999998, 4.0599999999999996, 4.0700000000000003, 4.0800000000000001, 4.0899999999999999, 4.0999999999999996, 4.1100000000000003, 4.1200000000000001, 4.1299999999999999, 4.1399999999999997, 4.1500000000000004, 4.1600000000000001, 4.1699999999999999, 4.1799999999999997, 4.1900000000000004, 4.2000000000000002, 4.21, 4.2199999999999998, 4.2300000000000004, 4.2400000000000002]
4:31:27[QML:Reduced 2; QMD 8] [compute expectation values] times to compute: [0.0, 0.01, 0.02, 0.029999999999999999, 0.040000000000000001, 0.050000000000000003, 0.059999999999999998, 0.070000000000000007, 0.080000000000000002, 0.089999999999999997, 0.10000000000000001, 0.11, 0.12, 0.13, 0.14000000000000001, 0.14999999999999999, 0.16, 0.17000000000000001, 0.17999999999999999, 0.19, 0.20000000000000001, 0.20999999999999999, 0.22, 0.23000000000000001, 0.23999999999999999, 0.25, 0.26000000000000001, 0.27000000000000002, 0.28000000000000003, 0.28999999999999998, 0.29999999999999999, 0.31, 0.32000000000000001, 0.33000000000000002, 0.34000000000000002, 0.34999999999999998, 0.35999999999999999, 0.37, 0.38, 0.39000000000000001, 0.40000000000000002, 0.40999999999999998, 0.41999999999999998, 0.42999999999999999, 0.44, 0.45000000000000001, 0.46000000000000002, 0.46999999999999997, 0.47999999999999998, 0.48999999999999999, 0.5, 0.51000000000000001, 0.52000000000000002, 0.53000000000000003, 0.54000000000000004, 0.55000000000000004, 0.56000000000000005, 0.56999999999999995, 0.57999999999999996, 0.58999999999999997, 0.59999999999999998, 0.60999999999999999, 0.62, 0.63, 0.64000000000000001, 0.65000000000000002, 0.66000000000000003, 0.67000000000000004, 0.68000000000000005, 0.68999999999999995, 0.69999999999999996, 0.70999999999999996, 0.71999999999999997, 0.72999999999999998, 0.73999999999999999, 0.75, 0.76000000000000001, 0.77000000000000002, 0.78000000000000003, 0.79000000000000004, 0.80000000000000004, 0.81000000000000005, 0.81999999999999995, 0.82999999999999996, 0.83999999999999997, 0.84999999999999998, 0.85999999999999999, 0.87, 0.88, 0.89000000000000001, 0.90000000000000002, 0.91000000000000003, 0.92000000000000004, 0.93000000000000005, 0.93999999999999995, 0.94999999999999996, 0.95999999999999996, 0.96999999999999997, 0.97999999999999998, 0.98999999999999999, 1.0, 1.01, 1.02, 1.03, 1.04, 1.05, 1.0600000000000001, 1.0700000000000001, 1.0800000000000001, 1.0900000000000001, 1.1000000000000001, 1.1100000000000001, 1.1200000000000001, 1.1299999999999999, 1.1399999999999999, 1.1499999999999999, 1.1599999999999999, 1.1699999999999999, 1.1799999999999999, 1.1899999999999999, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3, 1.3100000000000001, 1.3200000000000001, 1.3300000000000001, 1.3400000000000001, 1.3500000000000001, 1.3600000000000001, 1.3700000000000001, 1.3799999999999999, 1.3899999999999999, 1.3999999999999999, 1.4099999999999999, 1.4199999999999999, 1.4299999999999999, 1.4399999999999999, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5, 1.51, 1.52, 1.53, 1.54, 1.55, 1.5600000000000001, 1.5700000000000001, 1.5800000000000001, 1.5900000000000001, 1.6000000000000001, 1.6100000000000001, 1.6200000000000001, 1.6299999999999999, 1.6399999999999999, 1.6499999999999999, 1.6599999999999999, 1.6699999999999999, 1.6799999999999999, 1.6899999999999999, 1.7, 1.71, 1.72, 1.73, 1.74, 1.75, 1.76, 1.77, 1.78, 1.79, 1.8, 1.8100000000000001, 1.8200000000000001, 1.8300000000000001, 1.8400000000000001, 1.8500000000000001, 1.8600000000000001, 1.8700000000000001, 1.8799999999999999, 1.8899999999999999, 1.8999999999999999, 1.9099999999999999, 1.9199999999999999, 1.9299999999999999, 1.9399999999999999, 1.95, 1.96, 1.97, 1.98, 1.99, 2.0, 2.0099999999999998, 2.02, 2.0299999999999998, 2.04, 2.0499999999999998, 2.0600000000000001, 2.0699999999999998, 2.0800000000000001, 2.0899999999999999, 2.1000000000000001, 2.1099999999999999, 2.1200000000000001, 2.1299999999999999, 2.1400000000000001, 2.1499999999999999, 2.1600000000000001, 2.1699999999999999, 2.1800000000000002, 2.1899999999999999, 2.2000000000000002, 2.21, 2.2200000000000002, 2.23, 2.2400000000000002, 2.25, 2.2599999999999998, 2.27, 2.2799999999999998, 2.29, 2.2999999999999998, 2.3100000000000001, 2.3199999999999998, 2.3300000000000001, 2.3399999999999999, 2.3500000000000001, 2.3599999999999999, 2.3700000000000001, 2.3799999999999999, 2.3900000000000001, 2.3999999999999999, 2.4100000000000001, 2.4199999999999999, 2.4300000000000002, 2.4399999999999999, 2.4500000000000002, 2.46, 2.4700000000000002, 2.48, 2.4900000000000002, 2.5, 2.5099999999999998, 2.52, 2.5299999999999998, 2.54, 2.5499999999999998, 2.5600000000000001, 2.5699999999999998, 2.5800000000000001, 2.5899999999999999, 2.6000000000000001, 2.6099999999999999, 2.6200000000000001, 2.6299999999999999, 2.6400000000000001, 2.6499999999999999, 2.6600000000000001, 2.6699999999999999, 2.6800000000000002, 2.6899999999999999, 2.7000000000000002, 2.71, 2.7200000000000002, 2.73, 2.7400000000000002, 2.75, 2.7599999999999998, 2.77, 2.7799999999999998, 2.79, 2.7999999999999998, 2.8100000000000001, 2.8199999999999998, 2.8300000000000001, 2.8399999999999999, 2.8500000000000001, 2.8599999999999999, 2.8700000000000001, 2.8799999999999999, 2.8900000000000001, 2.8999999999999999, 2.9100000000000001, 2.9199999999999999, 2.9300000000000002, 2.9399999999999999, 2.9500000000000002, 2.96, 2.9700000000000002, 2.98, 2.9900000000000002, 3.0, 3.0099999999999998, 3.02, 3.0299999999999998, 3.04, 3.0499999999999998, 3.0600000000000001, 3.0699999999999998, 3.0800000000000001, 3.0899999999999999, 3.1000000000000001, 3.1099999999999999, 3.1200000000000001, 3.1299999999999999, 3.1400000000000001, 3.1499999999999999, 3.1600000000000001, 3.1699999999999999, 3.1800000000000002, 3.1899999999999999, 3.2000000000000002, 3.21, 3.2200000000000002, 3.23, 3.2400000000000002, 3.25, 3.2599999999999998, 3.27, 3.2799999999999998, 3.29, 3.2999999999999998, 3.3100000000000001, 3.3199999999999998, 3.3300000000000001, 3.3399999999999999, 3.3500000000000001, 3.3599999999999999, 3.3700000000000001, 3.3799999999999999, 3.3900000000000001, 3.3999999999999999, 3.4100000000000001, 3.4199999999999999, 3.4300000000000002, 3.4399999999999999, 3.4500000000000002, 3.46, 3.4700000000000002, 3.48, 3.4900000000000002, 3.5, 3.5099999999999998, 3.52, 3.5299999999999998, 3.54, 3.5499999999999998, 3.5600000000000001, 3.5699999999999998, 3.5800000000000001, 3.5899999999999999, 3.6000000000000001, 3.6099999999999999, 3.6200000000000001, 3.6299999999999999, 3.6400000000000001, 3.6499999999999999, 3.6600000000000001, 3.6699999999999999, 3.6800000000000002, 3.6899999999999999, 3.7000000000000002, 3.71, 3.7200000000000002, 3.73, 3.7400000000000002, 3.75, 3.7599999999999998, 3.77, 3.7799999999999998, 3.79, 3.7999999999999998, 3.8100000000000001, 3.8199999999999998, 3.8300000000000001, 3.8399999999999999, 3.8500000000000001, 3.8599999999999999, 3.8700000000000001, 3.8799999999999999, 3.8900000000000001, 3.8999999999999999, 3.9100000000000001, 3.9199999999999999, 3.9300000000000002, 3.9399999999999999, 3.9500000000000002, 3.96, 3.9700000000000002, 3.98, 3.9900000000000002, 4.0, 4.0099999999999998, 4.0199999999999996, 4.0300000000000002, 4.04, 4.0499999999999998, 4.0599999999999996, 4.0700000000000003, 4.0800000000000001, 4.0899999999999999, 4.0999999999999996, 4.1100000000000003, 4.1200000000000001, 4.1299999999999999, 4.1399999999999997, 4.1500000000000004, 4.1600000000000001, 4.1699999999999999, 4.1799999999999997, 4.1900000000000004, 4.2000000000000002, 4.21, 4.2199999999999998, 4.2300000000000004, 4.2400000000000002]
4:31:28[QML:Reduced 3; QMD 8] Computing expectation values. 
Measurement Type: hahn_evolution 
LearnedHamiltonian [[ 1.93398151+0.j  0.00000000+0.j -0.50051462+0.j  0.00000000+0.j]
 [ 0.00000000+0.j  1.93398151+0.j  0.00000000+0.j -0.50051462+0.j]
 [-0.50051462+0.j  0.00000000+0.j -1.93398151+0.j  0.00000000+0.j]
 [ 0.00000000+0.j -0.50051462+0.j  0.00000000+0.j -1.93398151+0.j]] 
Probe: [ 0.49971827 -4.83795104e-04j  0.50013082 +2.23249446e-04j
  0.50031730 -2.46059755e-05j  0.49983262 -6.92224955e-04j] 
Times: [0.0, 0.01, 0.02, 0.029999999999999999, 0.040000000000000001, 0.050000000000000003, 0.059999999999999998, 0.070000000000000007, 0.080000000000000002, 0.089999999999999997, 0.10000000000000001, 0.11, 0.12, 0.13, 0.14000000000000001, 0.14999999999999999, 0.16, 0.17000000000000001, 0.17999999999999999, 0.19, 0.20000000000000001, 0.20999999999999999, 0.22, 0.23000000000000001, 0.23999999999999999, 0.25, 0.26000000000000001, 0.27000000000000002, 0.28000000000000003, 0.28999999999999998, 0.29999999999999999, 0.31, 0.32000000000000001, 0.33000000000000002, 0.34000000000000002, 0.34999999999999998, 0.35999999999999999, 0.37, 0.38, 0.39000000000000001, 0.40000000000000002, 0.40999999999999998, 0.41999999999999998, 0.42999999999999999, 0.44, 0.45000000000000001, 0.46000000000000002, 0.46999999999999997, 0.47999999999999998, 0.48999999999999999, 0.5, 0.51000000000000001, 0.52000000000000002, 0.53000000000000003, 0.54000000000000004, 0.55000000000000004, 0.56000000000000005, 0.56999999999999995, 0.57999999999999996, 0.58999999999999997, 0.59999999999999998, 0.60999999999999999, 0.62, 0.63, 0.64000000000000001, 0.65000000000000002, 0.66000000000000003, 0.67000000000000004, 0.68000000000000005, 0.68999999999999995, 0.69999999999999996, 0.70999999999999996, 0.71999999999999997, 0.72999999999999998, 0.73999999999999999, 0.75, 0.76000000000000001, 0.77000000000000002, 0.78000000000000003, 0.79000000000000004, 0.80000000000000004, 0.81000000000000005, 0.81999999999999995, 0.82999999999999996, 0.83999999999999997, 0.84999999999999998, 0.85999999999999999, 0.87, 0.88, 0.89000000000000001, 0.90000000000000002, 0.91000000000000003, 0.92000000000000004, 0.93000000000000005, 0.93999999999999995, 0.94999999999999996, 0.95999999999999996, 0.96999999999999997, 0.97999999999999998, 0.98999999999999999, 1.0, 1.01, 1.02, 1.03, 1.04, 1.05, 1.0600000000000001, 1.0700000000000001, 1.0800000000000001, 1.0900000000000001, 1.1000000000000001, 1.1100000000000001, 1.1200000000000001, 1.1299999999999999, 1.1399999999999999, 1.1499999999999999, 1.1599999999999999, 1.1699999999999999, 1.1799999999999999, 1.1899999999999999, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3, 1.3100000000000001, 1.3200000000000001, 1.3300000000000001, 1.3400000000000001, 1.3500000000000001, 1.3600000000000001, 1.3700000000000001, 1.3799999999999999, 1.3899999999999999, 1.3999999999999999, 1.4099999999999999, 1.4199999999999999, 1.4299999999999999, 1.4399999999999999, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5, 1.51, 1.52, 1.53, 1.54, 1.55, 1.5600000000000001, 1.5700000000000001, 1.5800000000000001, 1.5900000000000001, 1.6000000000000001, 1.6100000000000001, 1.6200000000000001, 1.6299999999999999, 1.6399999999999999, 1.6499999999999999, 1.6599999999999999, 1.6699999999999999, 1.6799999999999999, 1.6899999999999999, 1.7, 1.71, 1.72, 1.73, 1.74, 1.75, 1.76, 1.77, 1.78, 1.79, 1.8, 1.8100000000000001, 1.8200000000000001, 1.8300000000000001, 1.8400000000000001, 1.8500000000000001, 1.8600000000000001, 1.8700000000000001, 1.8799999999999999, 1.8899999999999999, 1.8999999999999999, 1.9099999999999999, 1.9199999999999999, 1.9299999999999999, 1.9399999999999999, 1.95, 1.96, 1.97, 1.98, 1.99, 2.0, 2.0099999999999998, 2.02, 2.0299999999999998, 2.04, 2.0499999999999998, 2.0600000000000001, 2.0699999999999998, 2.0800000000000001, 2.0899999999999999, 2.1000000000000001, 2.1099999999999999, 2.1200000000000001, 2.1299999999999999, 2.1400000000000001, 2.1499999999999999, 2.1600000000000001, 2.1699999999999999, 2.1800000000000002, 2.1899999999999999, 2.2000000000000002, 2.21, 2.2200000000000002, 2.23, 2.2400000000000002, 2.25, 2.2599999999999998, 2.27, 2.2799999999999998, 2.29, 2.2999999999999998, 2.3100000000000001, 2.3199999999999998, 2.3300000000000001, 2.3399999999999999, 2.3500000000000001, 2.3599999999999999, 2.3700000000000001, 2.3799999999999999, 2.3900000000000001, 2.3999999999999999, 2.4100000000000001, 2.4199999999999999, 2.4300000000000002, 2.4399999999999999, 2.4500000000000002, 2.46, 2.4700000000000002, 2.48, 2.4900000000000002, 2.5, 2.5099999999999998, 2.52, 2.5299999999999998, 2.54, 2.5499999999999998, 2.5600000000000001, 2.5699999999999998, 2.5800000000000001, 2.5899999999999999, 2.6000000000000001, 2.6099999999999999, 2.6200000000000001, 2.6299999999999999, 2.6400000000000001, 2.6499999999999999, 2.6600000000000001, 2.6699999999999999, 2.6800000000000002, 2.6899999999999999, 2.7000000000000002, 2.71, 2.7200000000000002, 2.73, 2.7400000000000002, 2.75, 2.7599999999999998, 2.77, 2.7799999999999998, 2.79, 2.7999999999999998, 2.8100000000000001, 2.8199999999999998, 2.8300000000000001, 2.8399999999999999, 2.8500000000000001, 2.8599999999999999, 2.8700000000000001, 2.8799999999999999, 2.8900000000000001, 2.8999999999999999, 2.9100000000000001, 2.9199999999999999, 2.9300000000000002, 2.9399999999999999, 2.9500000000000002, 2.96, 2.9700000000000002, 2.98, 2.9900000000000002, 3.0, 3.0099999999999998, 3.02, 3.0299999999999998, 3.04, 3.0499999999999998, 3.0600000000000001, 3.0699999999999998, 3.0800000000000001, 3.0899999999999999, 3.1000000000000001, 3.1099999999999999, 3.1200000000000001, 3.1299999999999999, 3.1400000000000001, 3.1499999999999999, 3.1600000000000001, 3.1699999999999999, 3.1800000000000002, 3.1899999999999999, 3.2000000000000002, 3.21, 3.2200000000000002, 3.23, 3.2400000000000002, 3.25, 3.2599999999999998, 3.27, 3.2799999999999998, 3.29, 3.2999999999999998, 3.3100000000000001, 3.3199999999999998, 3.3300000000000001, 3.3399999999999999, 3.3500000000000001, 3.3599999999999999, 3.3700000000000001, 3.3799999999999999, 3.3900000000000001, 3.3999999999999999, 3.4100000000000001, 3.4199999999999999, 3.4300000000000002, 3.4399999999999999, 3.4500000000000002, 3.46, 3.4700000000000002, 3.48, 3.4900000000000002, 3.5, 3.5099999999999998, 3.52, 3.5299999999999998, 3.54, 3.5499999999999998, 3.5600000000000001, 3.5699999999999998, 3.5800000000000001, 3.5899999999999999, 3.6000000000000001, 3.6099999999999999, 3.6200000000000001, 3.6299999999999999, 3.6400000000000001, 3.6499999999999999, 3.6600000000000001, 3.6699999999999999, 3.6800000000000002, 3.6899999999999999, 3.7000000000000002, 3.71, 3.7200000000000002, 3.73, 3.7400000000000002, 3.75, 3.7599999999999998, 3.77, 3.7799999999999998, 3.79, 3.7999999999999998, 3.8100000000000001, 3.8199999999999998, 3.8300000000000001, 3.8399999999999999, 3.8500000000000001, 3.8599999999999999, 3.8700000000000001, 3.8799999999999999, 3.8900000000000001, 3.8999999999999999, 3.9100000000000001, 3.9199999999999999, 3.9300000000000002, 3.9399999999999999, 3.9500000000000002, 3.96, 3.9700000000000002, 3.98, 3.9900000000000002, 4.0, 4.0099999999999998, 4.0199999999999996, 4.0300000000000002, 4.04, 4.0499999999999998, 4.0599999999999996, 4.0700000000000003, 4.0800000000000001, 4.0899999999999999, 4.0999999999999996, 4.1100000000000003, 4.1200000000000001, 4.1299999999999999, 4.1399999999999997, 4.1500000000000004, 4.1600000000000001, 4.1699999999999999, 4.1799999999999997, 4.1900000000000004, 4.2000000000000002, 4.21, 4.2199999999999998, 4.2300000000000004, 4.2400000000000002]
4:31:28[QML:Reduced 3; QMD 8] [compute expectation values] times to compute: [0.0, 0.01, 0.02, 0.029999999999999999, 0.040000000000000001, 0.050000000000000003, 0.059999999999999998, 0.070000000000000007, 0.080000000000000002, 0.089999999999999997, 0.10000000000000001, 0.11, 0.12, 0.13, 0.14000000000000001, 0.14999999999999999, 0.16, 0.17000000000000001, 0.17999999999999999, 0.19, 0.20000000000000001, 0.20999999999999999, 0.22, 0.23000000000000001, 0.23999999999999999, 0.25, 0.26000000000000001, 0.27000000000000002, 0.28000000000000003, 0.28999999999999998, 0.29999999999999999, 0.31, 0.32000000000000001, 0.33000000000000002, 0.34000000000000002, 0.34999999999999998, 0.35999999999999999, 0.37, 0.38, 0.39000000000000001, 0.40000000000000002, 0.40999999999999998, 0.41999999999999998, 0.42999999999999999, 0.44, 0.45000000000000001, 0.46000000000000002, 0.46999999999999997, 0.47999999999999998, 0.48999999999999999, 0.5, 0.51000000000000001, 0.52000000000000002, 0.53000000000000003, 0.54000000000000004, 0.55000000000000004, 0.56000000000000005, 0.56999999999999995, 0.57999999999999996, 0.58999999999999997, 0.59999999999999998, 0.60999999999999999, 0.62, 0.63, 0.64000000000000001, 0.65000000000000002, 0.66000000000000003, 0.67000000000000004, 0.68000000000000005, 0.68999999999999995, 0.69999999999999996, 0.70999999999999996, 0.71999999999999997, 0.72999999999999998, 0.73999999999999999, 0.75, 0.76000000000000001, 0.77000000000000002, 0.78000000000000003, 0.79000000000000004, 0.80000000000000004, 0.81000000000000005, 0.81999999999999995, 0.82999999999999996, 0.83999999999999997, 0.84999999999999998, 0.85999999999999999, 0.87, 0.88, 0.89000000000000001, 0.90000000000000002, 0.91000000000000003, 0.92000000000000004, 0.93000000000000005, 0.93999999999999995, 0.94999999999999996, 0.95999999999999996, 0.96999999999999997, 0.97999999999999998, 0.98999999999999999, 1.0, 1.01, 1.02, 1.03, 1.04, 1.05, 1.0600000000000001, 1.0700000000000001, 1.0800000000000001, 1.0900000000000001, 1.1000000000000001, 1.1100000000000001, 1.1200000000000001, 1.1299999999999999, 1.1399999999999999, 1.1499999999999999, 1.1599999999999999, 1.1699999999999999, 1.1799999999999999, 1.1899999999999999, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3, 1.3100000000000001, 1.3200000000000001, 1.3300000000000001, 1.3400000000000001, 1.3500000000000001, 1.3600000000000001, 1.3700000000000001, 1.3799999999999999, 1.3899999999999999, 1.3999999999999999, 1.4099999999999999, 1.4199999999999999, 1.4299999999999999, 1.4399999999999999, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5, 1.51, 1.52, 1.53, 1.54, 1.55, 1.5600000000000001, 1.5700000000000001, 1.5800000000000001, 1.5900000000000001, 1.6000000000000001, 1.6100000000000001, 1.6200000000000001, 1.6299999999999999, 1.6399999999999999, 1.6499999999999999, 1.6599999999999999, 1.6699999999999999, 1.6799999999999999, 1.6899999999999999, 1.7, 1.71, 1.72, 1.73, 1.74, 1.75, 1.76, 1.77, 1.78, 1.79, 1.8, 1.8100000000000001, 1.8200000000000001, 1.8300000000000001, 1.8400000000000001, 1.8500000000000001, 1.8600000000000001, 1.8700000000000001, 1.8799999999999999, 1.8899999999999999, 1.8999999999999999, 1.9099999999999999, 1.9199999999999999, 1.9299999999999999, 1.9399999999999999, 1.95, 1.96, 1.97, 1.98, 1.99, 2.0, 2.0099999999999998, 2.02, 2.0299999999999998, 2.04, 2.0499999999999998, 2.0600000000000001, 2.0699999999999998, 2.0800000000000001, 2.0899999999999999, 2.1000000000000001, 2.1099999999999999, 2.1200000000000001, 2.1299999999999999, 2.1400000000000001, 2.1499999999999999, 2.1600000000000001, 2.1699999999999999, 2.1800000000000002, 2.1899999999999999, 2.2000000000000002, 2.21, 2.2200000000000002, 2.23, 2.2400000000000002, 2.25, 2.2599999999999998, 2.27, 2.2799999999999998, 2.29, 2.2999999999999998, 2.3100000000000001, 2.3199999999999998, 2.3300000000000001, 2.3399999999999999, 2.3500000000000001, 2.3599999999999999, 2.3700000000000001, 2.3799999999999999, 2.3900000000000001, 2.3999999999999999, 2.4100000000000001, 2.4199999999999999, 2.4300000000000002, 2.4399999999999999, 2.4500000000000002, 2.46, 2.4700000000000002, 2.48, 2.4900000000000002, 2.5, 2.5099999999999998, 2.52, 2.5299999999999998, 2.54, 2.5499999999999998, 2.5600000000000001, 2.5699999999999998, 2.5800000000000001, 2.5899999999999999, 2.6000000000000001, 2.6099999999999999, 2.6200000000000001, 2.6299999999999999, 2.6400000000000001, 2.6499999999999999, 2.6600000000000001, 2.6699999999999999, 2.6800000000000002, 2.6899999999999999, 2.7000000000000002, 2.71, 2.7200000000000002, 2.73, 2.7400000000000002, 2.75, 2.7599999999999998, 2.77, 2.7799999999999998, 2.79, 2.7999999999999998, 2.8100000000000001, 2.8199999999999998, 2.8300000000000001, 2.8399999999999999, 2.8500000000000001, 2.8599999999999999, 2.8700000000000001, 2.8799999999999999, 2.8900000000000001, 2.8999999999999999, 2.9100000000000001, 2.9199999999999999, 2.9300000000000002, 2.9399999999999999, 2.9500000000000002, 2.96, 2.9700000000000002, 2.98, 2.9900000000000002, 3.0, 3.0099999999999998, 3.02, 3.0299999999999998, 3.04, 3.0499999999999998, 3.0600000000000001, 3.0699999999999998, 3.0800000000000001, 3.0899999999999999, 3.1000000000000001, 3.1099999999999999, 3.1200000000000001, 3.1299999999999999, 3.1400000000000001, 3.1499999999999999, 3.1600000000000001, 3.1699999999999999, 3.1800000000000002, 3.1899999999999999, 3.2000000000000002, 3.21, 3.2200000000000002, 3.23, 3.2400000000000002, 3.25, 3.2599999999999998, 3.27, 3.2799999999999998, 3.29, 3.2999999999999998, 3.3100000000000001, 3.3199999999999998, 3.3300000000000001, 3.3399999999999999, 3.3500000000000001, 3.3599999999999999, 3.3700000000000001, 3.3799999999999999, 3.3900000000000001, 3.3999999999999999, 3.4100000000000001, 3.4199999999999999, 3.4300000000000002, 3.4399999999999999, 3.4500000000000002, 3.46, 3.4700000000000002, 3.48, 3.4900000000000002, 3.5, 3.5099999999999998, 3.52, 3.5299999999999998, 3.54, 3.5499999999999998, 3.5600000000000001, 3.5699999999999998, 3.5800000000000001, 3.5899999999999999, 3.6000000000000001, 3.6099999999999999, 3.6200000000000001, 3.6299999999999999, 3.6400000000000001, 3.6499999999999999, 3.6600000000000001, 3.6699999999999999, 3.6800000000000002, 3.6899999999999999, 3.7000000000000002, 3.71, 3.7200000000000002, 3.73, 3.7400000000000002, 3.75, 3.7599999999999998, 3.77, 3.7799999999999998, 3.79, 3.7999999999999998, 3.8100000000000001, 3.8199999999999998, 3.8300000000000001, 3.8399999999999999, 3.8500000000000001, 3.8599999999999999, 3.8700000000000001, 3.8799999999999999, 3.8900000000000001, 3.8999999999999999, 3.9100000000000001, 3.9199999999999999, 3.9300000000000002, 3.9399999999999999, 3.9500000000000002, 3.96, 3.9700000000000002, 3.98, 3.9900000000000002, 4.0, 4.0099999999999998, 4.0199999999999996, 4.0300000000000002, 4.04, 4.0499999999999998, 4.0599999999999996, 4.0700000000000003, 4.0800000000000001, 4.0899999999999999, 4.0999999999999996, 4.1100000000000003, 4.1200000000000001, 4.1299999999999999, 4.1399999999999997, 4.1500000000000004, 4.1600000000000001, 4.1699999999999999, 4.1799999999999997, 4.1900000000000004, 4.2000000000000002, 4.21, 4.2199999999999998, 4.2300000000000004, 4.2400000000000002]
4:31:28[QML:Reduced 5; QMD 8] Computing expectation values. 
Measurement Type: hahn_evolution 
LearnedHamiltonian [[ 3.52439508+0.j          0.00000000+0.j          0.46073038-5.37746602j
   0.00000000+0.j        ]
 [ 0.00000000+0.j          3.52439508+0.j          0.00000000+0.j
   0.46073038-5.37746602j]
 [ 0.46073038+5.37746602j  0.00000000+0.j         -3.52439508+0.j
   0.00000000+0.j        ]
 [ 0.00000000+0.j          0.46073038+5.37746602j  0.00000000+0.j
  -3.52439508+0.j        ]] 
Probe: [ 0.49971827 -4.83795104e-04j  0.50013082 +2.23249446e-04j
  0.50031730 -2.46059755e-05j  0.49983262 -6.92224955e-04j] 
Times: [0.0, 0.01, 0.02, 0.029999999999999999, 0.040000000000000001, 0.050000000000000003, 0.059999999999999998, 0.070000000000000007, 0.080000000000000002, 0.089999999999999997, 0.10000000000000001, 0.11, 0.12, 0.13, 0.14000000000000001, 0.14999999999999999, 0.16, 0.17000000000000001, 0.17999999999999999, 0.19, 0.20000000000000001, 0.20999999999999999, 0.22, 0.23000000000000001, 0.23999999999999999, 0.25, 0.26000000000000001, 0.27000000000000002, 0.28000000000000003, 0.28999999999999998, 0.29999999999999999, 0.31, 0.32000000000000001, 0.33000000000000002, 0.34000000000000002, 0.34999999999999998, 0.35999999999999999, 0.37, 0.38, 0.39000000000000001, 0.40000000000000002, 0.40999999999999998, 0.41999999999999998, 0.42999999999999999, 0.44, 0.45000000000000001, 0.46000000000000002, 0.46999999999999997, 0.47999999999999998, 0.48999999999999999, 0.5, 0.51000000000000001, 0.52000000000000002, 0.53000000000000003, 0.54000000000000004, 0.55000000000000004, 0.56000000000000005, 0.56999999999999995, 0.57999999999999996, 0.58999999999999997, 0.59999999999999998, 0.60999999999999999, 0.62, 0.63, 0.64000000000000001, 0.65000000000000002, 0.66000000000000003, 0.67000000000000004, 0.68000000000000005, 0.68999999999999995, 0.69999999999999996, 0.70999999999999996, 0.71999999999999997, 0.72999999999999998, 0.73999999999999999, 0.75, 0.76000000000000001, 0.77000000000000002, 0.78000000000000003, 0.79000000000000004, 0.80000000000000004, 0.81000000000000005, 0.81999999999999995, 0.82999999999999996, 0.83999999999999997, 0.84999999999999998, 0.85999999999999999, 0.87, 0.88, 0.89000000000000001, 0.90000000000000002, 0.91000000000000003, 0.92000000000000004, 0.93000000000000005, 0.93999999999999995, 0.94999999999999996, 0.95999999999999996, 0.96999999999999997, 0.97999999999999998, 0.98999999999999999, 1.0, 1.01, 1.02, 1.03, 1.04, 1.05, 1.0600000000000001, 1.0700000000000001, 1.0800000000000001, 1.0900000000000001, 1.1000000000000001, 1.1100000000000001, 1.1200000000000001, 1.1299999999999999, 1.1399999999999999, 1.1499999999999999, 1.1599999999999999, 1.1699999999999999, 1.1799999999999999, 1.1899999999999999, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3, 1.3100000000000001, 1.3200000000000001, 1.3300000000000001, 1.3400000000000001, 1.3500000000000001, 1.3600000000000001, 1.3700000000000001, 1.3799999999999999, 1.3899999999999999, 1.3999999999999999, 1.4099999999999999, 1.4199999999999999, 1.4299999999999999, 1.4399999999999999, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5, 1.51, 1.52, 1.53, 1.54, 1.55, 1.5600000000000001, 1.5700000000000001, 1.5800000000000001, 1.5900000000000001, 1.6000000000000001, 1.6100000000000001, 1.6200000000000001, 1.6299999999999999, 1.6399999999999999, 1.6499999999999999, 1.6599999999999999, 1.6699999999999999, 1.6799999999999999, 1.6899999999999999, 1.7, 1.71, 1.72, 1.73, 1.74, 1.75, 1.76, 1.77, 1.78, 1.79, 1.8, 1.8100000000000001, 1.8200000000000001, 1.8300000000000001, 1.8400000000000001, 1.8500000000000001, 1.8600000000000001, 1.8700000000000001, 1.8799999999999999, 1.8899999999999999, 1.8999999999999999, 1.9099999999999999, 1.9199999999999999, 1.9299999999999999, 1.9399999999999999, 1.95, 1.96, 1.97, 1.98, 1.99, 2.0, 2.0099999999999998, 2.02, 2.0299999999999998, 2.04, 2.0499999999999998, 2.0600000000000001, 2.0699999999999998, 2.0800000000000001, 2.0899999999999999, 2.1000000000000001, 2.1099999999999999, 2.1200000000000001, 2.1299999999999999, 2.1400000000000001, 2.1499999999999999, 2.1600000000000001, 2.1699999999999999, 2.1800000000000002, 2.1899999999999999, 2.2000000000000002, 2.21, 2.2200000000000002, 2.23, 2.2400000000000002, 2.25, 2.2599999999999998, 2.27, 2.2799999999999998, 2.29, 2.2999999999999998, 2.3100000000000001, 2.3199999999999998, 2.3300000000000001, 2.3399999999999999, 2.3500000000000001, 2.3599999999999999, 2.3700000000000001, 2.3799999999999999, 2.3900000000000001, 2.3999999999999999, 2.4100000000000001, 2.4199999999999999, 2.4300000000000002, 2.4399999999999999, 2.4500000000000002, 2.46, 2.4700000000000002, 2.48, 2.4900000000000002, 2.5, 2.5099999999999998, 2.52, 2.5299999999999998, 2.54, 2.5499999999999998, 2.5600000000000001, 2.5699999999999998, 2.5800000000000001, 2.5899999999999999, 2.6000000000000001, 2.6099999999999999, 2.6200000000000001, 2.6299999999999999, 2.6400000000000001, 2.6499999999999999, 2.6600000000000001, 2.6699999999999999, 2.6800000000000002, 2.6899999999999999, 2.7000000000000002, 2.71, 2.7200000000000002, 2.73, 2.7400000000000002, 2.75, 2.7599999999999998, 2.77, 2.7799999999999998, 2.79, 2.7999999999999998, 2.8100000000000001, 2.8199999999999998, 2.8300000000000001, 2.8399999999999999, 2.8500000000000001, 2.8599999999999999, 2.8700000000000001, 2.8799999999999999, 2.8900000000000001, 2.8999999999999999, 2.9100000000000001, 2.9199999999999999, 2.9300000000000002, 2.9399999999999999, 2.9500000000000002, 2.96, 2.9700000000000002, 2.98, 2.9900000000000002, 3.0, 3.0099999999999998, 3.02, 3.0299999999999998, 3.04, 3.0499999999999998, 3.0600000000000001, 3.0699999999999998, 3.0800000000000001, 3.0899999999999999, 3.1000000000000001, 3.1099999999999999, 3.1200000000000001, 3.1299999999999999, 3.1400000000000001, 3.1499999999999999, 3.1600000000000001, 3.1699999999999999, 3.1800000000000002, 3.1899999999999999, 3.2000000000000002, 3.21, 3.2200000000000002, 3.23, 3.2400000000000002, 3.25, 3.2599999999999998, 3.27, 3.2799999999999998, 3.29, 3.2999999999999998, 3.3100000000000001, 3.3199999999999998, 3.3300000000000001, 3.3399999999999999, 3.3500000000000001, 3.3599999999999999, 3.3700000000000001, 3.3799999999999999, 3.3900000000000001, 3.3999999999999999, 3.4100000000000001, 3.4199999999999999, 3.4300000000000002, 3.4399999999999999, 3.4500000000000002, 3.46, 3.4700000000000002, 3.48, 3.4900000000000002, 3.5, 3.5099999999999998, 3.52, 3.5299999999999998, 3.54, 3.5499999999999998, 3.5600000000000001, 3.5699999999999998, 3.5800000000000001, 3.5899999999999999, 3.6000000000000001, 3.6099999999999999, 3.6200000000000001, 3.6299999999999999, 3.6400000000000001, 3.6499999999999999, 3.6600000000000001, 3.6699999999999999, 3.6800000000000002, 3.6899999999999999, 3.7000000000000002, 3.71, 3.7200000000000002, 3.73, 3.7400000000000002, 3.75, 3.7599999999999998, 3.77, 3.7799999999999998, 3.79, 3.7999999999999998, 3.8100000000000001, 3.8199999999999998, 3.8300000000000001, 3.8399999999999999, 3.8500000000000001, 3.8599999999999999, 3.8700000000000001, 3.8799999999999999, 3.8900000000000001, 3.8999999999999999, 3.9100000000000001, 3.9199999999999999, 3.9300000000000002, 3.9399999999999999, 3.9500000000000002, 3.96, 3.9700000000000002, 3.98, 3.9900000000000002, 4.0, 4.0099999999999998, 4.0199999999999996, 4.0300000000000002, 4.04, 4.0499999999999998, 4.0599999999999996, 4.0700000000000003, 4.0800000000000001, 4.0899999999999999, 4.0999999999999996, 4.1100000000000003, 4.1200000000000001, 4.1299999999999999, 4.1399999999999997, 4.1500000000000004, 4.1600000000000001, 4.1699999999999999, 4.1799999999999997, 4.1900000000000004, 4.2000000000000002, 4.21, 4.2199999999999998, 4.2300000000000004, 4.2400000000000002]
4:31:28[QML:Reduced 5; QMD 8] [compute expectation values] times to compute: [0.0, 0.01, 0.02, 0.029999999999999999, 0.040000000000000001, 0.050000000000000003, 0.059999999999999998, 0.070000000000000007, 0.080000000000000002, 0.089999999999999997, 0.10000000000000001, 0.11, 0.12, 0.13, 0.14000000000000001, 0.14999999999999999, 0.16, 0.17000000000000001, 0.17999999999999999, 0.19, 0.20000000000000001, 0.20999999999999999, 0.22, 0.23000000000000001, 0.23999999999999999, 0.25, 0.26000000000000001, 0.27000000000000002, 0.28000000000000003, 0.28999999999999998, 0.29999999999999999, 0.31, 0.32000000000000001, 0.33000000000000002, 0.34000000000000002, 0.34999999999999998, 0.35999999999999999, 0.37, 0.38, 0.39000000000000001, 0.40000000000000002, 0.40999999999999998, 0.41999999999999998, 0.42999999999999999, 0.44, 0.45000000000000001, 0.46000000000000002, 0.46999999999999997, 0.47999999999999998, 0.48999999999999999, 0.5, 0.51000000000000001, 0.52000000000000002, 0.53000000000000003, 0.54000000000000004, 0.55000000000000004, 0.56000000000000005, 0.56999999999999995, 0.57999999999999996, 0.58999999999999997, 0.59999999999999998, 0.60999999999999999, 0.62, 0.63, 0.64000000000000001, 0.65000000000000002, 0.66000000000000003, 0.67000000000000004, 0.68000000000000005, 0.68999999999999995, 0.69999999999999996, 0.70999999999999996, 0.71999999999999997, 0.72999999999999998, 0.73999999999999999, 0.75, 0.76000000000000001, 0.77000000000000002, 0.78000000000000003, 0.79000000000000004, 0.80000000000000004, 0.81000000000000005, 0.81999999999999995, 0.82999999999999996, 0.83999999999999997, 0.84999999999999998, 0.85999999999999999, 0.87, 0.88, 0.89000000000000001, 0.90000000000000002, 0.91000000000000003, 0.92000000000000004, 0.93000000000000005, 0.93999999999999995, 0.94999999999999996, 0.95999999999999996, 0.96999999999999997, 0.97999999999999998, 0.98999999999999999, 1.0, 1.01, 1.02, 1.03, 1.04, 1.05, 1.0600000000000001, 1.0700000000000001, 1.0800000000000001, 1.0900000000000001, 1.1000000000000001, 1.1100000000000001, 1.1200000000000001, 1.1299999999999999, 1.1399999999999999, 1.1499999999999999, 1.1599999999999999, 1.1699999999999999, 1.1799999999999999, 1.1899999999999999, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3, 1.3100000000000001, 1.3200000000000001, 1.3300000000000001, 1.3400000000000001, 1.3500000000000001, 1.3600000000000001, 1.3700000000000001, 1.3799999999999999, 1.3899999999999999, 1.3999999999999999, 1.4099999999999999, 1.4199999999999999, 1.4299999999999999, 1.4399999999999999, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5, 1.51, 1.52, 1.53, 1.54, 1.55, 1.5600000000000001, 1.5700000000000001, 1.5800000000000001, 1.5900000000000001, 1.6000000000000001, 1.6100000000000001, 1.6200000000000001, 1.6299999999999999, 1.6399999999999999, 1.6499999999999999, 1.6599999999999999, 1.6699999999999999, 1.6799999999999999, 1.6899999999999999, 1.7, 1.71, 1.72, 1.73, 1.74, 1.75, 1.76, 1.77, 1.78, 1.79, 1.8, 1.8100000000000001, 1.8200000000000001, 1.8300000000000001, 1.8400000000000001, 1.8500000000000001, 1.8600000000000001, 1.8700000000000001, 1.8799999999999999, 1.8899999999999999, 1.8999999999999999, 1.9099999999999999, 1.9199999999999999, 1.9299999999999999, 1.9399999999999999, 1.95, 1.96, 1.97, 1.98, 1.99, 2.0, 2.0099999999999998, 2.02, 2.0299999999999998, 2.04, 2.0499999999999998, 2.0600000000000001, 2.0699999999999998, 2.0800000000000001, 2.0899999999999999, 2.1000000000000001, 2.1099999999999999, 2.1200000000000001, 2.1299999999999999, 2.1400000000000001, 2.1499999999999999, 2.1600000000000001, 2.1699999999999999, 2.1800000000000002, 2.1899999999999999, 2.2000000000000002, 2.21, 2.2200000000000002, 2.23, 2.2400000000000002, 2.25, 2.2599999999999998, 2.27, 2.2799999999999998, 2.29, 2.2999999999999998, 2.3100000000000001, 2.3199999999999998, 2.3300000000000001, 2.3399999999999999, 2.3500000000000001, 2.3599999999999999, 2.3700000000000001, 2.3799999999999999, 2.3900000000000001, 2.3999999999999999, 2.4100000000000001, 2.4199999999999999, 2.4300000000000002, 2.4399999999999999, 2.4500000000000002, 2.46, 2.4700000000000002, 2.48, 2.4900000000000002, 2.5, 2.5099999999999998, 2.52, 2.5299999999999998, 2.54, 2.5499999999999998, 2.5600000000000001, 2.5699999999999998, 2.5800000000000001, 2.5899999999999999, 2.6000000000000001, 2.6099999999999999, 2.6200000000000001, 2.6299999999999999, 2.6400000000000001, 2.6499999999999999, 2.6600000000000001, 2.6699999999999999, 2.6800000000000002, 2.6899999999999999, 2.7000000000000002, 2.71, 2.7200000000000002, 2.73, 2.7400000000000002, 2.75, 2.7599999999999998, 2.77, 2.7799999999999998, 2.79, 2.7999999999999998, 2.8100000000000001, 2.8199999999999998, 2.8300000000000001, 2.8399999999999999, 2.8500000000000001, 2.8599999999999999, 2.8700000000000001, 2.8799999999999999, 2.8900000000000001, 2.8999999999999999, 2.9100000000000001, 2.9199999999999999, 2.9300000000000002, 2.9399999999999999, 2.9500000000000002, 2.96, 2.9700000000000002, 2.98, 2.9900000000000002, 3.0, 3.0099999999999998, 3.02, 3.0299999999999998, 3.04, 3.0499999999999998, 3.0600000000000001, 3.0699999999999998, 3.0800000000000001, 3.0899999999999999, 3.1000000000000001, 3.1099999999999999, 3.1200000000000001, 3.1299999999999999, 3.1400000000000001, 3.1499999999999999, 3.1600000000000001, 3.1699999999999999, 3.1800000000000002, 3.1899999999999999, 3.2000000000000002, 3.21, 3.2200000000000002, 3.23, 3.2400000000000002, 3.25, 3.2599999999999998, 3.27, 3.2799999999999998, 3.29, 3.2999999999999998, 3.3100000000000001, 3.3199999999999998, 3.3300000000000001, 3.3399999999999999, 3.3500000000000001, 3.3599999999999999, 3.3700000000000001, 3.3799999999999999, 3.3900000000000001, 3.3999999999999999, 3.4100000000000001, 3.4199999999999999, 3.4300000000000002, 3.4399999999999999, 3.4500000000000002, 3.46, 3.4700000000000002, 3.48, 3.4900000000000002, 3.5, 3.5099999999999998, 3.52, 3.5299999999999998, 3.54, 3.5499999999999998, 3.5600000000000001, 3.5699999999999998, 3.5800000000000001, 3.5899999999999999, 3.6000000000000001, 3.6099999999999999, 3.6200000000000001, 3.6299999999999999, 3.6400000000000001, 3.6499999999999999, 3.6600000000000001, 3.6699999999999999, 3.6800000000000002, 3.6899999999999999, 3.7000000000000002, 3.71, 3.7200000000000002, 3.73, 3.7400000000000002, 3.75, 3.7599999999999998, 3.77, 3.7799999999999998, 3.79, 3.7999999999999998, 3.8100000000000001, 3.8199999999999998, 3.8300000000000001, 3.8399999999999999, 3.8500000000000001, 3.8599999999999999, 3.8700000000000001, 3.8799999999999999, 3.8900000000000001, 3.8999999999999999, 3.9100000000000001, 3.9199999999999999, 3.9300000000000002, 3.9399999999999999, 3.9500000000000002, 3.96, 3.9700000000000002, 3.98, 3.9900000000000002, 4.0, 4.0099999999999998, 4.0199999999999996, 4.0300000000000002, 4.04, 4.0499999999999998, 4.0599999999999996, 4.0700000000000003, 4.0800000000000001, 4.0899999999999999, 4.0999999999999996, 4.1100000000000003, 4.1200000000000001, 4.1299999999999999, 4.1399999999999997, 4.1500000000000004, 4.1600000000000001, 4.1699999999999999, 4.1799999999999997, 4.1900000000000004, 4.2000000000000002, 4.21, 4.2199999999999998, 4.2300000000000004, 4.2400000000000002]
4:31:29[QML:Reduced 8; QMD 8] Computing expectation values. 
Measurement Type: hahn_evolution 
LearnedHamiltonian [[ 1.99702703+0.j          0.00000000+0.j         -0.09883486-3.10676659j
  -2.99999974+0.j        ]
 [ 0.00000000+0.j          1.99702703+0.j          2.99999974+0.j
  -0.09883486-3.10676659j]
 [-0.09883486+3.10676659j  2.99999974+0.j         -1.99702703+0.j
   0.00000000+0.j        ]
 [-2.99999974+0.j         -0.09883486+3.10676659j  0.00000000+0.j
  -1.99702703+0.j        ]] 
Probe: [ 0.49971827 -4.83795104e-04j  0.50013082 +2.23249446e-04j
  0.50031730 -2.46059755e-05j  0.49983262 -6.92224955e-04j] 
Times: [0.0, 0.01, 0.02, 0.029999999999999999, 0.040000000000000001, 0.050000000000000003, 0.059999999999999998, 0.070000000000000007, 0.080000000000000002, 0.089999999999999997, 0.10000000000000001, 0.11, 0.12, 0.13, 0.14000000000000001, 0.14999999999999999, 0.16, 0.17000000000000001, 0.17999999999999999, 0.19, 0.20000000000000001, 0.20999999999999999, 0.22, 0.23000000000000001, 0.23999999999999999, 0.25, 0.26000000000000001, 0.27000000000000002, 0.28000000000000003, 0.28999999999999998, 0.29999999999999999, 0.31, 0.32000000000000001, 0.33000000000000002, 0.34000000000000002, 0.34999999999999998, 0.35999999999999999, 0.37, 0.38, 0.39000000000000001, 0.40000000000000002, 0.40999999999999998, 0.41999999999999998, 0.42999999999999999, 0.44, 0.45000000000000001, 0.46000000000000002, 0.46999999999999997, 0.47999999999999998, 0.48999999999999999, 0.5, 0.51000000000000001, 0.52000000000000002, 0.53000000000000003, 0.54000000000000004, 0.55000000000000004, 0.56000000000000005, 0.56999999999999995, 0.57999999999999996, 0.58999999999999997, 0.59999999999999998, 0.60999999999999999, 0.62, 0.63, 0.64000000000000001, 0.65000000000000002, 0.66000000000000003, 0.67000000000000004, 0.68000000000000005, 0.68999999999999995, 0.69999999999999996, 0.70999999999999996, 0.71999999999999997, 0.72999999999999998, 0.73999999999999999, 0.75, 0.76000000000000001, 0.77000000000000002, 0.78000000000000003, 0.79000000000000004, 0.80000000000000004, 0.81000000000000005, 0.81999999999999995, 0.82999999999999996, 0.83999999999999997, 0.84999999999999998, 0.85999999999999999, 0.87, 0.88, 0.89000000000000001, 0.90000000000000002, 0.91000000000000003, 0.92000000000000004, 0.93000000000000005, 0.93999999999999995, 0.94999999999999996, 0.95999999999999996, 0.96999999999999997, 0.97999999999999998, 0.98999999999999999, 1.0, 1.01, 1.02, 1.03, 1.04, 1.05, 1.0600000000000001, 1.0700000000000001, 1.0800000000000001, 1.0900000000000001, 1.1000000000000001, 1.1100000000000001, 1.1200000000000001, 1.1299999999999999, 1.1399999999999999, 1.1499999999999999, 1.1599999999999999, 1.1699999999999999, 1.1799999999999999, 1.1899999999999999, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3, 1.3100000000000001, 1.3200000000000001, 1.3300000000000001, 1.3400000000000001, 1.3500000000000001, 1.3600000000000001, 1.3700000000000001, 1.3799999999999999, 1.3899999999999999, 1.3999999999999999, 1.4099999999999999, 1.4199999999999999, 1.4299999999999999, 1.4399999999999999, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5, 1.51, 1.52, 1.53, 1.54, 1.55, 1.5600000000000001, 1.5700000000000001, 1.5800000000000001, 1.5900000000000001, 1.6000000000000001, 1.6100000000000001, 1.6200000000000001, 1.6299999999999999, 1.6399999999999999, 1.6499999999999999, 1.6599999999999999, 1.6699999999999999, 1.6799999999999999, 1.6899999999999999, 1.7, 1.71, 1.72, 1.73, 1.74, 1.75, 1.76, 1.77, 1.78, 1.79, 1.8, 1.8100000000000001, 1.8200000000000001, 1.8300000000000001, 1.8400000000000001, 1.8500000000000001, 1.8600000000000001, 1.8700000000000001, 1.8799999999999999, 1.8899999999999999, 1.8999999999999999, 1.9099999999999999, 1.9199999999999999, 1.9299999999999999, 1.9399999999999999, 1.95, 1.96, 1.97, 1.98, 1.99, 2.0, 2.0099999999999998, 2.02, 2.0299999999999998, 2.04, 2.0499999999999998, 2.0600000000000001, 2.0699999999999998, 2.0800000000000001, 2.0899999999999999, 2.1000000000000001, 2.1099999999999999, 2.1200000000000001, 2.1299999999999999, 2.1400000000000001, 2.1499999999999999, 2.1600000000000001, 2.1699999999999999, 2.1800000000000002, 2.1899999999999999, 2.2000000000000002, 2.21, 2.2200000000000002, 2.23, 2.2400000000000002, 2.25, 2.2599999999999998, 2.27, 2.2799999999999998, 2.29, 2.2999999999999998, 2.3100000000000001, 2.3199999999999998, 2.3300000000000001, 2.3399999999999999, 2.3500000000000001, 2.3599999999999999, 2.3700000000000001, 2.3799999999999999, 2.3900000000000001, 2.3999999999999999, 2.4100000000000001, 2.4199999999999999, 2.4300000000000002, 2.4399999999999999, 2.4500000000000002, 2.46, 2.4700000000000002, 2.48, 2.4900000000000002, 2.5, 2.5099999999999998, 2.52, 2.5299999999999998, 2.54, 2.5499999999999998, 2.5600000000000001, 2.5699999999999998, 2.5800000000000001, 2.5899999999999999, 2.6000000000000001, 2.6099999999999999, 2.6200000000000001, 2.6299999999999999, 2.6400000000000001, 2.6499999999999999, 2.6600000000000001, 2.6699999999999999, 2.6800000000000002, 2.6899999999999999, 2.7000000000000002, 2.71, 2.7200000000000002, 2.73, 2.7400000000000002, 2.75, 2.7599999999999998, 2.77, 2.7799999999999998, 2.79, 2.7999999999999998, 2.8100000000000001, 2.8199999999999998, 2.8300000000000001, 2.8399999999999999, 2.8500000000000001, 2.8599999999999999, 2.8700000000000001, 2.8799999999999999, 2.8900000000000001, 2.8999999999999999, 2.9100000000000001, 2.9199999999999999, 2.9300000000000002, 2.9399999999999999, 2.9500000000000002, 2.96, 2.9700000000000002, 2.98, 2.9900000000000002, 3.0, 3.0099999999999998, 3.02, 3.0299999999999998, 3.04, 3.0499999999999998, 3.0600000000000001, 3.0699999999999998, 3.0800000000000001, 3.0899999999999999, 3.1000000000000001, 3.1099999999999999, 3.1200000000000001, 3.1299999999999999, 3.1400000000000001, 3.1499999999999999, 3.1600000000000001, 3.1699999999999999, 3.1800000000000002, 3.1899999999999999, 3.2000000000000002, 3.21, 3.2200000000000002, 3.23, 3.2400000000000002, 3.25, 3.2599999999999998, 3.27, 3.2799999999999998, 3.29, 3.2999999999999998, 3.3100000000000001, 3.3199999999999998, 3.3300000000000001, 3.3399999999999999, 3.3500000000000001, 3.3599999999999999, 3.3700000000000001, 3.3799999999999999, 3.3900000000000001, 3.3999999999999999, 3.4100000000000001, 3.4199999999999999, 3.4300000000000002, 3.4399999999999999, 3.4500000000000002, 3.46, 3.4700000000000002, 3.48, 3.4900000000000002, 3.5, 3.5099999999999998, 3.52, 3.5299999999999998, 3.54, 3.5499999999999998, 3.5600000000000001, 3.5699999999999998, 3.5800000000000001, 3.5899999999999999, 3.6000000000000001, 3.6099999999999999, 3.6200000000000001, 3.6299999999999999, 3.6400000000000001, 3.6499999999999999, 3.6600000000000001, 3.6699999999999999, 3.6800000000000002, 3.6899999999999999, 3.7000000000000002, 3.71, 3.7200000000000002, 3.73, 3.7400000000000002, 3.75, 3.7599999999999998, 3.77, 3.7799999999999998, 3.79, 3.7999999999999998, 3.8100000000000001, 3.8199999999999998, 3.8300000000000001, 3.8399999999999999, 3.8500000000000001, 3.8599999999999999, 3.8700000000000001, 3.8799999999999999, 3.8900000000000001, 3.8999999999999999, 3.9100000000000001, 3.9199999999999999, 3.9300000000000002, 3.9399999999999999, 3.9500000000000002, 3.96, 3.9700000000000002, 3.98, 3.9900000000000002, 4.0, 4.0099999999999998, 4.0199999999999996, 4.0300000000000002, 4.04, 4.0499999999999998, 4.0599999999999996, 4.0700000000000003, 4.0800000000000001, 4.0899999999999999, 4.0999999999999996, 4.1100000000000003, 4.1200000000000001, 4.1299999999999999, 4.1399999999999997, 4.1500000000000004, 4.1600000000000001, 4.1699999999999999, 4.1799999999999997, 4.1900000000000004, 4.2000000000000002, 4.21, 4.2199999999999998, 4.2300000000000004, 4.2400000000000002]
4:31:29[QML:Reduced 8; QMD 8] [compute expectation values] times to compute: []
4:31:29[QML:Reduced 10; QMD 8] Computing expectation values. 
Measurement Type: hahn_evolution 
LearnedHamiltonian [[ 1.76291616+0.j          0.00000000+0.j         -0.08370890-2.94946994j
  -3.01756330+0.j        ]
 [ 0.00000000+0.j          2.18346954+0.j          3.01756330+0.j
  -0.08370890-2.94946994j]
 [-0.08370890+2.94946994j  3.01756330+0.j         -1.76291616+0.j
   0.00000000+0.j        ]
 [-3.01756330+0.j         -0.08370890+2.94946994j  0.00000000+0.j
  -2.18346954+0.j        ]] 
Probe: [ 0.49971827 -4.83795104e-04j  0.50013082 +2.23249446e-04j
  0.50031730 -2.46059755e-05j  0.49983262 -6.92224955e-04j] 
Times: [0.0, 0.01, 0.02, 0.029999999999999999, 0.040000000000000001, 0.050000000000000003, 0.059999999999999998, 0.070000000000000007, 0.080000000000000002, 0.089999999999999997, 0.10000000000000001, 0.11, 0.12, 0.13, 0.14000000000000001, 0.14999999999999999, 0.16, 0.17000000000000001, 0.17999999999999999, 0.19, 0.20000000000000001, 0.20999999999999999, 0.22, 0.23000000000000001, 0.23999999999999999, 0.25, 0.26000000000000001, 0.27000000000000002, 0.28000000000000003, 0.28999999999999998, 0.29999999999999999, 0.31, 0.32000000000000001, 0.33000000000000002, 0.34000000000000002, 0.34999999999999998, 0.35999999999999999, 0.37, 0.38, 0.39000000000000001, 0.40000000000000002, 0.40999999999999998, 0.41999999999999998, 0.42999999999999999, 0.44, 0.45000000000000001, 0.46000000000000002, 0.46999999999999997, 0.47999999999999998, 0.48999999999999999, 0.5, 0.51000000000000001, 0.52000000000000002, 0.53000000000000003, 0.54000000000000004, 0.55000000000000004, 0.56000000000000005, 0.56999999999999995, 0.57999999999999996, 0.58999999999999997, 0.59999999999999998, 0.60999999999999999, 0.62, 0.63, 0.64000000000000001, 0.65000000000000002, 0.66000000000000003, 0.67000000000000004, 0.68000000000000005, 0.68999999999999995, 0.69999999999999996, 0.70999999999999996, 0.71999999999999997, 0.72999999999999998, 0.73999999999999999, 0.75, 0.76000000000000001, 0.77000000000000002, 0.78000000000000003, 0.79000000000000004, 0.80000000000000004, 0.81000000000000005, 0.81999999999999995, 0.82999999999999996, 0.83999999999999997, 0.84999999999999998, 0.85999999999999999, 0.87, 0.88, 0.89000000000000001, 0.90000000000000002, 0.91000000000000003, 0.92000000000000004, 0.93000000000000005, 0.93999999999999995, 0.94999999999999996, 0.95999999999999996, 0.96999999999999997, 0.97999999999999998, 0.98999999999999999, 1.0, 1.01, 1.02, 1.03, 1.04, 1.05, 1.0600000000000001, 1.0700000000000001, 1.0800000000000001, 1.0900000000000001, 1.1000000000000001, 1.1100000000000001, 1.1200000000000001, 1.1299999999999999, 1.1399999999999999, 1.1499999999999999, 1.1599999999999999, 1.1699999999999999, 1.1799999999999999, 1.1899999999999999, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3, 1.3100000000000001, 1.3200000000000001, 1.3300000000000001, 1.3400000000000001, 1.3500000000000001, 1.3600000000000001, 1.3700000000000001, 1.3799999999999999, 1.3899999999999999, 1.3999999999999999, 1.4099999999999999, 1.4199999999999999, 1.4299999999999999, 1.4399999999999999, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5, 1.51, 1.52, 1.53, 1.54, 1.55, 1.5600000000000001, 1.5700000000000001, 1.5800000000000001, 1.5900000000000001, 1.6000000000000001, 1.6100000000000001, 1.6200000000000001, 1.6299999999999999, 1.6399999999999999, 1.6499999999999999, 1.6599999999999999, 1.6699999999999999, 1.6799999999999999, 1.6899999999999999, 1.7, 1.71, 1.72, 1.73, 1.74, 1.75, 1.76, 1.77, 1.78, 1.79, 1.8, 1.8100000000000001, 1.8200000000000001, 1.8300000000000001, 1.8400000000000001, 1.8500000000000001, 1.8600000000000001, 1.8700000000000001, 1.8799999999999999, 1.8899999999999999, 1.8999999999999999, 1.9099999999999999, 1.9199999999999999, 1.9299999999999999, 1.9399999999999999, 1.95, 1.96, 1.97, 1.98, 1.99, 2.0, 2.0099999999999998, 2.02, 2.0299999999999998, 2.04, 2.0499999999999998, 2.0600000000000001, 2.0699999999999998, 2.0800000000000001, 2.0899999999999999, 2.1000000000000001, 2.1099999999999999, 2.1200000000000001, 2.1299999999999999, 2.1400000000000001, 2.1499999999999999, 2.1600000000000001, 2.1699999999999999, 2.1800000000000002, 2.1899999999999999, 2.2000000000000002, 2.21, 2.2200000000000002, 2.23, 2.2400000000000002, 2.25, 2.2599999999999998, 2.27, 2.2799999999999998, 2.29, 2.2999999999999998, 2.3100000000000001, 2.3199999999999998, 2.3300000000000001, 2.3399999999999999, 2.3500000000000001, 2.3599999999999999, 2.3700000000000001, 2.3799999999999999, 2.3900000000000001, 2.3999999999999999, 2.4100000000000001, 2.4199999999999999, 2.4300000000000002, 2.4399999999999999, 2.4500000000000002, 2.46, 2.4700000000000002, 2.48, 2.4900000000000002, 2.5, 2.5099999999999998, 2.52, 2.5299999999999998, 2.54, 2.5499999999999998, 2.5600000000000001, 2.5699999999999998, 2.5800000000000001, 2.5899999999999999, 2.6000000000000001, 2.6099999999999999, 2.6200000000000001, 2.6299999999999999, 2.6400000000000001, 2.6499999999999999, 2.6600000000000001, 2.6699999999999999, 2.6800000000000002, 2.6899999999999999, 2.7000000000000002, 2.71, 2.7200000000000002, 2.73, 2.7400000000000002, 2.75, 2.7599999999999998, 2.77, 2.7799999999999998, 2.79, 2.7999999999999998, 2.8100000000000001, 2.8199999999999998, 2.8300000000000001, 2.8399999999999999, 2.8500000000000001, 2.8599999999999999, 2.8700000000000001, 2.8799999999999999, 2.8900000000000001, 2.8999999999999999, 2.9100000000000001, 2.9199999999999999, 2.9300000000000002, 2.9399999999999999, 2.9500000000000002, 2.96, 2.9700000000000002, 2.98, 2.9900000000000002, 3.0, 3.0099999999999998, 3.02, 3.0299999999999998, 3.04, 3.0499999999999998, 3.0600000000000001, 3.0699999999999998, 3.0800000000000001, 3.0899999999999999, 3.1000000000000001, 3.1099999999999999, 3.1200000000000001, 3.1299999999999999, 3.1400000000000001, 3.1499999999999999, 3.1600000000000001, 3.1699999999999999, 3.1800000000000002, 3.1899999999999999, 3.2000000000000002, 3.21, 3.2200000000000002, 3.23, 3.2400000000000002, 3.25, 3.2599999999999998, 3.27, 3.2799999999999998, 3.29, 3.2999999999999998, 3.3100000000000001, 3.3199999999999998, 3.3300000000000001, 3.3399999999999999, 3.3500000000000001, 3.3599999999999999, 3.3700000000000001, 3.3799999999999999, 3.3900000000000001, 3.3999999999999999, 3.4100000000000001, 3.4199999999999999, 3.4300000000000002, 3.4399999999999999, 3.4500000000000002, 3.46, 3.4700000000000002, 3.48, 3.4900000000000002, 3.5, 3.5099999999999998, 3.52, 3.5299999999999998, 3.54, 3.5499999999999998, 3.5600000000000001, 3.5699999999999998, 3.5800000000000001, 3.5899999999999999, 3.6000000000000001, 3.6099999999999999, 3.6200000000000001, 3.6299999999999999, 3.6400000000000001, 3.6499999999999999, 3.6600000000000001, 3.6699999999999999, 3.6800000000000002, 3.6899999999999999, 3.7000000000000002, 3.71, 3.7200000000000002, 3.73, 3.7400000000000002, 3.75, 3.7599999999999998, 3.77, 3.7799999999999998, 3.79, 3.7999999999999998, 3.8100000000000001, 3.8199999999999998, 3.8300000000000001, 3.8399999999999999, 3.8500000000000001, 3.8599999999999999, 3.8700000000000001, 3.8799999999999999, 3.8900000000000001, 3.8999999999999999, 3.9100000000000001, 3.9199999999999999, 3.9300000000000002, 3.9399999999999999, 3.9500000000000002, 3.96, 3.9700000000000002, 3.98, 3.9900000000000002, 4.0, 4.0099999999999998, 4.0199999999999996, 4.0300000000000002, 4.04, 4.0499999999999998, 4.0599999999999996, 4.0700000000000003, 4.0800000000000001, 4.0899999999999999, 4.0999999999999996, 4.1100000000000003, 4.1200000000000001, 4.1299999999999999, 4.1399999999999997, 4.1500000000000004, 4.1600000000000001, 4.1699999999999999, 4.1799999999999997, 4.1900000000000004, 4.2000000000000002, 4.21, 4.2199999999999998, 4.2300000000000004, 4.2400000000000002]
4:31:29[QML:Reduced 10; QMD 8] [compute expectation values] times to compute: [0.0, 0.01, 0.02, 0.029999999999999999, 0.040000000000000001, 0.050000000000000003, 0.059999999999999998, 0.070000000000000007, 0.080000000000000002, 0.089999999999999997, 0.10000000000000001, 0.11, 0.12, 0.13, 0.14000000000000001, 0.14999999999999999, 0.16, 0.17000000000000001, 0.17999999999999999, 0.19, 0.20000000000000001, 0.20999999999999999, 0.22, 0.23000000000000001, 0.23999999999999999, 0.25, 0.26000000000000001, 0.27000000000000002, 0.28000000000000003, 0.28999999999999998, 0.29999999999999999, 0.31, 0.32000000000000001, 0.33000000000000002, 0.34000000000000002, 0.34999999999999998, 0.35999999999999999, 0.37, 0.38, 0.39000000000000001, 0.40000000000000002, 0.40999999999999998, 0.41999999999999998, 0.42999999999999999, 0.44, 0.45000000000000001, 0.46000000000000002, 0.46999999999999997, 0.47999999999999998, 0.48999999999999999, 0.5, 0.51000000000000001, 0.52000000000000002, 0.53000000000000003, 0.54000000000000004, 0.55000000000000004, 0.56000000000000005, 0.56999999999999995, 0.57999999999999996, 0.58999999999999997, 0.59999999999999998, 0.60999999999999999, 0.62, 0.63, 0.64000000000000001, 0.65000000000000002, 0.66000000000000003, 0.67000000000000004, 0.68000000000000005, 0.68999999999999995, 0.69999999999999996, 0.70999999999999996, 0.71999999999999997, 0.72999999999999998, 0.73999999999999999, 0.75, 0.76000000000000001, 0.77000000000000002, 0.78000000000000003, 0.79000000000000004, 0.80000000000000004, 0.81000000000000005, 0.81999999999999995, 0.82999999999999996, 0.83999999999999997, 0.84999999999999998, 0.85999999999999999, 0.87, 0.88, 0.89000000000000001, 0.90000000000000002, 0.91000000000000003, 0.92000000000000004, 0.93000000000000005, 0.93999999999999995, 0.94999999999999996, 0.95999999999999996, 0.96999999999999997, 0.97999999999999998, 0.98999999999999999, 1.0, 1.01, 1.02, 1.03, 1.04, 1.05, 1.0600000000000001, 1.0700000000000001, 1.0800000000000001, 1.0900000000000001, 1.1000000000000001, 1.1100000000000001, 1.1200000000000001, 1.1299999999999999, 1.1399999999999999, 1.1499999999999999, 1.1599999999999999, 1.1699999999999999, 1.1799999999999999, 1.1899999999999999, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3, 1.3100000000000001, 1.3200000000000001, 1.3300000000000001, 1.3400000000000001, 1.3500000000000001, 1.3600000000000001, 1.3700000000000001, 1.3799999999999999, 1.3899999999999999, 1.3999999999999999, 1.4099999999999999, 1.4199999999999999, 1.4299999999999999, 1.4399999999999999, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5, 1.51, 1.52, 1.53, 1.54, 1.55, 1.5600000000000001, 1.5700000000000001, 1.5800000000000001, 1.5900000000000001, 1.6000000000000001, 1.6100000000000001, 1.6200000000000001, 1.6299999999999999, 1.6399999999999999, 1.6499999999999999, 1.6599999999999999, 1.6699999999999999, 1.6799999999999999, 1.6899999999999999, 1.7, 1.71, 1.72, 1.73, 1.74, 1.75, 1.76, 1.77, 1.78, 1.79, 1.8, 1.8100000000000001, 1.8200000000000001, 1.8300000000000001, 1.8400000000000001, 1.8500000000000001, 1.8600000000000001, 1.8700000000000001, 1.8799999999999999, 1.8899999999999999, 1.8999999999999999, 1.9099999999999999, 1.9199999999999999, 1.9299999999999999, 1.9399999999999999, 1.95, 1.96, 1.97, 1.98, 1.99, 2.0, 2.0099999999999998, 2.02, 2.0299999999999998, 2.04, 2.0499999999999998, 2.0600000000000001, 2.0699999999999998, 2.0800000000000001, 2.0899999999999999, 2.1000000000000001, 2.1099999999999999, 2.1200000000000001, 2.1299999999999999, 2.1400000000000001, 2.1499999999999999, 2.1600000000000001, 2.1699999999999999, 2.1800000000000002, 2.1899999999999999, 2.2000000000000002, 2.21, 2.2200000000000002, 2.23, 2.2400000000000002, 2.25, 2.2599999999999998, 2.27, 2.2799999999999998, 2.29, 2.2999999999999998, 2.3100000000000001, 2.3199999999999998, 2.3300000000000001, 2.3399999999999999, 2.3500000000000001, 2.3599999999999999, 2.3700000000000001, 2.3799999999999999, 2.3900000000000001, 2.3999999999999999, 2.4100000000000001, 2.4199999999999999, 2.4300000000000002, 2.4399999999999999, 2.4500000000000002, 2.46, 2.4700000000000002, 2.48, 2.4900000000000002, 2.5, 2.5099999999999998, 2.52, 2.5299999999999998, 2.54, 2.5499999999999998, 2.5600000000000001, 2.5699999999999998, 2.5800000000000001, 2.5899999999999999, 2.6000000000000001, 2.6099999999999999, 2.6200000000000001, 2.6299999999999999, 2.6400000000000001, 2.6499999999999999, 2.6600000000000001, 2.6699999999999999, 2.6800000000000002, 2.6899999999999999, 2.7000000000000002, 2.71, 2.7200000000000002, 2.73, 2.7400000000000002, 2.75, 2.7599999999999998, 2.77, 2.7799999999999998, 2.79, 2.7999999999999998, 2.8100000000000001, 2.8199999999999998, 2.8300000000000001, 2.8399999999999999, 2.8500000000000001, 2.8599999999999999, 2.8700000000000001, 2.8799999999999999, 2.8900000000000001, 2.8999999999999999, 2.9100000000000001, 2.9199999999999999, 2.9300000000000002, 2.9399999999999999, 2.9500000000000002, 2.96, 2.9700000000000002, 2.98, 2.9900000000000002, 3.0, 3.0099999999999998, 3.02, 3.0299999999999998, 3.04, 3.0499999999999998, 3.0600000000000001, 3.0699999999999998, 3.0800000000000001, 3.0899999999999999, 3.1000000000000001, 3.1099999999999999, 3.1200000000000001, 3.1299999999999999, 3.1400000000000001, 3.1499999999999999, 3.1600000000000001, 3.1699999999999999, 3.1800000000000002, 3.1899999999999999, 3.2000000000000002, 3.21, 3.2200000000000002, 3.23, 3.2400000000000002, 3.25, 3.2599999999999998, 3.27, 3.2799999999999998, 3.29, 3.2999999999999998, 3.3100000000000001, 3.3199999999999998, 3.3300000000000001, 3.3399999999999999, 3.3500000000000001, 3.3599999999999999, 3.3700000000000001, 3.3799999999999999, 3.3900000000000001, 3.3999999999999999, 3.4100000000000001, 3.4199999999999999, 3.4300000000000002, 3.4399999999999999, 3.4500000000000002, 3.46, 3.4700000000000002, 3.48, 3.4900000000000002, 3.5, 3.5099999999999998, 3.52, 3.5299999999999998, 3.54, 3.5499999999999998, 3.5600000000000001, 3.5699999999999998, 3.5800000000000001, 3.5899999999999999, 3.6000000000000001, 3.6099999999999999, 3.6200000000000001, 3.6299999999999999, 3.6400000000000001, 3.6499999999999999, 3.6600000000000001, 3.6699999999999999, 3.6800000000000002, 3.6899999999999999, 3.7000000000000002, 3.71, 3.7200000000000002, 3.73, 3.7400000000000002, 3.75, 3.7599999999999998, 3.77, 3.7799999999999998, 3.79, 3.7999999999999998, 3.8100000000000001, 3.8199999999999998, 3.8300000000000001, 3.8399999999999999, 3.8500000000000001, 3.8599999999999999, 3.8700000000000001, 3.8799999999999999, 3.8900000000000001, 3.8999999999999999, 3.9100000000000001, 3.9199999999999999, 3.9300000000000002, 3.9399999999999999, 3.9500000000000002, 3.96, 3.9700000000000002, 3.98, 3.9900000000000002, 4.0, 4.0099999999999998, 4.0199999999999996, 4.0300000000000002, 4.04, 4.0499999999999998, 4.0599999999999996, 4.0700000000000003, 4.0800000000000001, 4.0899999999999999, 4.0999999999999996, 4.1100000000000003, 4.1200000000000001, 4.1299999999999999, 4.1399999999999997, 4.1500000000000004, 4.1600000000000001, 4.1699999999999999, 4.1799999999999997, 4.1900000000000004, 4.2000000000000002, 4.21, 4.2199999999999998, 4.2300000000000004, 4.2400000000000002]
4:31:29[QML:Reduced 11; QMD 8] Computing expectation values. 
Measurement Type: hahn_evolution 
LearnedHamiltonian [[ 4.56552471+0.j          0.00000000+0.j         -1.05663152-6.09030552j
   3.88430711+0.j        ]
 [ 0.00000000+0.j          1.54000692+0.j          9.22529159+0.j
  -1.05663152-6.09030552j]
 [-1.05663152+6.09030552j  9.22529159+0.j         -4.56552471+0.j
   0.00000000+0.j        ]
 [ 3.88430711+0.j         -1.05663152+6.09030552j  0.00000000+0.j
  -1.54000692+0.j        ]] 
Probe: [ 0.49971827 -4.83795104e-04j  0.50013082 +2.23249446e-04j
  0.50031730 -2.46059755e-05j  0.49983262 -6.92224955e-04j] 
Times: [0.0, 0.01, 0.02, 0.029999999999999999, 0.040000000000000001, 0.050000000000000003, 0.059999999999999998, 0.070000000000000007, 0.080000000000000002, 0.089999999999999997, 0.10000000000000001, 0.11, 0.12, 0.13, 0.14000000000000001, 0.14999999999999999, 0.16, 0.17000000000000001, 0.17999999999999999, 0.19, 0.20000000000000001, 0.20999999999999999, 0.22, 0.23000000000000001, 0.23999999999999999, 0.25, 0.26000000000000001, 0.27000000000000002, 0.28000000000000003, 0.28999999999999998, 0.29999999999999999, 0.31, 0.32000000000000001, 0.33000000000000002, 0.34000000000000002, 0.34999999999999998, 0.35999999999999999, 0.37, 0.38, 0.39000000000000001, 0.40000000000000002, 0.40999999999999998, 0.41999999999999998, 0.42999999999999999, 0.44, 0.45000000000000001, 0.46000000000000002, 0.46999999999999997, 0.47999999999999998, 0.48999999999999999, 0.5, 0.51000000000000001, 0.52000000000000002, 0.53000000000000003, 0.54000000000000004, 0.55000000000000004, 0.56000000000000005, 0.56999999999999995, 0.57999999999999996, 0.58999999999999997, 0.59999999999999998, 0.60999999999999999, 0.62, 0.63, 0.64000000000000001, 0.65000000000000002, 0.66000000000000003, 0.67000000000000004, 0.68000000000000005, 0.68999999999999995, 0.69999999999999996, 0.70999999999999996, 0.71999999999999997, 0.72999999999999998, 0.73999999999999999, 0.75, 0.76000000000000001, 0.77000000000000002, 0.78000000000000003, 0.79000000000000004, 0.80000000000000004, 0.81000000000000005, 0.81999999999999995, 0.82999999999999996, 0.83999999999999997, 0.84999999999999998, 0.85999999999999999, 0.87, 0.88, 0.89000000000000001, 0.90000000000000002, 0.91000000000000003, 0.92000000000000004, 0.93000000000000005, 0.93999999999999995, 0.94999999999999996, 0.95999999999999996, 0.96999999999999997, 0.97999999999999998, 0.98999999999999999, 1.0, 1.01, 1.02, 1.03, 1.04, 1.05, 1.0600000000000001, 1.0700000000000001, 1.0800000000000001, 1.0900000000000001, 1.1000000000000001, 1.1100000000000001, 1.1200000000000001, 1.1299999999999999, 1.1399999999999999, 1.1499999999999999, 1.1599999999999999, 1.1699999999999999, 1.1799999999999999, 1.1899999999999999, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3, 1.3100000000000001, 1.3200000000000001, 1.3300000000000001, 1.3400000000000001, 1.3500000000000001, 1.3600000000000001, 1.3700000000000001, 1.3799999999999999, 1.3899999999999999, 1.3999999999999999, 1.4099999999999999, 1.4199999999999999, 1.4299999999999999, 1.4399999999999999, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5, 1.51, 1.52, 1.53, 1.54, 1.55, 1.5600000000000001, 1.5700000000000001, 1.5800000000000001, 1.5900000000000001, 1.6000000000000001, 1.6100000000000001, 1.6200000000000001, 1.6299999999999999, 1.6399999999999999, 1.6499999999999999, 1.6599999999999999, 1.6699999999999999, 1.6799999999999999, 1.6899999999999999, 1.7, 1.71, 1.72, 1.73, 1.74, 1.75, 1.76, 1.77, 1.78, 1.79, 1.8, 1.8100000000000001, 1.8200000000000001, 1.8300000000000001, 1.8400000000000001, 1.8500000000000001, 1.8600000000000001, 1.8700000000000001, 1.8799999999999999, 1.8899999999999999, 1.8999999999999999, 1.9099999999999999, 1.9199999999999999, 1.9299999999999999, 1.9399999999999999, 1.95, 1.96, 1.97, 1.98, 1.99, 2.0, 2.0099999999999998, 2.02, 2.0299999999999998, 2.04, 2.0499999999999998, 2.0600000000000001, 2.0699999999999998, 2.0800000000000001, 2.0899999999999999, 2.1000000000000001, 2.1099999999999999, 2.1200000000000001, 2.1299999999999999, 2.1400000000000001, 2.1499999999999999, 2.1600000000000001, 2.1699999999999999, 2.1800000000000002, 2.1899999999999999, 2.2000000000000002, 2.21, 2.2200000000000002, 2.23, 2.2400000000000002, 2.25, 2.2599999999999998, 2.27, 2.2799999999999998, 2.29, 2.2999999999999998, 2.3100000000000001, 2.3199999999999998, 2.3300000000000001, 2.3399999999999999, 2.3500000000000001, 2.3599999999999999, 2.3700000000000001, 2.3799999999999999, 2.3900000000000001, 2.3999999999999999, 2.4100000000000001, 2.4199999999999999, 2.4300000000000002, 2.4399999999999999, 2.4500000000000002, 2.46, 2.4700000000000002, 2.48, 2.4900000000000002, 2.5, 2.5099999999999998, 2.52, 2.5299999999999998, 2.54, 2.5499999999999998, 2.5600000000000001, 2.5699999999999998, 2.5800000000000001, 2.5899999999999999, 2.6000000000000001, 2.6099999999999999, 2.6200000000000001, 2.6299999999999999, 2.6400000000000001, 2.6499999999999999, 2.6600000000000001, 2.6699999999999999, 2.6800000000000002, 2.6899999999999999, 2.7000000000000002, 2.71, 2.7200000000000002, 2.73, 2.7400000000000002, 2.75, 2.7599999999999998, 2.77, 2.7799999999999998, 2.79, 2.7999999999999998, 2.8100000000000001, 2.8199999999999998, 2.8300000000000001, 2.8399999999999999, 2.8500000000000001, 2.8599999999999999, 2.8700000000000001, 2.8799999999999999, 2.8900000000000001, 2.8999999999999999, 2.9100000000000001, 2.9199999999999999, 2.9300000000000002, 2.9399999999999999, 2.9500000000000002, 2.96, 2.9700000000000002, 2.98, 2.9900000000000002, 3.0, 3.0099999999999998, 3.02, 3.0299999999999998, 3.04, 3.0499999999999998, 3.0600000000000001, 3.0699999999999998, 3.0800000000000001, 3.0899999999999999, 3.1000000000000001, 3.1099999999999999, 3.1200000000000001, 3.1299999999999999, 3.1400000000000001, 3.1499999999999999, 3.1600000000000001, 3.1699999999999999, 3.1800000000000002, 3.1899999999999999, 3.2000000000000002, 3.21, 3.2200000000000002, 3.23, 3.2400000000000002, 3.25, 3.2599999999999998, 3.27, 3.2799999999999998, 3.29, 3.2999999999999998, 3.3100000000000001, 3.3199999999999998, 3.3300000000000001, 3.3399999999999999, 3.3500000000000001, 3.3599999999999999, 3.3700000000000001, 3.3799999999999999, 3.3900000000000001, 3.3999999999999999, 3.4100000000000001, 3.4199999999999999, 3.4300000000000002, 3.4399999999999999, 3.4500000000000002, 3.46, 3.4700000000000002, 3.48, 3.4900000000000002, 3.5, 3.5099999999999998, 3.52, 3.5299999999999998, 3.54, 3.5499999999999998, 3.5600000000000001, 3.5699999999999998, 3.5800000000000001, 3.5899999999999999, 3.6000000000000001, 3.6099999999999999, 3.6200000000000001, 3.6299999999999999, 3.6400000000000001, 3.6499999999999999, 3.6600000000000001, 3.6699999999999999, 3.6800000000000002, 3.6899999999999999, 3.7000000000000002, 3.71, 3.7200000000000002, 3.73, 3.7400000000000002, 3.75, 3.7599999999999998, 3.77, 3.7799999999999998, 3.79, 3.7999999999999998, 3.8100000000000001, 3.8199999999999998, 3.8300000000000001, 3.8399999999999999, 3.8500000000000001, 3.8599999999999999, 3.8700000000000001, 3.8799999999999999, 3.8900000000000001, 3.8999999999999999, 3.9100000000000001, 3.9199999999999999, 3.9300000000000002, 3.9399999999999999, 3.9500000000000002, 3.96, 3.9700000000000002, 3.98, 3.9900000000000002, 4.0, 4.0099999999999998, 4.0199999999999996, 4.0300000000000002, 4.04, 4.0499999999999998, 4.0599999999999996, 4.0700000000000003, 4.0800000000000001, 4.0899999999999999, 4.0999999999999996, 4.1100000000000003, 4.1200000000000001, 4.1299999999999999, 4.1399999999999997, 4.1500000000000004, 4.1600000000000001, 4.1699999999999999, 4.1799999999999997, 4.1900000000000004, 4.2000000000000002, 4.21, 4.2199999999999998, 4.2300000000000004, 4.2400000000000002]
4:31:29[QML:Reduced 11; QMD 8] [compute expectation values] times to compute: [0.0, 0.01, 0.02, 0.029999999999999999, 0.040000000000000001, 0.050000000000000003, 0.059999999999999998, 0.070000000000000007, 0.080000000000000002, 0.089999999999999997, 0.10000000000000001, 0.11, 0.12, 0.13, 0.14000000000000001, 0.14999999999999999, 0.16, 0.17000000000000001, 0.17999999999999999, 0.19, 0.20000000000000001, 0.20999999999999999, 0.22, 0.23000000000000001, 0.23999999999999999, 0.25, 0.26000000000000001, 0.27000000000000002, 0.28000000000000003, 0.28999999999999998, 0.29999999999999999, 0.31, 0.32000000000000001, 0.33000000000000002, 0.34000000000000002, 0.34999999999999998, 0.35999999999999999, 0.37, 0.38, 0.39000000000000001, 0.40000000000000002, 0.40999999999999998, 0.41999999999999998, 0.42999999999999999, 0.44, 0.45000000000000001, 0.46000000000000002, 0.46999999999999997, 0.47999999999999998, 0.48999999999999999, 0.5, 0.51000000000000001, 0.52000000000000002, 0.53000000000000003, 0.54000000000000004, 0.55000000000000004, 0.56000000000000005, 0.56999999999999995, 0.57999999999999996, 0.58999999999999997, 0.59999999999999998, 0.60999999999999999, 0.62, 0.63, 0.64000000000000001, 0.65000000000000002, 0.66000000000000003, 0.67000000000000004, 0.68000000000000005, 0.68999999999999995, 0.69999999999999996, 0.70999999999999996, 0.71999999999999997, 0.72999999999999998, 0.73999999999999999, 0.75, 0.76000000000000001, 0.77000000000000002, 0.78000000000000003, 0.79000000000000004, 0.80000000000000004, 0.81000000000000005, 0.81999999999999995, 0.82999999999999996, 0.83999999999999997, 0.84999999999999998, 0.85999999999999999, 0.87, 0.88, 0.89000000000000001, 0.90000000000000002, 0.91000000000000003, 0.92000000000000004, 0.93000000000000005, 0.93999999999999995, 0.94999999999999996, 0.95999999999999996, 0.96999999999999997, 0.97999999999999998, 0.98999999999999999, 1.0, 1.01, 1.02, 1.03, 1.04, 1.05, 1.0600000000000001, 1.0700000000000001, 1.0800000000000001, 1.0900000000000001, 1.1000000000000001, 1.1100000000000001, 1.1200000000000001, 1.1299999999999999, 1.1399999999999999, 1.1499999999999999, 1.1599999999999999, 1.1699999999999999, 1.1799999999999999, 1.1899999999999999, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3, 1.3100000000000001, 1.3200000000000001, 1.3300000000000001, 1.3400000000000001, 1.3500000000000001, 1.3600000000000001, 1.3700000000000001, 1.3799999999999999, 1.3899999999999999, 1.3999999999999999, 1.4099999999999999, 1.4199999999999999, 1.4299999999999999, 1.4399999999999999, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5, 1.51, 1.52, 1.53, 1.54, 1.55, 1.5600000000000001, 1.5700000000000001, 1.5800000000000001, 1.5900000000000001, 1.6000000000000001, 1.6100000000000001, 1.6200000000000001, 1.6299999999999999, 1.6399999999999999, 1.6499999999999999, 1.6599999999999999, 1.6699999999999999, 1.6799999999999999, 1.6899999999999999, 1.7, 1.71, 1.72, 1.73, 1.74, 1.75, 1.76, 1.77, 1.78, 1.79, 1.8, 1.8100000000000001, 1.8200000000000001, 1.8300000000000001, 1.8400000000000001, 1.8500000000000001, 1.8600000000000001, 1.8700000000000001, 1.8799999999999999, 1.8899999999999999, 1.8999999999999999, 1.9099999999999999, 1.9199999999999999, 1.9299999999999999, 1.9399999999999999, 1.95, 1.96, 1.97, 1.98, 1.99, 2.0, 2.0099999999999998, 2.02, 2.0299999999999998, 2.04, 2.0499999999999998, 2.0600000000000001, 2.0699999999999998, 2.0800000000000001, 2.0899999999999999, 2.1000000000000001, 2.1099999999999999, 2.1200000000000001, 2.1299999999999999, 2.1400000000000001, 2.1499999999999999, 2.1600000000000001, 2.1699999999999999, 2.1800000000000002, 2.1899999999999999, 2.2000000000000002, 2.21, 2.2200000000000002, 2.23, 2.2400000000000002, 2.25, 2.2599999999999998, 2.27, 2.2799999999999998, 2.29, 2.2999999999999998, 2.3100000000000001, 2.3199999999999998, 2.3300000000000001, 2.3399999999999999, 2.3500000000000001, 2.3599999999999999, 2.3700000000000001, 2.3799999999999999, 2.3900000000000001, 2.3999999999999999, 2.4100000000000001, 2.4199999999999999, 2.4300000000000002, 2.4399999999999999, 2.4500000000000002, 2.46, 2.4700000000000002, 2.48, 2.4900000000000002, 2.5, 2.5099999999999998, 2.52, 2.5299999999999998, 2.54, 2.5499999999999998, 2.5600000000000001, 2.5699999999999998, 2.5800000000000001, 2.5899999999999999, 2.6000000000000001, 2.6099999999999999, 2.6200000000000001, 2.6299999999999999, 2.6400000000000001, 2.6499999999999999, 2.6600000000000001, 2.6699999999999999, 2.6800000000000002, 2.6899999999999999, 2.7000000000000002, 2.71, 2.7200000000000002, 2.73, 2.7400000000000002, 2.75, 2.7599999999999998, 2.77, 2.7799999999999998, 2.79, 2.7999999999999998, 2.8100000000000001, 2.8199999999999998, 2.8300000000000001, 2.8399999999999999, 2.8500000000000001, 2.8599999999999999, 2.8700000000000001, 2.8799999999999999, 2.8900000000000001, 2.8999999999999999, 2.9100000000000001, 2.9199999999999999, 2.9300000000000002, 2.9399999999999999, 2.9500000000000002, 2.96, 2.9700000000000002, 2.98, 2.9900000000000002, 3.0, 3.0099999999999998, 3.02, 3.0299999999999998, 3.04, 3.0499999999999998, 3.0600000000000001, 3.0699999999999998, 3.0800000000000001, 3.0899999999999999, 3.1000000000000001, 3.1099999999999999, 3.1200000000000001, 3.1299999999999999, 3.1400000000000001, 3.1499999999999999, 3.1600000000000001, 3.1699999999999999, 3.1800000000000002, 3.1899999999999999, 3.2000000000000002, 3.21, 3.2200000000000002, 3.23, 3.2400000000000002, 3.25, 3.2599999999999998, 3.27, 3.2799999999999998, 3.29, 3.2999999999999998, 3.3100000000000001, 3.3199999999999998, 3.3300000000000001, 3.3399999999999999, 3.3500000000000001, 3.3599999999999999, 3.3700000000000001, 3.3799999999999999, 3.3900000000000001, 3.3999999999999999, 3.4100000000000001, 3.4199999999999999, 3.4300000000000002, 3.4399999999999999, 3.4500000000000002, 3.46, 3.4700000000000002, 3.48, 3.4900000000000002, 3.5, 3.5099999999999998, 3.52, 3.5299999999999998, 3.54, 3.5499999999999998, 3.5600000000000001, 3.5699999999999998, 3.5800000000000001, 3.5899999999999999, 3.6000000000000001, 3.6099999999999999, 3.6200000000000001, 3.6299999999999999, 3.6400000000000001, 3.6499999999999999, 3.6600000000000001, 3.6699999999999999, 3.6800000000000002, 3.6899999999999999, 3.7000000000000002, 3.71, 3.7200000000000002, 3.73, 3.7400000000000002, 3.75, 3.7599999999999998, 3.77, 3.7799999999999998, 3.79, 3.7999999999999998, 3.8100000000000001, 3.8199999999999998, 3.8300000000000001, 3.8399999999999999, 3.8500000000000001, 3.8599999999999999, 3.8700000000000001, 3.8799999999999999, 3.8900000000000001, 3.8999999999999999, 3.9100000000000001, 3.9199999999999999, 3.9300000000000002, 3.9399999999999999, 3.9500000000000002, 3.96, 3.9700000000000002, 3.98, 3.9900000000000002, 4.0, 4.0099999999999998, 4.0199999999999996, 4.0300000000000002, 4.04, 4.0499999999999998, 4.0599999999999996, 4.0700000000000003, 4.0800000000000001, 4.0899999999999999, 4.0999999999999996, 4.1100000000000003, 4.1200000000000001, 4.1299999999999999, 4.1399999999999997, 4.1500000000000004, 4.1600000000000001, 4.1699999999999999, 4.1799999999999997, 4.1900000000000004, 4.2000000000000002, 4.21, 4.2199999999999998, 4.2300000000000004, 4.2400000000000002]
4:31:30[QML:Reduced 14; QMD 8] Computing expectation values. 
Measurement Type: hahn_evolution 
LearnedHamiltonian [[  1.08935028+0.j           0.00000000+0.j           1.65982442-4.25512192j
    0.57278239-1.7012939j ]
 [  0.00000000+0.j           0.15946308+0.j          10.94318793+1.7012939j
    1.65982442-4.25512192j]
 [  1.65982442+4.25512192j  10.94318793-1.7012939j   -1.08935028+0.j
    0.00000000+0.j        ]
 [  0.57278239+1.7012939j    1.65982442+4.25512192j   0.00000000+0.j
   -0.15946308+0.j        ]] 
Probe: [ 0.49971827 -4.83795104e-04j  0.50013082 +2.23249446e-04j
  0.50031730 -2.46059755e-05j  0.49983262 -6.92224955e-04j] 
Times: [0.0, 0.01, 0.02, 0.029999999999999999, 0.040000000000000001, 0.050000000000000003, 0.059999999999999998, 0.070000000000000007, 0.080000000000000002, 0.089999999999999997, 0.10000000000000001, 0.11, 0.12, 0.13, 0.14000000000000001, 0.14999999999999999, 0.16, 0.17000000000000001, 0.17999999999999999, 0.19, 0.20000000000000001, 0.20999999999999999, 0.22, 0.23000000000000001, 0.23999999999999999, 0.25, 0.26000000000000001, 0.27000000000000002, 0.28000000000000003, 0.28999999999999998, 0.29999999999999999, 0.31, 0.32000000000000001, 0.33000000000000002, 0.34000000000000002, 0.34999999999999998, 0.35999999999999999, 0.37, 0.38, 0.39000000000000001, 0.40000000000000002, 0.40999999999999998, 0.41999999999999998, 0.42999999999999999, 0.44, 0.45000000000000001, 0.46000000000000002, 0.46999999999999997, 0.47999999999999998, 0.48999999999999999, 0.5, 0.51000000000000001, 0.52000000000000002, 0.53000000000000003, 0.54000000000000004, 0.55000000000000004, 0.56000000000000005, 0.56999999999999995, 0.57999999999999996, 0.58999999999999997, 0.59999999999999998, 0.60999999999999999, 0.62, 0.63, 0.64000000000000001, 0.65000000000000002, 0.66000000000000003, 0.67000000000000004, 0.68000000000000005, 0.68999999999999995, 0.69999999999999996, 0.70999999999999996, 0.71999999999999997, 0.72999999999999998, 0.73999999999999999, 0.75, 0.76000000000000001, 0.77000000000000002, 0.78000000000000003, 0.79000000000000004, 0.80000000000000004, 0.81000000000000005, 0.81999999999999995, 0.82999999999999996, 0.83999999999999997, 0.84999999999999998, 0.85999999999999999, 0.87, 0.88, 0.89000000000000001, 0.90000000000000002, 0.91000000000000003, 0.92000000000000004, 0.93000000000000005, 0.93999999999999995, 0.94999999999999996, 0.95999999999999996, 0.96999999999999997, 0.97999999999999998, 0.98999999999999999, 1.0, 1.01, 1.02, 1.03, 1.04, 1.05, 1.0600000000000001, 1.0700000000000001, 1.0800000000000001, 1.0900000000000001, 1.1000000000000001, 1.1100000000000001, 1.1200000000000001, 1.1299999999999999, 1.1399999999999999, 1.1499999999999999, 1.1599999999999999, 1.1699999999999999, 1.1799999999999999, 1.1899999999999999, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3, 1.3100000000000001, 1.3200000000000001, 1.3300000000000001, 1.3400000000000001, 1.3500000000000001, 1.3600000000000001, 1.3700000000000001, 1.3799999999999999, 1.3899999999999999, 1.3999999999999999, 1.4099999999999999, 1.4199999999999999, 1.4299999999999999, 1.4399999999999999, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5, 1.51, 1.52, 1.53, 1.54, 1.55, 1.5600000000000001, 1.5700000000000001, 1.5800000000000001, 1.5900000000000001, 1.6000000000000001, 1.6100000000000001, 1.6200000000000001, 1.6299999999999999, 1.6399999999999999, 1.6499999999999999, 1.6599999999999999, 1.6699999999999999, 1.6799999999999999, 1.6899999999999999, 1.7, 1.71, 1.72, 1.73, 1.74, 1.75, 1.76, 1.77, 1.78, 1.79, 1.8, 1.8100000000000001, 1.8200000000000001, 1.8300000000000001, 1.8400000000000001, 1.8500000000000001, 1.8600000000000001, 1.8700000000000001, 1.8799999999999999, 1.8899999999999999, 1.8999999999999999, 1.9099999999999999, 1.9199999999999999, 1.9299999999999999, 1.9399999999999999, 1.95, 1.96, 1.97, 1.98, 1.99, 2.0, 2.0099999999999998, 2.02, 2.0299999999999998, 2.04, 2.0499999999999998, 2.0600000000000001, 2.0699999999999998, 2.0800000000000001, 2.0899999999999999, 2.1000000000000001, 2.1099999999999999, 2.1200000000000001, 2.1299999999999999, 2.1400000000000001, 2.1499999999999999, 2.1600000000000001, 2.1699999999999999, 2.1800000000000002, 2.1899999999999999, 2.2000000000000002, 2.21, 2.2200000000000002, 2.23, 2.2400000000000002, 2.25, 2.2599999999999998, 2.27, 2.2799999999999998, 2.29, 2.2999999999999998, 2.3100000000000001, 2.3199999999999998, 2.3300000000000001, 2.3399999999999999, 2.3500000000000001, 2.3599999999999999, 2.3700000000000001, 2.3799999999999999, 2.3900000000000001, 2.3999999999999999, 2.4100000000000001, 2.4199999999999999, 2.4300000000000002, 2.4399999999999999, 2.4500000000000002, 2.46, 2.4700000000000002, 2.48, 2.4900000000000002, 2.5, 2.5099999999999998, 2.52, 2.5299999999999998, 2.54, 2.5499999999999998, 2.5600000000000001, 2.5699999999999998, 2.5800000000000001, 2.5899999999999999, 2.6000000000000001, 2.6099999999999999, 2.6200000000000001, 2.6299999999999999, 2.6400000000000001, 2.6499999999999999, 2.6600000000000001, 2.6699999999999999, 2.6800000000000002, 2.6899999999999999, 2.7000000000000002, 2.71, 2.7200000000000002, 2.73, 2.7400000000000002, 2.75, 2.7599999999999998, 2.77, 2.7799999999999998, 2.79, 2.7999999999999998, 2.8100000000000001, 2.8199999999999998, 2.8300000000000001, 2.8399999999999999, 2.8500000000000001, 2.8599999999999999, 2.8700000000000001, 2.8799999999999999, 2.8900000000000001, 2.8999999999999999, 2.9100000000000001, 2.9199999999999999, 2.9300000000000002, 2.9399999999999999, 2.9500000000000002, 2.96, 2.9700000000000002, 2.98, 2.9900000000000002, 3.0, 3.0099999999999998, 3.02, 3.0299999999999998, 3.04, 3.0499999999999998, 3.0600000000000001, 3.0699999999999998, 3.0800000000000001, 3.0899999999999999, 3.1000000000000001, 3.1099999999999999, 3.1200000000000001, 3.1299999999999999, 3.1400000000000001, 3.1499999999999999, 3.1600000000000001, 3.1699999999999999, 3.1800000000000002, 3.1899999999999999, 3.2000000000000002, 3.21, 3.2200000000000002, 3.23, 3.2400000000000002, 3.25, 3.2599999999999998, 3.27, 3.2799999999999998, 3.29, 3.2999999999999998, 3.3100000000000001, 3.3199999999999998, 3.3300000000000001, 3.3399999999999999, 3.3500000000000001, 3.3599999999999999, 3.3700000000000001, 3.3799999999999999, 3.3900000000000001, 3.3999999999999999, 3.4100000000000001, 3.4199999999999999, 3.4300000000000002, 3.4399999999999999, 3.4500000000000002, 3.46, 3.4700000000000002, 3.48, 3.4900000000000002, 3.5, 3.5099999999999998, 3.52, 3.5299999999999998, 3.54, 3.5499999999999998, 3.5600000000000001, 3.5699999999999998, 3.5800000000000001, 3.5899999999999999, 3.6000000000000001, 3.6099999999999999, 3.6200000000000001, 3.6299999999999999, 3.6400000000000001, 3.6499999999999999, 3.6600000000000001, 3.6699999999999999, 3.6800000000000002, 3.6899999999999999, 3.7000000000000002, 3.71, 3.7200000000000002, 3.73, 3.7400000000000002, 3.75, 3.7599999999999998, 3.77, 3.7799999999999998, 3.79, 3.7999999999999998, 3.8100000000000001, 3.8199999999999998, 3.8300000000000001, 3.8399999999999999, 3.8500000000000001, 3.8599999999999999, 3.8700000000000001, 3.8799999999999999, 3.8900000000000001, 3.8999999999999999, 3.9100000000000001, 3.9199999999999999, 3.9300000000000002, 3.9399999999999999, 3.9500000000000002, 3.96, 3.9700000000000002, 3.98, 3.9900000000000002, 4.0, 4.0099999999999998, 4.0199999999999996, 4.0300000000000002, 4.04, 4.0499999999999998, 4.0599999999999996, 4.0700000000000003, 4.0800000000000001, 4.0899999999999999, 4.0999999999999996, 4.1100000000000003, 4.1200000000000001, 4.1299999999999999, 4.1399999999999997, 4.1500000000000004, 4.1600000000000001, 4.1699999999999999, 4.1799999999999997, 4.1900000000000004, 4.2000000000000002, 4.21, 4.2199999999999998, 4.2300000000000004, 4.2400000000000002]
4:31:30[QML:Reduced 14; QMD 8] [compute expectation values] times to compute: [0.0, 0.01, 0.02, 0.029999999999999999, 0.040000000000000001, 0.050000000000000003, 0.059999999999999998, 0.070000000000000007, 0.080000000000000002, 0.089999999999999997, 0.10000000000000001, 0.11, 0.12, 0.13, 0.14000000000000001, 0.14999999999999999, 0.16, 0.17000000000000001, 0.17999999999999999, 0.19, 0.20000000000000001, 0.20999999999999999, 0.22, 0.23000000000000001, 0.23999999999999999, 0.25, 0.26000000000000001, 0.27000000000000002, 0.28000000000000003, 0.28999999999999998, 0.29999999999999999, 0.31, 0.32000000000000001, 0.33000000000000002, 0.34000000000000002, 0.34999999999999998, 0.35999999999999999, 0.37, 0.38, 0.39000000000000001, 0.40000000000000002, 0.40999999999999998, 0.41999999999999998, 0.42999999999999999, 0.44, 0.45000000000000001, 0.46000000000000002, 0.46999999999999997, 0.47999999999999998, 0.48999999999999999, 0.5, 0.51000000000000001, 0.52000000000000002, 0.53000000000000003, 0.54000000000000004, 0.55000000000000004, 0.56000000000000005, 0.56999999999999995, 0.57999999999999996, 0.58999999999999997, 0.59999999999999998, 0.60999999999999999, 0.62, 0.63, 0.64000000000000001, 0.65000000000000002, 0.66000000000000003, 0.67000000000000004, 0.68000000000000005, 0.68999999999999995, 0.69999999999999996, 0.70999999999999996, 0.71999999999999997, 0.72999999999999998, 0.73999999999999999, 0.75, 0.76000000000000001, 0.77000000000000002, 0.78000000000000003, 0.79000000000000004, 0.80000000000000004, 0.81000000000000005, 0.81999999999999995, 0.82999999999999996, 0.83999999999999997, 0.84999999999999998, 0.85999999999999999, 0.87, 0.88, 0.89000000000000001, 0.90000000000000002, 0.91000000000000003, 0.92000000000000004, 0.93000000000000005, 0.93999999999999995, 0.94999999999999996, 0.95999999999999996, 0.96999999999999997, 0.97999999999999998, 0.98999999999999999, 1.0, 1.01, 1.02, 1.03, 1.04, 1.05, 1.0600000000000001, 1.0700000000000001, 1.0800000000000001, 1.0900000000000001, 1.1000000000000001, 1.1100000000000001, 1.1200000000000001, 1.1299999999999999, 1.1399999999999999, 1.1499999999999999, 1.1599999999999999, 1.1699999999999999, 1.1799999999999999, 1.1899999999999999, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3, 1.3100000000000001, 1.3200000000000001, 1.3300000000000001, 1.3400000000000001, 1.3500000000000001, 1.3600000000000001, 1.3700000000000001, 1.3799999999999999, 1.3899999999999999, 1.3999999999999999, 1.4099999999999999, 1.4199999999999999, 1.4299999999999999, 1.4399999999999999, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5, 1.51, 1.52, 1.53, 1.54, 1.55, 1.5600000000000001, 1.5700000000000001, 1.5800000000000001, 1.5900000000000001, 1.6000000000000001, 1.6100000000000001, 1.6200000000000001, 1.6299999999999999, 1.6399999999999999, 1.6499999999999999, 1.6599999999999999, 1.6699999999999999, 1.6799999999999999, 1.6899999999999999, 1.7, 1.71, 1.72, 1.73, 1.74, 1.75, 1.76, 1.77, 1.78, 1.79, 1.8, 1.8100000000000001, 1.8200000000000001, 1.8300000000000001, 1.8400000000000001, 1.8500000000000001, 1.8600000000000001, 1.8700000000000001, 1.8799999999999999, 1.8899999999999999, 1.8999999999999999, 1.9099999999999999, 1.9199999999999999, 1.9299999999999999, 1.9399999999999999, 1.95, 1.96, 1.97, 1.98, 1.99, 2.0, 2.0099999999999998, 2.02, 2.0299999999999998, 2.04, 2.0499999999999998, 2.0600000000000001, 2.0699999999999998, 2.0800000000000001, 2.0899999999999999, 2.1000000000000001, 2.1099999999999999, 2.1200000000000001, 2.1299999999999999, 2.1400000000000001, 2.1499999999999999, 2.1600000000000001, 2.1699999999999999, 2.1800000000000002, 2.1899999999999999, 2.2000000000000002, 2.21, 2.2200000000000002, 2.23, 2.2400000000000002, 2.25, 2.2599999999999998, 2.27, 2.2799999999999998, 2.29, 2.2999999999999998, 2.3100000000000001, 2.3199999999999998, 2.3300000000000001, 2.3399999999999999, 2.3500000000000001, 2.3599999999999999, 2.3700000000000001, 2.3799999999999999, 2.3900000000000001, 2.3999999999999999, 2.4100000000000001, 2.4199999999999999, 2.4300000000000002, 2.4399999999999999, 2.4500000000000002, 2.46, 2.4700000000000002, 2.48, 2.4900000000000002, 2.5, 2.5099999999999998, 2.52, 2.5299999999999998, 2.54, 2.5499999999999998, 2.5600000000000001, 2.5699999999999998, 2.5800000000000001, 2.5899999999999999, 2.6000000000000001, 2.6099999999999999, 2.6200000000000001, 2.6299999999999999, 2.6400000000000001, 2.6499999999999999, 2.6600000000000001, 2.6699999999999999, 2.6800000000000002, 2.6899999999999999, 2.7000000000000002, 2.71, 2.7200000000000002, 2.73, 2.7400000000000002, 2.75, 2.7599999999999998, 2.77, 2.7799999999999998, 2.79, 2.7999999999999998, 2.8100000000000001, 2.8199999999999998, 2.8300000000000001, 2.8399999999999999, 2.8500000000000001, 2.8599999999999999, 2.8700000000000001, 2.8799999999999999, 2.8900000000000001, 2.8999999999999999, 2.9100000000000001, 2.9199999999999999, 2.9300000000000002, 2.9399999999999999, 2.9500000000000002, 2.96, 2.9700000000000002, 2.98, 2.9900000000000002, 3.0, 3.0099999999999998, 3.02, 3.0299999999999998, 3.04, 3.0499999999999998, 3.0600000000000001, 3.0699999999999998, 3.0800000000000001, 3.0899999999999999, 3.1000000000000001, 3.1099999999999999, 3.1200000000000001, 3.1299999999999999, 3.1400000000000001, 3.1499999999999999, 3.1600000000000001, 3.1699999999999999, 3.1800000000000002, 3.1899999999999999, 3.2000000000000002, 3.21, 3.2200000000000002, 3.23, 3.2400000000000002, 3.25, 3.2599999999999998, 3.27, 3.2799999999999998, 3.29, 3.2999999999999998, 3.3100000000000001, 3.3199999999999998, 3.3300000000000001, 3.3399999999999999, 3.3500000000000001, 3.3599999999999999, 3.3700000000000001, 3.3799999999999999, 3.3900000000000001, 3.3999999999999999, 3.4100000000000001, 3.4199999999999999, 3.4300000000000002, 3.4399999999999999, 3.4500000000000002, 3.46, 3.4700000000000002, 3.48, 3.4900000000000002, 3.5, 3.5099999999999998, 3.52, 3.5299999999999998, 3.54, 3.5499999999999998, 3.5600000000000001, 3.5699999999999998, 3.5800000000000001, 3.5899999999999999, 3.6000000000000001, 3.6099999999999999, 3.6200000000000001, 3.6299999999999999, 3.6400000000000001, 3.6499999999999999, 3.6600000000000001, 3.6699999999999999, 3.6800000000000002, 3.6899999999999999, 3.7000000000000002, 3.71, 3.7200000000000002, 3.73, 3.7400000000000002, 3.75, 3.7599999999999998, 3.77, 3.7799999999999998, 3.79, 3.7999999999999998, 3.8100000000000001, 3.8199999999999998, 3.8300000000000001, 3.8399999999999999, 3.8500000000000001, 3.8599999999999999, 3.8700000000000001, 3.8799999999999999, 3.8900000000000001, 3.8999999999999999, 3.9100000000000001, 3.9199999999999999, 3.9300000000000002, 3.9399999999999999, 3.9500000000000002, 3.96, 3.9700000000000002, 3.98, 3.9900000000000002, 4.0, 4.0099999999999998, 4.0199999999999996, 4.0300000000000002, 4.04, 4.0499999999999998, 4.0599999999999996, 4.0700000000000003, 4.0800000000000001, 4.0899999999999999, 4.0999999999999996, 4.1100000000000003, 4.1200000000000001, 4.1299999999999999, 4.1399999999999997, 4.1500000000000004, 4.1600000000000001, 4.1699999999999999, 4.1799999999999997, 4.1900000000000004, 4.2000000000000002, 4.21, 4.2199999999999998, 4.2300000000000004, 4.2400000000000002]
4:31:30[QML:Reduced 16; QMD 8] Computing expectation values. 
Measurement Type: hahn_evolution 
LearnedHamiltonian [[ 4.70327118+0.j          0.00000000+0.j          1.32641870-6.877443j
   4.00344855-1.92122895j]
 [ 0.00000000+0.j         -0.20886352+0.j          7.21115172+1.92122895j
   1.32641870-0.71777879j]
 [ 1.32641870+6.877443j    7.21115172-1.92122895j -4.70327118+0.j
   0.00000000+0.j        ]
 [ 4.00344855+1.92122895j  1.32641870+0.71777879j  0.00000000+0.j
   0.20886352+0.j        ]] 
Probe: [ 0.49971827 -4.83795104e-04j  0.50013082 +2.23249446e-04j
  0.50031730 -2.46059755e-05j  0.49983262 -6.92224955e-04j] 
Times: [0.0, 0.01, 0.02, 0.029999999999999999, 0.040000000000000001, 0.050000000000000003, 0.059999999999999998, 0.070000000000000007, 0.080000000000000002, 0.089999999999999997, 0.10000000000000001, 0.11, 0.12, 0.13, 0.14000000000000001, 0.14999999999999999, 0.16, 0.17000000000000001, 0.17999999999999999, 0.19, 0.20000000000000001, 0.20999999999999999, 0.22, 0.23000000000000001, 0.23999999999999999, 0.25, 0.26000000000000001, 0.27000000000000002, 0.28000000000000003, 0.28999999999999998, 0.29999999999999999, 0.31, 0.32000000000000001, 0.33000000000000002, 0.34000000000000002, 0.34999999999999998, 0.35999999999999999, 0.37, 0.38, 0.39000000000000001, 0.40000000000000002, 0.40999999999999998, 0.41999999999999998, 0.42999999999999999, 0.44, 0.45000000000000001, 0.46000000000000002, 0.46999999999999997, 0.47999999999999998, 0.48999999999999999, 0.5, 0.51000000000000001, 0.52000000000000002, 0.53000000000000003, 0.54000000000000004, 0.55000000000000004, 0.56000000000000005, 0.56999999999999995, 0.57999999999999996, 0.58999999999999997, 0.59999999999999998, 0.60999999999999999, 0.62, 0.63, 0.64000000000000001, 0.65000000000000002, 0.66000000000000003, 0.67000000000000004, 0.68000000000000005, 0.68999999999999995, 0.69999999999999996, 0.70999999999999996, 0.71999999999999997, 0.72999999999999998, 0.73999999999999999, 0.75, 0.76000000000000001, 0.77000000000000002, 0.78000000000000003, 0.79000000000000004, 0.80000000000000004, 0.81000000000000005, 0.81999999999999995, 0.82999999999999996, 0.83999999999999997, 0.84999999999999998, 0.85999999999999999, 0.87, 0.88, 0.89000000000000001, 0.90000000000000002, 0.91000000000000003, 0.92000000000000004, 0.93000000000000005, 0.93999999999999995, 0.94999999999999996, 0.95999999999999996, 0.96999999999999997, 0.97999999999999998, 0.98999999999999999, 1.0, 1.01, 1.02, 1.03, 1.04, 1.05, 1.0600000000000001, 1.0700000000000001, 1.0800000000000001, 1.0900000000000001, 1.1000000000000001, 1.1100000000000001, 1.1200000000000001, 1.1299999999999999, 1.1399999999999999, 1.1499999999999999, 1.1599999999999999, 1.1699999999999999, 1.1799999999999999, 1.1899999999999999, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3, 1.3100000000000001, 1.3200000000000001, 1.3300000000000001, 1.3400000000000001, 1.3500000000000001, 1.3600000000000001, 1.3700000000000001, 1.3799999999999999, 1.3899999999999999, 1.3999999999999999, 1.4099999999999999, 1.4199999999999999, 1.4299999999999999, 1.4399999999999999, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5, 1.51, 1.52, 1.53, 1.54, 1.55, 1.5600000000000001, 1.5700000000000001, 1.5800000000000001, 1.5900000000000001, 1.6000000000000001, 1.6100000000000001, 1.6200000000000001, 1.6299999999999999, 1.6399999999999999, 1.6499999999999999, 1.6599999999999999, 1.6699999999999999, 1.6799999999999999, 1.6899999999999999, 1.7, 1.71, 1.72, 1.73, 1.74, 1.75, 1.76, 1.77, 1.78, 1.79, 1.8, 1.8100000000000001, 1.8200000000000001, 1.8300000000000001, 1.8400000000000001, 1.8500000000000001, 1.8600000000000001, 1.8700000000000001, 1.8799999999999999, 1.8899999999999999, 1.8999999999999999, 1.9099999999999999, 1.9199999999999999, 1.9299999999999999, 1.9399999999999999, 1.95, 1.96, 1.97, 1.98, 1.99, 2.0, 2.0099999999999998, 2.02, 2.0299999999999998, 2.04, 2.0499999999999998, 2.0600000000000001, 2.0699999999999998, 2.0800000000000001, 2.0899999999999999, 2.1000000000000001, 2.1099999999999999, 2.1200000000000001, 2.1299999999999999, 2.1400000000000001, 2.1499999999999999, 2.1600000000000001, 2.1699999999999999, 2.1800000000000002, 2.1899999999999999, 2.2000000000000002, 2.21, 2.2200000000000002, 2.23, 2.2400000000000002, 2.25, 2.2599999999999998, 2.27, 2.2799999999999998, 2.29, 2.2999999999999998, 2.3100000000000001, 2.3199999999999998, 2.3300000000000001, 2.3399999999999999, 2.3500000000000001, 2.3599999999999999, 2.3700000000000001, 2.3799999999999999, 2.3900000000000001, 2.3999999999999999, 2.4100000000000001, 2.4199999999999999, 2.4300000000000002, 2.4399999999999999, 2.4500000000000002, 2.46, 2.4700000000000002, 2.48, 2.4900000000000002, 2.5, 2.5099999999999998, 2.52, 2.5299999999999998, 2.54, 2.5499999999999998, 2.5600000000000001, 2.5699999999999998, 2.5800000000000001, 2.5899999999999999, 2.6000000000000001, 2.6099999999999999, 2.6200000000000001, 2.6299999999999999, 2.6400000000000001, 2.6499999999999999, 2.6600000000000001, 2.6699999999999999, 2.6800000000000002, 2.6899999999999999, 2.7000000000000002, 2.71, 2.7200000000000002, 2.73, 2.7400000000000002, 2.75, 2.7599999999999998, 2.77, 2.7799999999999998, 2.79, 2.7999999999999998, 2.8100000000000001, 2.8199999999999998, 2.8300000000000001, 2.8399999999999999, 2.8500000000000001, 2.8599999999999999, 2.8700000000000001, 2.8799999999999999, 2.8900000000000001, 2.8999999999999999, 2.9100000000000001, 2.9199999999999999, 2.9300000000000002, 2.9399999999999999, 2.9500000000000002, 2.96, 2.9700000000000002, 2.98, 2.9900000000000002, 3.0, 3.0099999999999998, 3.02, 3.0299999999999998, 3.04, 3.0499999999999998, 3.0600000000000001, 3.0699999999999998, 3.0800000000000001, 3.0899999999999999, 3.1000000000000001, 3.1099999999999999, 3.1200000000000001, 3.1299999999999999, 3.1400000000000001, 3.1499999999999999, 3.1600000000000001, 3.1699999999999999, 3.1800000000000002, 3.1899999999999999, 3.2000000000000002, 3.21, 3.2200000000000002, 3.23, 3.2400000000000002, 3.25, 3.2599999999999998, 3.27, 3.2799999999999998, 3.29, 3.2999999999999998, 3.3100000000000001, 3.3199999999999998, 3.3300000000000001, 3.3399999999999999, 3.3500000000000001, 3.3599999999999999, 3.3700000000000001, 3.3799999999999999, 3.3900000000000001, 3.3999999999999999, 3.4100000000000001, 3.4199999999999999, 3.4300000000000002, 3.4399999999999999, 3.4500000000000002, 3.46, 3.4700000000000002, 3.48, 3.4900000000000002, 3.5, 3.5099999999999998, 3.52, 3.5299999999999998, 3.54, 3.5499999999999998, 3.5600000000000001, 3.5699999999999998, 3.5800000000000001, 3.5899999999999999, 3.6000000000000001, 3.6099999999999999, 3.6200000000000001, 3.6299999999999999, 3.6400000000000001, 3.6499999999999999, 3.6600000000000001, 3.6699999999999999, 3.6800000000000002, 3.6899999999999999, 3.7000000000000002, 3.71, 3.7200000000000002, 3.73, 3.7400000000000002, 3.75, 3.7599999999999998, 3.77, 3.7799999999999998, 3.79, 3.7999999999999998, 3.8100000000000001, 3.8199999999999998, 3.8300000000000001, 3.8399999999999999, 3.8500000000000001, 3.8599999999999999, 3.8700000000000001, 3.8799999999999999, 3.8900000000000001, 3.8999999999999999, 3.9100000000000001, 3.9199999999999999, 3.9300000000000002, 3.9399999999999999, 3.9500000000000002, 3.96, 3.9700000000000002, 3.98, 3.9900000000000002, 4.0, 4.0099999999999998, 4.0199999999999996, 4.0300000000000002, 4.04, 4.0499999999999998, 4.0599999999999996, 4.0700000000000003, 4.0800000000000001, 4.0899999999999999, 4.0999999999999996, 4.1100000000000003, 4.1200000000000001, 4.1299999999999999, 4.1399999999999997, 4.1500000000000004, 4.1600000000000001, 4.1699999999999999, 4.1799999999999997, 4.1900000000000004, 4.2000000000000002, 4.21, 4.2199999999999998, 4.2300000000000004, 4.2400000000000002]
4:31:30[QML:Reduced 16; QMD 8] [compute expectation values] times to compute: [0.0, 0.01, 0.02, 0.029999999999999999, 0.040000000000000001, 0.050000000000000003, 0.059999999999999998, 0.070000000000000007, 0.080000000000000002, 0.089999999999999997, 0.10000000000000001, 0.11, 0.12, 0.13, 0.14000000000000001, 0.14999999999999999, 0.16, 0.17000000000000001, 0.17999999999999999, 0.19, 0.20000000000000001, 0.20999999999999999, 0.22, 0.23000000000000001, 0.23999999999999999, 0.25, 0.26000000000000001, 0.27000000000000002, 0.28000000000000003, 0.28999999999999998, 0.29999999999999999, 0.31, 0.32000000000000001, 0.33000000000000002, 0.34000000000000002, 0.34999999999999998, 0.35999999999999999, 0.37, 0.38, 0.39000000000000001, 0.40000000000000002, 0.40999999999999998, 0.41999999999999998, 0.42999999999999999, 0.44, 0.45000000000000001, 0.46000000000000002, 0.46999999999999997, 0.47999999999999998, 0.48999999999999999, 0.5, 0.51000000000000001, 0.52000000000000002, 0.53000000000000003, 0.54000000000000004, 0.55000000000000004, 0.56000000000000005, 0.56999999999999995, 0.57999999999999996, 0.58999999999999997, 0.59999999999999998, 0.60999999999999999, 0.62, 0.63, 0.64000000000000001, 0.65000000000000002, 0.66000000000000003, 0.67000000000000004, 0.68000000000000005, 0.68999999999999995, 0.69999999999999996, 0.70999999999999996, 0.71999999999999997, 0.72999999999999998, 0.73999999999999999, 0.75, 0.76000000000000001, 0.77000000000000002, 0.78000000000000003, 0.79000000000000004, 0.80000000000000004, 0.81000000000000005, 0.81999999999999995, 0.82999999999999996, 0.83999999999999997, 0.84999999999999998, 0.85999999999999999, 0.87, 0.88, 0.89000000000000001, 0.90000000000000002, 0.91000000000000003, 0.92000000000000004, 0.93000000000000005, 0.93999999999999995, 0.94999999999999996, 0.95999999999999996, 0.96999999999999997, 0.97999999999999998, 0.98999999999999999, 1.0, 1.01, 1.02, 1.03, 1.04, 1.05, 1.0600000000000001, 1.0700000000000001, 1.0800000000000001, 1.0900000000000001, 1.1000000000000001, 1.1100000000000001, 1.1200000000000001, 1.1299999999999999, 1.1399999999999999, 1.1499999999999999, 1.1599999999999999, 1.1699999999999999, 1.1799999999999999, 1.1899999999999999, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3, 1.3100000000000001, 1.3200000000000001, 1.3300000000000001, 1.3400000000000001, 1.3500000000000001, 1.3600000000000001, 1.3700000000000001, 1.3799999999999999, 1.3899999999999999, 1.3999999999999999, 1.4099999999999999, 1.4199999999999999, 1.4299999999999999, 1.4399999999999999, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5, 1.51, 1.52, 1.53, 1.54, 1.55, 1.5600000000000001, 1.5700000000000001, 1.5800000000000001, 1.5900000000000001, 1.6000000000000001, 1.6100000000000001, 1.6200000000000001, 1.6299999999999999, 1.6399999999999999, 1.6499999999999999, 1.6599999999999999, 1.6699999999999999, 1.6799999999999999, 1.6899999999999999, 1.7, 1.71, 1.72, 1.73, 1.74, 1.75, 1.76, 1.77, 1.78, 1.79, 1.8, 1.8100000000000001, 1.8200000000000001, 1.8300000000000001, 1.8400000000000001, 1.8500000000000001, 1.8600000000000001, 1.8700000000000001, 1.8799999999999999, 1.8899999999999999, 1.8999999999999999, 1.9099999999999999, 1.9199999999999999, 1.9299999999999999, 1.9399999999999999, 1.95, 1.96, 1.97, 1.98, 1.99, 2.0, 2.0099999999999998, 2.02, 2.0299999999999998, 2.04, 2.0499999999999998, 2.0600000000000001, 2.0699999999999998, 2.0800000000000001, 2.0899999999999999, 2.1000000000000001, 2.1099999999999999, 2.1200000000000001, 2.1299999999999999, 2.1400000000000001, 2.1499999999999999, 2.1600000000000001, 2.1699999999999999, 2.1800000000000002, 2.1899999999999999, 2.2000000000000002, 2.21, 2.2200000000000002, 2.23, 2.2400000000000002, 2.25, 2.2599999999999998, 2.27, 2.2799999999999998, 2.29, 2.2999999999999998, 2.3100000000000001, 2.3199999999999998, 2.3300000000000001, 2.3399999999999999, 2.3500000000000001, 2.3599999999999999, 2.3700000000000001, 2.3799999999999999, 2.3900000000000001, 2.3999999999999999, 2.4100000000000001, 2.4199999999999999, 2.4300000000000002, 2.4399999999999999, 2.4500000000000002, 2.46, 2.4700000000000002, 2.48, 2.4900000000000002, 2.5, 2.5099999999999998, 2.52, 2.5299999999999998, 2.54, 2.5499999999999998, 2.5600000000000001, 2.5699999999999998, 2.5800000000000001, 2.5899999999999999, 2.6000000000000001, 2.6099999999999999, 2.6200000000000001, 2.6299999999999999, 2.6400000000000001, 2.6499999999999999, 2.6600000000000001, 2.6699999999999999, 2.6800000000000002, 2.6899999999999999, 2.7000000000000002, 2.71, 2.7200000000000002, 2.73, 2.7400000000000002, 2.75, 2.7599999999999998, 2.77, 2.7799999999999998, 2.79, 2.7999999999999998, 2.8100000000000001, 2.8199999999999998, 2.8300000000000001, 2.8399999999999999, 2.8500000000000001, 2.8599999999999999, 2.8700000000000001, 2.8799999999999999, 2.8900000000000001, 2.8999999999999999, 2.9100000000000001, 2.9199999999999999, 2.9300000000000002, 2.9399999999999999, 2.9500000000000002, 2.96, 2.9700000000000002, 2.98, 2.9900000000000002, 3.0, 3.0099999999999998, 3.02, 3.0299999999999998, 3.04, 3.0499999999999998, 3.0600000000000001, 3.0699999999999998, 3.0800000000000001, 3.0899999999999999, 3.1000000000000001, 3.1099999999999999, 3.1200000000000001, 3.1299999999999999, 3.1400000000000001, 3.1499999999999999, 3.1600000000000001, 3.1699999999999999, 3.1800000000000002, 3.1899999999999999, 3.2000000000000002, 3.21, 3.2200000000000002, 3.23, 3.2400000000000002, 3.25, 3.2599999999999998, 3.27, 3.2799999999999998, 3.29, 3.2999999999999998, 3.3100000000000001, 3.3199999999999998, 3.3300000000000001, 3.3399999999999999, 3.3500000000000001, 3.3599999999999999, 3.3700000000000001, 3.3799999999999999, 3.3900000000000001, 3.3999999999999999, 3.4100000000000001, 3.4199999999999999, 3.4300000000000002, 3.4399999999999999, 3.4500000000000002, 3.46, 3.4700000000000002, 3.48, 3.4900000000000002, 3.5, 3.5099999999999998, 3.52, 3.5299999999999998, 3.54, 3.5499999999999998, 3.5600000000000001, 3.5699999999999998, 3.5800000000000001, 3.5899999999999999, 3.6000000000000001, 3.6099999999999999, 3.6200000000000001, 3.6299999999999999, 3.6400000000000001, 3.6499999999999999, 3.6600000000000001, 3.6699999999999999, 3.6800000000000002, 3.6899999999999999, 3.7000000000000002, 3.71, 3.7200000000000002, 3.73, 3.7400000000000002, 3.75, 3.7599999999999998, 3.77, 3.7799999999999998, 3.79, 3.7999999999999998, 3.8100000000000001, 3.8199999999999998, 3.8300000000000001, 3.8399999999999999, 3.8500000000000001, 3.8599999999999999, 3.8700000000000001, 3.8799999999999999, 3.8900000000000001, 3.8999999999999999, 3.9100000000000001, 3.9199999999999999, 3.9300000000000002, 3.9399999999999999, 3.9500000000000002, 3.96, 3.9700000000000002, 3.98, 3.9900000000000002, 4.0, 4.0099999999999998, 4.0199999999999996, 4.0300000000000002, 4.04, 4.0499999999999998, 4.0599999999999996, 4.0700000000000003, 4.0800000000000001, 4.0899999999999999, 4.0999999999999996, 4.1100000000000003, 4.1200000000000001, 4.1299999999999999, 4.1399999999999997, 4.1500000000000004, 4.1600000000000001, 4.1699999999999999, 4.1799999999999997, 4.1900000000000004, 4.2000000000000002, 4.21, 4.2199999999999998, 4.2300000000000004, 4.2400000000000002]
4:31:31[QML:Reduced 17; QMD 8] Computing expectation values. 
Measurement Type: hahn_evolution 
LearnedHamiltonian [[ 3.38290366+0.j          0.00000000+0.j          5.17554626-5.53131805j
  -2.60411479-1.85319033j]
 [ 0.00000000+0.j         -0.79327291+0.j          4.54890625+1.85319033j
  -0.57765293+5.09009054j]
 [ 5.17554626+5.53131805j  4.54890625-1.85319033j -3.38290366+0.j
   0.00000000+0.j        ]
 [-2.60411479+1.85319033j -0.57765293-5.09009054j  0.00000000+0.j
   0.79327291+0.j        ]] 
Probe: [ 0.49971827 -4.83795104e-04j  0.50013082 +2.23249446e-04j
  0.50031730 -2.46059755e-05j  0.49983262 -6.92224955e-04j] 
Times: [0.0, 0.01, 0.02, 0.029999999999999999, 0.040000000000000001, 0.050000000000000003, 0.059999999999999998, 0.070000000000000007, 0.080000000000000002, 0.089999999999999997, 0.10000000000000001, 0.11, 0.12, 0.13, 0.14000000000000001, 0.14999999999999999, 0.16, 0.17000000000000001, 0.17999999999999999, 0.19, 0.20000000000000001, 0.20999999999999999, 0.22, 0.23000000000000001, 0.23999999999999999, 0.25, 0.26000000000000001, 0.27000000000000002, 0.28000000000000003, 0.28999999999999998, 0.29999999999999999, 0.31, 0.32000000000000001, 0.33000000000000002, 0.34000000000000002, 0.34999999999999998, 0.35999999999999999, 0.37, 0.38, 0.39000000000000001, 0.40000000000000002, 0.40999999999999998, 0.41999999999999998, 0.42999999999999999, 0.44, 0.45000000000000001, 0.46000000000000002, 0.46999999999999997, 0.47999999999999998, 0.48999999999999999, 0.5, 0.51000000000000001, 0.52000000000000002, 0.53000000000000003, 0.54000000000000004, 0.55000000000000004, 0.56000000000000005, 0.56999999999999995, 0.57999999999999996, 0.58999999999999997, 0.59999999999999998, 0.60999999999999999, 0.62, 0.63, 0.64000000000000001, 0.65000000000000002, 0.66000000000000003, 0.67000000000000004, 0.68000000000000005, 0.68999999999999995, 0.69999999999999996, 0.70999999999999996, 0.71999999999999997, 0.72999999999999998, 0.73999999999999999, 0.75, 0.76000000000000001, 0.77000000000000002, 0.78000000000000003, 0.79000000000000004, 0.80000000000000004, 0.81000000000000005, 0.81999999999999995, 0.82999999999999996, 0.83999999999999997, 0.84999999999999998, 0.85999999999999999, 0.87, 0.88, 0.89000000000000001, 0.90000000000000002, 0.91000000000000003, 0.92000000000000004, 0.93000000000000005, 0.93999999999999995, 0.94999999999999996, 0.95999999999999996, 0.96999999999999997, 0.97999999999999998, 0.98999999999999999, 1.0, 1.01, 1.02, 1.03, 1.04, 1.05, 1.0600000000000001, 1.0700000000000001, 1.0800000000000001, 1.0900000000000001, 1.1000000000000001, 1.1100000000000001, 1.1200000000000001, 1.1299999999999999, 1.1399999999999999, 1.1499999999999999, 1.1599999999999999, 1.1699999999999999, 1.1799999999999999, 1.1899999999999999, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3, 1.3100000000000001, 1.3200000000000001, 1.3300000000000001, 1.3400000000000001, 1.3500000000000001, 1.3600000000000001, 1.3700000000000001, 1.3799999999999999, 1.3899999999999999, 1.3999999999999999, 1.4099999999999999, 1.4199999999999999, 1.4299999999999999, 1.4399999999999999, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5, 1.51, 1.52, 1.53, 1.54, 1.55, 1.5600000000000001, 1.5700000000000001, 1.5800000000000001, 1.5900000000000001, 1.6000000000000001, 1.6100000000000001, 1.6200000000000001, 1.6299999999999999, 1.6399999999999999, 1.6499999999999999, 1.6599999999999999, 1.6699999999999999, 1.6799999999999999, 1.6899999999999999, 1.7, 1.71, 1.72, 1.73, 1.74, 1.75, 1.76, 1.77, 1.78, 1.79, 1.8, 1.8100000000000001, 1.8200000000000001, 1.8300000000000001, 1.8400000000000001, 1.8500000000000001, 1.8600000000000001, 1.8700000000000001, 1.8799999999999999, 1.8899999999999999, 1.8999999999999999, 1.9099999999999999, 1.9199999999999999, 1.9299999999999999, 1.9399999999999999, 1.95, 1.96, 1.97, 1.98, 1.99, 2.0, 2.0099999999999998, 2.02, 2.0299999999999998, 2.04, 2.0499999999999998, 2.0600000000000001, 2.0699999999999998, 2.0800000000000001, 2.0899999999999999, 2.1000000000000001, 2.1099999999999999, 2.1200000000000001, 2.1299999999999999, 2.1400000000000001, 2.1499999999999999, 2.1600000000000001, 2.1699999999999999, 2.1800000000000002, 2.1899999999999999, 2.2000000000000002, 2.21, 2.2200000000000002, 2.23, 2.2400000000000002, 2.25, 2.2599999999999998, 2.27, 2.2799999999999998, 2.29, 2.2999999999999998, 2.3100000000000001, 2.3199999999999998, 2.3300000000000001, 2.3399999999999999, 2.3500000000000001, 2.3599999999999999, 2.3700000000000001, 2.3799999999999999, 2.3900000000000001, 2.3999999999999999, 2.4100000000000001, 2.4199999999999999, 2.4300000000000002, 2.4399999999999999, 2.4500000000000002, 2.46, 2.4700000000000002, 2.48, 2.4900000000000002, 2.5, 2.5099999999999998, 2.52, 2.5299999999999998, 2.54, 2.5499999999999998, 2.5600000000000001, 2.5699999999999998, 2.5800000000000001, 2.5899999999999999, 2.6000000000000001, 2.6099999999999999, 2.6200000000000001, 2.6299999999999999, 2.6400000000000001, 2.6499999999999999, 2.6600000000000001, 2.6699999999999999, 2.6800000000000002, 2.6899999999999999, 2.7000000000000002, 2.71, 2.7200000000000002, 2.73, 2.7400000000000002, 2.75, 2.7599999999999998, 2.77, 2.7799999999999998, 2.79, 2.7999999999999998, 2.8100000000000001, 2.8199999999999998, 2.8300000000000001, 2.8399999999999999, 2.8500000000000001, 2.8599999999999999, 2.8700000000000001, 2.8799999999999999, 2.8900000000000001, 2.8999999999999999, 2.9100000000000001, 2.9199999999999999, 2.9300000000000002, 2.9399999999999999, 2.9500000000000002, 2.96, 2.9700000000000002, 2.98, 2.9900000000000002, 3.0, 3.0099999999999998, 3.02, 3.0299999999999998, 3.04, 3.0499999999999998, 3.0600000000000001, 3.0699999999999998, 3.0800000000000001, 3.0899999999999999, 3.1000000000000001, 3.1099999999999999, 3.1200000000000001, 3.1299999999999999, 3.1400000000000001, 3.1499999999999999, 3.1600000000000001, 3.1699999999999999, 3.1800000000000002, 3.1899999999999999, 3.2000000000000002, 3.21, 3.2200000000000002, 3.23, 3.2400000000000002, 3.25, 3.2599999999999998, 3.27, 3.2799999999999998, 3.29, 3.2999999999999998, 3.3100000000000001, 3.3199999999999998, 3.3300000000000001, 3.3399999999999999, 3.3500000000000001, 3.3599999999999999, 3.3700000000000001, 3.3799999999999999, 3.3900000000000001, 3.3999999999999999, 3.4100000000000001, 3.4199999999999999, 3.4300000000000002, 3.4399999999999999, 3.4500000000000002, 3.46, 3.4700000000000002, 3.48, 3.4900000000000002, 3.5, 3.5099999999999998, 3.52, 3.5299999999999998, 3.54, 3.5499999999999998, 3.5600000000000001, 3.5699999999999998, 3.5800000000000001, 3.5899999999999999, 3.6000000000000001, 3.6099999999999999, 3.6200000000000001, 3.6299999999999999, 3.6400000000000001, 3.6499999999999999, 3.6600000000000001, 3.6699999999999999, 3.6800000000000002, 3.6899999999999999, 3.7000000000000002, 3.71, 3.7200000000000002, 3.73, 3.7400000000000002, 3.75, 3.7599999999999998, 3.77, 3.7799999999999998, 3.79, 3.7999999999999998, 3.8100000000000001, 3.8199999999999998, 3.8300000000000001, 3.8399999999999999, 3.8500000000000001, 3.8599999999999999, 3.8700000000000001, 3.8799999999999999, 3.8900000000000001, 3.8999999999999999, 3.9100000000000001, 3.9199999999999999, 3.9300000000000002, 3.9399999999999999, 3.9500000000000002, 3.96, 3.9700000000000002, 3.98, 3.9900000000000002, 4.0, 4.0099999999999998, 4.0199999999999996, 4.0300000000000002, 4.04, 4.0499999999999998, 4.0599999999999996, 4.0700000000000003, 4.0800000000000001, 4.0899999999999999, 4.0999999999999996, 4.1100000000000003, 4.1200000000000001, 4.1299999999999999, 4.1399999999999997, 4.1500000000000004, 4.1600000000000001, 4.1699999999999999, 4.1799999999999997, 4.1900000000000004, 4.2000000000000002, 4.21, 4.2199999999999998, 4.2300000000000004, 4.2400000000000002]
4:31:31[QML:Reduced 17; QMD 8] [compute expectation values] times to compute: [0.0, 0.01, 0.02, 0.029999999999999999, 0.040000000000000001, 0.050000000000000003, 0.059999999999999998, 0.070000000000000007, 0.080000000000000002, 0.089999999999999997, 0.10000000000000001, 0.11, 0.12, 0.13, 0.14000000000000001, 0.14999999999999999, 0.16, 0.17000000000000001, 0.17999999999999999, 0.19, 0.20000000000000001, 0.20999999999999999, 0.22, 0.23000000000000001, 0.23999999999999999, 0.25, 0.26000000000000001, 0.27000000000000002, 0.28000000000000003, 0.28999999999999998, 0.29999999999999999, 0.31, 0.32000000000000001, 0.33000000000000002, 0.34000000000000002, 0.34999999999999998, 0.35999999999999999, 0.37, 0.38, 0.39000000000000001, 0.40000000000000002, 0.40999999999999998, 0.41999999999999998, 0.42999999999999999, 0.44, 0.45000000000000001, 0.46000000000000002, 0.46999999999999997, 0.47999999999999998, 0.48999999999999999, 0.5, 0.51000000000000001, 0.52000000000000002, 0.53000000000000003, 0.54000000000000004, 0.55000000000000004, 0.56000000000000005, 0.56999999999999995, 0.57999999999999996, 0.58999999999999997, 0.59999999999999998, 0.60999999999999999, 0.62, 0.63, 0.64000000000000001, 0.65000000000000002, 0.66000000000000003, 0.67000000000000004, 0.68000000000000005, 0.68999999999999995, 0.69999999999999996, 0.70999999999999996, 0.71999999999999997, 0.72999999999999998, 0.73999999999999999, 0.75, 0.76000000000000001, 0.77000000000000002, 0.78000000000000003, 0.79000000000000004, 0.80000000000000004, 0.81000000000000005, 0.81999999999999995, 0.82999999999999996, 0.83999999999999997, 0.84999999999999998, 0.85999999999999999, 0.87, 0.88, 0.89000000000000001, 0.90000000000000002, 0.91000000000000003, 0.92000000000000004, 0.93000000000000005, 0.93999999999999995, 0.94999999999999996, 0.95999999999999996, 0.96999999999999997, 0.97999999999999998, 0.98999999999999999, 1.0, 1.01, 1.02, 1.03, 1.04, 1.05, 1.0600000000000001, 1.0700000000000001, 1.0800000000000001, 1.0900000000000001, 1.1000000000000001, 1.1100000000000001, 1.1200000000000001, 1.1299999999999999, 1.1399999999999999, 1.1499999999999999, 1.1599999999999999, 1.1699999999999999, 1.1799999999999999, 1.1899999999999999, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3, 1.3100000000000001, 1.3200000000000001, 1.3300000000000001, 1.3400000000000001, 1.3500000000000001, 1.3600000000000001, 1.3700000000000001, 1.3799999999999999, 1.3899999999999999, 1.3999999999999999, 1.4099999999999999, 1.4199999999999999, 1.4299999999999999, 1.4399999999999999, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5, 1.51, 1.52, 1.53, 1.54, 1.55, 1.5600000000000001, 1.5700000000000001, 1.5800000000000001, 1.5900000000000001, 1.6000000000000001, 1.6100000000000001, 1.6200000000000001, 1.6299999999999999, 1.6399999999999999, 1.6499999999999999, 1.6599999999999999, 1.6699999999999999, 1.6799999999999999, 1.6899999999999999, 1.7, 1.71, 1.72, 1.73, 1.74, 1.75, 1.76, 1.77, 1.78, 1.79, 1.8, 1.8100000000000001, 1.8200000000000001, 1.8300000000000001, 1.8400000000000001, 1.8500000000000001, 1.8600000000000001, 1.8700000000000001, 1.8799999999999999, 1.8899999999999999, 1.8999999999999999, 1.9099999999999999, 1.9199999999999999, 1.9299999999999999, 1.9399999999999999, 1.95, 1.96, 1.97, 1.98, 1.99, 2.0, 2.0099999999999998, 2.02, 2.0299999999999998, 2.04, 2.0499999999999998, 2.0600000000000001, 2.0699999999999998, 2.0800000000000001, 2.0899999999999999, 2.1000000000000001, 2.1099999999999999, 2.1200000000000001, 2.1299999999999999, 2.1400000000000001, 2.1499999999999999, 2.1600000000000001, 2.1699999999999999, 2.1800000000000002, 2.1899999999999999, 2.2000000000000002, 2.21, 2.2200000000000002, 2.23, 2.2400000000000002, 2.25, 2.2599999999999998, 2.27, 2.2799999999999998, 2.29, 2.2999999999999998, 2.3100000000000001, 2.3199999999999998, 2.3300000000000001, 2.3399999999999999, 2.3500000000000001, 2.3599999999999999, 2.3700000000000001, 2.3799999999999999, 2.3900000000000001, 2.3999999999999999, 2.4100000000000001, 2.4199999999999999, 2.4300000000000002, 2.4399999999999999, 2.4500000000000002, 2.46, 2.4700000000000002, 2.48, 2.4900000000000002, 2.5, 2.5099999999999998, 2.52, 2.5299999999999998, 2.54, 2.5499999999999998, 2.5600000000000001, 2.5699999999999998, 2.5800000000000001, 2.5899999999999999, 2.6000000000000001, 2.6099999999999999, 2.6200000000000001, 2.6299999999999999, 2.6400000000000001, 2.6499999999999999, 2.6600000000000001, 2.6699999999999999, 2.6800000000000002, 2.6899999999999999, 2.7000000000000002, 2.71, 2.7200000000000002, 2.73, 2.7400000000000002, 2.75, 2.7599999999999998, 2.77, 2.7799999999999998, 2.79, 2.7999999999999998, 2.8100000000000001, 2.8199999999999998, 2.8300000000000001, 2.8399999999999999, 2.8500000000000001, 2.8599999999999999, 2.8700000000000001, 2.8799999999999999, 2.8900000000000001, 2.8999999999999999, 2.9100000000000001, 2.9199999999999999, 2.9300000000000002, 2.9399999999999999, 2.9500000000000002, 2.96, 2.9700000000000002, 2.98, 2.9900000000000002, 3.0, 3.0099999999999998, 3.02, 3.0299999999999998, 3.04, 3.0499999999999998, 3.0600000000000001, 3.0699999999999998, 3.0800000000000001, 3.0899999999999999, 3.1000000000000001, 3.1099999999999999, 3.1200000000000001, 3.1299999999999999, 3.1400000000000001, 3.1499999999999999, 3.1600000000000001, 3.1699999999999999, 3.1800000000000002, 3.1899999999999999, 3.2000000000000002, 3.21, 3.2200000000000002, 3.23, 3.2400000000000002, 3.25, 3.2599999999999998, 3.27, 3.2799999999999998, 3.29, 3.2999999999999998, 3.3100000000000001, 3.3199999999999998, 3.3300000000000001, 3.3399999999999999, 3.3500000000000001, 3.3599999999999999, 3.3700000000000001, 3.3799999999999999, 3.3900000000000001, 3.3999999999999999, 3.4100000000000001, 3.4199999999999999, 3.4300000000000002, 3.4399999999999999, 3.4500000000000002, 3.46, 3.4700000000000002, 3.48, 3.4900000000000002, 3.5, 3.5099999999999998, 3.52, 3.5299999999999998, 3.54, 3.5499999999999998, 3.5600000000000001, 3.5699999999999998, 3.5800000000000001, 3.5899999999999999, 3.6000000000000001, 3.6099999999999999, 3.6200000000000001, 3.6299999999999999, 3.6400000000000001, 3.6499999999999999, 3.6600000000000001, 3.6699999999999999, 3.6800000000000002, 3.6899999999999999, 3.7000000000000002, 3.71, 3.7200000000000002, 3.73, 3.7400000000000002, 3.75, 3.7599999999999998, 3.77, 3.7799999999999998, 3.79, 3.7999999999999998, 3.8100000000000001, 3.8199999999999998, 3.8300000000000001, 3.8399999999999999, 3.8500000000000001, 3.8599999999999999, 3.8700000000000001, 3.8799999999999999, 3.8900000000000001, 3.8999999999999999, 3.9100000000000001, 3.9199999999999999, 3.9300000000000002, 3.9399999999999999, 3.9500000000000002, 3.96, 3.9700000000000002, 3.98, 3.9900000000000002, 4.0, 4.0099999999999998, 4.0199999999999996, 4.0300000000000002, 4.04, 4.0499999999999998, 4.0599999999999996, 4.0700000000000003, 4.0800000000000001, 4.0899999999999999, 4.0999999999999996, 4.1100000000000003, 4.1200000000000001, 4.1299999999999999, 4.1399999999999997, 4.1500000000000004, 4.1600000000000001, 4.1699999999999999, 4.1799999999999997, 4.1900000000000004, 4.2000000000000002, 4.21, 4.2199999999999998, 4.2300000000000004, 4.2400000000000002]
4:31:34[QML:Reduced 8; QMD 8] Computing expectation values. 
Measurement Type: hahn_evolution 
LearnedHamiltonian [[ 1.99702703+0.j          0.00000000+0.j         -0.09883486-3.10676659j
  -2.99999974+0.j        ]
 [ 0.00000000+0.j          1.99702703+0.j          2.99999974+0.j
  -0.09883486-3.10676659j]
 [-0.09883486+3.10676659j  2.99999974+0.j         -1.99702703+0.j
   0.00000000+0.j        ]
 [-2.99999974+0.j         -0.09883486+3.10676659j  0.00000000+0.j
  -1.99702703+0.j        ]] 
Probe: [ 0.49971827 -4.83795104e-04j  0.50013082 +2.23249446e-04j
  0.50031730 -2.46059755e-05j  0.49983262 -6.92224955e-04j] 
Times: [0.0, 0.02, 0.040000000000000001, 0.059999999999999998, 0.080000000000000002, 0.10000000000000001, 0.12, 0.14000000000000001, 0.16, 0.17999999999999999, 0.20000000000000001, 0.22, 0.23999999999999999, 0.26000000000000001, 0.28000000000000003, 0.29999999999999999, 0.32000000000000001, 0.34000000000000002, 0.35999999999999999, 0.38, 0.40000000000000002, 0.41999999999999998, 0.44, 0.46000000000000002, 0.47999999999999998, 0.5, 0.52000000000000002, 0.54000000000000004, 0.56000000000000005, 0.57999999999999996, 0.59999999999999998, 0.62, 0.64000000000000001, 0.66000000000000003, 0.68000000000000005, 0.69999999999999996, 0.71999999999999997, 0.73999999999999999, 0.76000000000000001, 0.78000000000000003, 0.80000000000000004, 0.81999999999999995, 0.83999999999999997, 0.85999999999999999, 0.88, 0.90000000000000002, 0.92000000000000004, 0.93999999999999995, 0.95999999999999996, 0.97999999999999998, 1.0, 1.02, 1.04, 1.0600000000000001, 1.0800000000000001, 1.1000000000000001, 1.1200000000000001, 1.1399999999999999, 1.1599999999999999, 1.1799999999999999, 1.2, 1.22, 1.24, 1.26, 1.28, 1.3, 1.3200000000000001, 1.3400000000000001, 1.3600000000000001, 1.3799999999999999, 1.3999999999999999, 1.4199999999999999, 1.4399999999999999, 1.46, 1.48, 1.5, 1.52, 1.54, 1.5600000000000001, 1.5800000000000001, 1.6000000000000001, 1.6200000000000001, 1.6399999999999999, 1.6599999999999999, 1.6799999999999999, 1.7, 1.72, 1.74, 1.76, 1.78, 1.8, 1.8200000000000001, 1.8400000000000001, 1.8600000000000001, 1.8799999999999999, 1.8999999999999999, 1.9199999999999999, 1.9399999999999999, 1.96, 1.98, 2.0, 2.02, 2.04, 2.0600000000000001, 2.0800000000000001, 2.1000000000000001, 2.1200000000000001, 2.1400000000000001, 2.1600000000000001, 2.1800000000000002, 2.2000000000000002, 2.2200000000000002, 2.2400000000000002, 2.2599999999999998, 2.2799999999999998, 2.2999999999999998, 2.3199999999999998, 2.3399999999999999, 2.3599999999999999, 2.3799999999999999, 2.3999999999999999, 2.4199999999999999, 2.4399999999999999, 2.46, 2.48, 2.5, 2.52, 2.54, 2.5600000000000001, 2.5800000000000001, 2.6000000000000001, 2.6200000000000001, 2.6400000000000001, 2.6600000000000001, 2.6800000000000002, 2.7000000000000002, 2.7200000000000002, 2.7400000000000002, 2.7599999999999998, 2.7799999999999998, 2.7999999999999998, 2.8199999999999998, 2.8399999999999999, 2.8599999999999999, 2.8799999999999999, 2.8999999999999999, 2.9199999999999999, 2.9399999999999999, 2.96, 2.98, 3.0, 3.02, 3.04, 3.0600000000000001, 3.0800000000000001, 3.1000000000000001, 3.1200000000000001, 3.1400000000000001, 3.1600000000000001, 3.1800000000000002, 3.2000000000000002, 3.2200000000000002, 3.2400000000000002, 3.2599999999999998, 3.2799999999999998, 3.2999999999999998, 3.3199999999999998, 3.3399999999999999, 3.3599999999999999, 3.3799999999999999, 3.3999999999999999, 3.4199999999999999, 3.4399999999999999, 3.46, 3.48, 3.5, 3.52, 3.54, 3.5600000000000001, 3.5800000000000001, 3.6000000000000001, 3.6200000000000001, 3.6400000000000001, 3.6600000000000001, 3.6800000000000002, 3.7000000000000002, 3.7200000000000002, 3.7400000000000002, 3.7599999999999998, 3.7799999999999998, 3.7999999999999998, 3.8199999999999998, 3.8399999999999999, 3.8599999999999999, 3.8799999999999999, 3.8999999999999999, 3.9199999999999999, 3.9399999999999999, 3.96, 3.98, 4.0, 4.0199999999999996, 4.04, 4.0599999999999996, 4.0800000000000001, 4.0999999999999996, 4.1200000000000001, 4.1399999999999997, 4.1600000000000001, 4.1799999999999997, 4.2000000000000002, 4.2199999999999998, 4.2400000000000002, 4.2599999999999998, 4.2800000000000002, 4.2999999999999998, 4.3200000000000003, 4.3399999999999999, 4.3600000000000003, 4.3799999999999999, 4.4000000000000004, 4.4199999999999999, 4.4400000000000004, 4.46, 4.4800000000000004, 4.5, 4.5199999999999996, 4.54, 4.5599999999999996, 4.5800000000000001, 4.5999999999999996, 4.6200000000000001, 4.6399999999999997, 4.6600000000000001, 4.6799999999999997, 4.7000000000000002, 4.7199999999999998, 4.7400000000000002, 4.7599999999999998, 4.7800000000000002, 4.7999999999999998, 4.8200000000000003, 4.8399999999999999, 4.8600000000000003, 4.8799999999999999, 4.9000000000000004, 4.9199999999999999, 4.9400000000000004, 4.96, 4.9800000000000004, 5.0, 5.0199999999999996, 5.04, 5.0599999999999996, 5.0800000000000001, 5.0999999999999996, 5.1200000000000001, 5.1399999999999997, 5.1600000000000001, 5.1799999999999997, 5.2000000000000002, 5.2199999999999998, 5.2400000000000002, 5.2599999999999998, 5.2800000000000002, 5.2999999999999998, 5.3200000000000003, 5.3399999999999999, 5.3600000000000003, 5.3799999999999999, 5.4000000000000004, 5.4199999999999999, 5.4400000000000004, 5.46, 5.4800000000000004, 5.5, 5.5199999999999996, 5.54, 5.5599999999999996, 5.5800000000000001, 5.5999999999999996, 5.6200000000000001, 5.6399999999999997, 5.6600000000000001, 5.6799999999999997, 5.7000000000000002, 5.7199999999999998, 5.7400000000000002, 5.7599999999999998, 5.7800000000000002, 5.7999999999999998, 5.8200000000000003, 5.8399999999999999, 5.8600000000000003, 5.8799999999999999, 5.9000000000000004, 5.9199999999999999, 5.9400000000000004, 5.96, 5.9800000000000004, 6.0, 6.0199999999999996, 6.04, 6.0599999999999996, 6.0800000000000001, 6.0999999999999996, 6.1200000000000001, 6.1399999999999997, 6.1600000000000001, 6.1799999999999997, 6.2000000000000002, 6.2199999999999998, 6.2400000000000002, 6.2599999999999998, 6.2800000000000002, 6.2999999999999998, 6.3200000000000003, 6.3399999999999999, 6.3600000000000003, 6.3799999999999999, 6.4000000000000004, 6.4199999999999999, 6.4400000000000004, 6.46, 6.4800000000000004, 6.5, 6.5199999999999996, 6.54, 6.5599999999999996, 6.5800000000000001, 6.5999999999999996, 6.6200000000000001, 6.6399999999999997, 6.6600000000000001, 6.6799999999999997, 6.7000000000000002, 6.7199999999999998, 6.7400000000000002, 6.7599999999999998, 6.7800000000000002, 6.7999999999999998, 6.8200000000000003, 6.8399999999999999, 6.8600000000000003, 6.8799999999999999, 6.9000000000000004, 6.9199999999999999, 6.9400000000000004, 6.96, 6.9800000000000004, 7.0, 7.0199999999999996, 7.04, 7.0599999999999996, 7.0800000000000001, 7.0999999999999996, 7.1200000000000001, 7.1399999999999997, 7.1600000000000001, 7.1799999999999997, 7.2000000000000002, 7.2199999999999998, 7.2400000000000002, 7.2599999999999998, 7.2800000000000002, 7.2999999999999998, 7.3200000000000003, 7.3399999999999999, 7.3600000000000003, 7.3799999999999999, 7.4000000000000004, 7.4199999999999999, 7.4400000000000004, 7.46, 7.4800000000000004, 7.5, 7.5199999999999996, 7.54, 7.5599999999999996, 7.5800000000000001, 7.5999999999999996, 7.6200000000000001, 7.6399999999999997, 7.6600000000000001, 7.6799999999999997, 7.7000000000000002, 7.7199999999999998, 7.7400000000000002, 7.7599999999999998, 7.7800000000000002, 7.7999999999999998, 7.8200000000000003, 7.8399999999999999, 7.8600000000000003, 7.8799999999999999, 7.9000000000000004, 7.9199999999999999, 7.9400000000000004, 7.96, 7.9800000000000004, 8.0, 8.0199999999999996, 8.0399999999999991, 8.0600000000000005, 8.0800000000000001, 8.0999999999999996, 8.1199999999999992, 8.1400000000000006, 8.1600000000000001, 8.1799999999999997, 8.1999999999999993, 8.2200000000000006, 8.2400000000000002, 8.2599999999999998, 8.2799999999999994, 8.3000000000000007, 8.3200000000000003, 8.3399999999999999, 8.3599999999999994, 8.3800000000000008, 8.4000000000000004, 8.4199999999999999, 8.4399999999999995, 8.4600000000000009, 8.4800000000000004]
4:31:34[QML:Reduced 8; QMD 8] [compute expectation values] times to compute: [4.2599999999999998, 4.2800000000000002, 4.2999999999999998, 4.3200000000000003, 4.3399999999999999, 4.3600000000000003, 4.3799999999999999, 4.4000000000000004, 4.4199999999999999, 4.4400000000000004, 4.46, 4.4800000000000004, 4.5, 4.5199999999999996, 4.54, 4.5599999999999996, 4.5800000000000001, 4.5999999999999996, 4.6200000000000001, 4.6399999999999997, 4.6600000000000001, 4.6799999999999997, 4.7000000000000002, 4.7199999999999998, 4.7400000000000002, 4.7599999999999998, 4.7800000000000002, 4.7999999999999998, 4.8200000000000003, 4.8399999999999999, 4.8600000000000003, 4.8799999999999999, 4.9000000000000004, 4.9199999999999999, 4.9400000000000004, 4.96, 4.9800000000000004, 5.0, 5.0199999999999996, 5.04, 5.0599999999999996, 5.0800000000000001, 5.0999999999999996, 5.1200000000000001, 5.1399999999999997, 5.1600000000000001, 5.1799999999999997, 5.2000000000000002, 5.2199999999999998, 5.2400000000000002, 5.2599999999999998, 5.2800000000000002, 5.2999999999999998, 5.3200000000000003, 5.3399999999999999, 5.3600000000000003, 5.3799999999999999, 5.4000000000000004, 5.4199999999999999, 5.4400000000000004, 5.46, 5.4800000000000004, 5.5, 5.5199999999999996, 5.54, 5.5599999999999996, 5.5800000000000001, 5.5999999999999996, 5.6200000000000001, 5.6399999999999997, 5.6600000000000001, 5.6799999999999997, 5.7000000000000002, 5.7199999999999998, 5.7400000000000002, 5.7599999999999998, 5.7800000000000002, 5.7999999999999998, 5.8200000000000003, 5.8399999999999999, 5.8600000000000003, 5.8799999999999999, 5.9000000000000004, 5.9199999999999999, 5.9400000000000004, 5.96, 5.9800000000000004, 6.0, 6.0199999999999996, 6.04, 6.0599999999999996, 6.0800000000000001, 6.0999999999999996, 6.1200000000000001, 6.1399999999999997, 6.1600000000000001, 6.1799999999999997, 6.2000000000000002, 6.2199999999999998, 6.2400000000000002, 6.2599999999999998, 6.2800000000000002, 6.2999999999999998, 6.3200000000000003, 6.3399999999999999, 6.3600000000000003, 6.3799999999999999, 6.4000000000000004, 6.4199999999999999, 6.4400000000000004, 6.46, 6.4800000000000004, 6.5, 6.5199999999999996, 6.54, 6.5599999999999996, 6.5800000000000001, 6.5999999999999996, 6.6200000000000001, 6.6399999999999997, 6.6600000000000001, 6.6799999999999997, 6.7000000000000002, 6.7199999999999998, 6.7400000000000002, 6.7599999999999998, 6.7800000000000002, 6.7999999999999998, 6.8200000000000003, 6.8399999999999999, 6.8600000000000003, 6.8799999999999999, 6.9000000000000004, 6.9199999999999999, 6.9400000000000004, 6.96, 6.9800000000000004, 7.0, 7.0199999999999996, 7.04, 7.0599999999999996, 7.0800000000000001, 7.0999999999999996, 7.1200000000000001, 7.1399999999999997, 7.1600000000000001, 7.1799999999999997, 7.2000000000000002, 7.2199999999999998, 7.2400000000000002, 7.2599999999999998, 7.2800000000000002, 7.2999999999999998, 7.3200000000000003, 7.3399999999999999, 7.3600000000000003, 7.3799999999999999, 7.4000000000000004, 7.4199999999999999, 7.4400000000000004, 7.46, 7.4800000000000004, 7.5, 7.5199999999999996, 7.54, 7.5599999999999996, 7.5800000000000001, 7.5999999999999996, 7.6200000000000001, 7.6399999999999997, 7.6600000000000001, 7.6799999999999997, 7.7000000000000002, 7.7199999999999998, 7.7400000000000002, 7.7599999999999998, 7.7800000000000002, 7.7999999999999998, 7.8200000000000003, 7.8399999999999999, 7.8600000000000003, 7.8799999999999999, 7.9000000000000004, 7.9199999999999999, 7.9400000000000004, 7.96, 7.9800000000000004, 8.0, 8.0199999999999996, 8.0399999999999991, 8.0600000000000005, 8.0800000000000001, 8.0999999999999996, 8.1199999999999992, 8.1400000000000006, 8.1600000000000001, 8.1799999999999997, 8.1999999999999993, 8.2200000000000006, 8.2400000000000002, 8.2599999999999998, 8.2799999999999994, 8.3000000000000007, 8.3200000000000003, 8.3399999999999999, 8.3599999999999994, 8.3800000000000008, 8.4000000000000004, 8.4199999999999999, 8.4399999999999995, 8.4600000000000009, 8.4800000000000004]
4:31:34[QML:Reduced 8; QMD 8] Computing expectation values. 
Measurement Type: hahn_evolution 
LearnedHamiltonian [[ 1.99702703+0.j          0.00000000+0.j         -0.09883486-3.10676659j
  -2.99999974+0.j        ]
 [ 0.00000000+0.j          1.99702703+0.j          2.99999974+0.j
  -0.09883486-3.10676659j]
 [-0.09883486+3.10676659j  2.99999974+0.j         -1.99702703+0.j
   0.00000000+0.j        ]
 [-2.99999974+0.j         -0.09883486+3.10676659j  0.00000000+0.j
  -1.99702703+0.j        ]] 
Probe: [ 0.49971827 -4.83795104e-04j  0.50013082 +2.23249446e-04j
  0.50031730 -2.46059755e-05j  0.49983262 -6.92224955e-04j] 
Times: [0.0, 0.01, 0.02, 0.029999999999999999, 0.040000000000000001, 0.050000000000000003, 0.059999999999999998, 0.070000000000000007, 0.080000000000000002, 0.089999999999999997, 0.10000000000000001, 0.11, 0.12, 0.13, 0.14000000000000001, 0.14999999999999999, 0.16, 0.17000000000000001, 0.17999999999999999, 0.19, 0.20000000000000001, 0.20999999999999999, 0.22, 0.23000000000000001, 0.23999999999999999, 0.25, 0.26000000000000001, 0.27000000000000002, 0.28000000000000003, 0.28999999999999998, 0.29999999999999999, 0.31, 0.32000000000000001, 0.33000000000000002, 0.34000000000000002, 0.34999999999999998, 0.35999999999999999, 0.37, 0.38, 0.39000000000000001, 0.40000000000000002, 0.40999999999999998, 0.41999999999999998, 0.42999999999999999, 0.44, 0.45000000000000001, 0.46000000000000002, 0.46999999999999997, 0.47999999999999998, 0.48999999999999999, 0.5, 0.51000000000000001, 0.52000000000000002, 0.53000000000000003, 0.54000000000000004, 0.55000000000000004, 0.56000000000000005, 0.56999999999999995, 0.57999999999999996, 0.58999999999999997, 0.59999999999999998, 0.60999999999999999, 0.62, 0.63, 0.64000000000000001, 0.65000000000000002, 0.66000000000000003, 0.67000000000000004, 0.68000000000000005, 0.68999999999999995, 0.69999999999999996, 0.70999999999999996, 0.71999999999999997, 0.72999999999999998, 0.73999999999999999, 0.75, 0.76000000000000001, 0.77000000000000002, 0.78000000000000003, 0.79000000000000004, 0.80000000000000004, 0.81000000000000005, 0.81999999999999995, 0.82999999999999996, 0.83999999999999997, 0.84999999999999998, 0.85999999999999999, 0.87, 0.88, 0.89000000000000001, 0.90000000000000002, 0.91000000000000003, 0.92000000000000004, 0.93000000000000005, 0.93999999999999995, 0.94999999999999996, 0.95999999999999996, 0.96999999999999997, 0.97999999999999998, 0.98999999999999999, 1.0, 1.01, 1.02, 1.03, 1.04, 1.05, 1.0600000000000001, 1.0700000000000001, 1.0800000000000001, 1.0900000000000001, 1.1000000000000001, 1.1100000000000001, 1.1200000000000001, 1.1299999999999999, 1.1399999999999999, 1.1499999999999999, 1.1599999999999999, 1.1699999999999999, 1.1799999999999999, 1.1899999999999999, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3, 1.3100000000000001, 1.3200000000000001, 1.3300000000000001, 1.3400000000000001, 1.3500000000000001, 1.3600000000000001, 1.3700000000000001, 1.3799999999999999, 1.3899999999999999, 1.3999999999999999, 1.4099999999999999, 1.4199999999999999, 1.4299999999999999, 1.4399999999999999, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5, 1.51, 1.52, 1.53, 1.54, 1.55, 1.5600000000000001, 1.5700000000000001, 1.5800000000000001, 1.5900000000000001, 1.6000000000000001, 1.6100000000000001, 1.6200000000000001, 1.6299999999999999, 1.6399999999999999, 1.6499999999999999, 1.6599999999999999, 1.6699999999999999, 1.6799999999999999, 1.6899999999999999, 1.7, 1.71, 1.72, 1.73, 1.74, 1.75, 1.76, 1.77, 1.78, 1.79, 1.8, 1.8100000000000001, 1.8200000000000001, 1.8300000000000001, 1.8400000000000001, 1.8500000000000001, 1.8600000000000001, 1.8700000000000001, 1.8799999999999999, 1.8899999999999999, 1.8999999999999999, 1.9099999999999999, 1.9199999999999999, 1.9299999999999999, 1.9399999999999999, 1.95, 1.96, 1.97, 1.98, 1.99, 2.0, 2.0099999999999998, 2.02, 2.0299999999999998, 2.04, 2.0499999999999998, 2.0600000000000001, 2.0699999999999998, 2.0800000000000001, 2.0899999999999999, 2.1000000000000001, 2.1099999999999999, 2.1200000000000001, 2.1299999999999999, 2.1400000000000001, 2.1499999999999999, 2.1600000000000001, 2.1699999999999999, 2.1800000000000002, 2.1899999999999999, 2.2000000000000002, 2.21, 2.2200000000000002, 2.23, 2.2400000000000002, 2.25, 2.2599999999999998, 2.27, 2.2799999999999998, 2.29, 2.2999999999999998, 2.3100000000000001, 2.3199999999999998, 2.3300000000000001, 2.3399999999999999, 2.3500000000000001, 2.3599999999999999, 2.3700000000000001, 2.3799999999999999, 2.3900000000000001, 2.3999999999999999, 2.4100000000000001, 2.4199999999999999, 2.4300000000000002, 2.4399999999999999, 2.4500000000000002, 2.46, 2.4700000000000002, 2.48, 2.4900000000000002, 2.5, 2.5099999999999998, 2.52, 2.5299999999999998, 2.54, 2.5499999999999998, 2.5600000000000001, 2.5699999999999998, 2.5800000000000001, 2.5899999999999999, 2.6000000000000001, 2.6099999999999999, 2.6200000000000001, 2.6299999999999999, 2.6400000000000001, 2.6499999999999999, 2.6600000000000001, 2.6699999999999999, 2.6800000000000002, 2.6899999999999999, 2.7000000000000002, 2.71, 2.7200000000000002, 2.73, 2.7400000000000002, 2.75, 2.7599999999999998, 2.77, 2.7799999999999998, 2.79, 2.7999999999999998, 2.8100000000000001, 2.8199999999999998, 2.8300000000000001, 2.8399999999999999, 2.8500000000000001, 2.8599999999999999, 2.8700000000000001, 2.8799999999999999, 2.8900000000000001, 2.8999999999999999, 2.9100000000000001, 2.9199999999999999, 2.9300000000000002, 2.9399999999999999, 2.9500000000000002, 2.96, 2.9700000000000002, 2.98, 2.9900000000000002, 3.0, 3.0099999999999998, 3.02, 3.0299999999999998, 3.04, 3.0499999999999998, 3.0600000000000001, 3.0699999999999998, 3.0800000000000001, 3.0899999999999999, 3.1000000000000001, 3.1099999999999999, 3.1200000000000001, 3.1299999999999999, 3.1400000000000001, 3.1499999999999999, 3.1600000000000001, 3.1699999999999999, 3.1800000000000002, 3.1899999999999999, 3.2000000000000002, 3.21, 3.2200000000000002, 3.23, 3.2400000000000002, 3.25, 3.2599999999999998, 3.27, 3.2799999999999998, 3.29, 3.2999999999999998, 3.3100000000000001, 3.3199999999999998, 3.3300000000000001, 3.3399999999999999, 3.3500000000000001, 3.3599999999999999, 3.3700000000000001, 3.3799999999999999, 3.3900000000000001, 3.3999999999999999, 3.4100000000000001, 3.4199999999999999, 3.4300000000000002, 3.4399999999999999, 3.4500000000000002, 3.46, 3.4700000000000002, 3.48, 3.4900000000000002, 3.5, 3.5099999999999998, 3.52, 3.5299999999999998, 3.54, 3.5499999999999998, 3.5600000000000001, 3.5699999999999998, 3.5800000000000001, 3.5899999999999999, 3.6000000000000001, 3.6099999999999999, 3.6200000000000001, 3.6299999999999999, 3.6400000000000001, 3.6499999999999999, 3.6600000000000001, 3.6699999999999999, 3.6800000000000002, 3.6899999999999999, 3.7000000000000002, 3.71, 3.7200000000000002, 3.73, 3.7400000000000002, 3.75, 3.7599999999999998, 3.77, 3.7799999999999998, 3.79, 3.7999999999999998, 3.8100000000000001, 3.8199999999999998, 3.8300000000000001, 3.8399999999999999, 3.8500000000000001, 3.8599999999999999, 3.8700000000000001, 3.8799999999999999, 3.8900000000000001, 3.8999999999999999, 3.9100000000000001, 3.9199999999999999, 3.9300000000000002, 3.9399999999999999, 3.9500000000000002, 3.96, 3.9700000000000002, 3.98, 3.9900000000000002, 4.0, 4.0099999999999998, 4.0199999999999996, 4.0300000000000002, 4.04, 4.0499999999999998, 4.0599999999999996, 4.0700000000000003, 4.0800000000000001, 4.0899999999999999, 4.0999999999999996, 4.1100000000000003, 4.1200000000000001, 4.1299999999999999, 4.1399999999999997, 4.1500000000000004, 4.1600000000000001, 4.1699999999999999, 4.1799999999999997, 4.1900000000000004, 4.2000000000000002, 4.21, 4.2199999999999998, 4.2300000000000004, 4.2400000000000002]
4:31:34[QML:Reduced 8; QMD 8] [compute expectation values] times to compute: []
4:31:34 [EXP] QMD complete. Pickling result to /panfs/panasas01/phys/bf16951/QMD/ParallelDevelopment/Results/Aug_21/15_59/qmd_class_008.p
4:31:36 [EXP] Time taken: 45023.82172393799
4:31:36 [EXP] END: QMD id 8 : 2500  particles; 750 exp;  750 bayes. Time: 45023.82172393799
